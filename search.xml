<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习平凡之路三]]></title>
    <url>%2F2021%2F03%2F24%2F2021-03-25-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%87%A1%E4%B9%8B%E8%B7%AF%E4%B8%89%2F</url>
    <content type="text"><![CDATA[机器学习平凡之路三 线性回归 网店销售额预测 步骤说明 明确定义所解决的问题——网店销售额的预测 数据收集和预处理环节分5步走 收集数据 收集的数据可视化，熟悉数据的结构 做特征工程，使数据更好的被机器识别 查分数据集为训练集和测试集 做特征缩放，把数据压缩到比较小的区间中 选择合适的机器学习算法 确定机器学习的算法(线性回归算法) 确定线性回归的假设函数 确定线性回归的损失函数 通过梯度下降训练机器，确定内部参数的过程 进行超参数调试和性能优化 简明的说就是发现一个能有此到彼的函数，如果函数只包括一个自变量和一个因变量，这个就是一元线性回归。包含2个以上的自变量就是多元线性回归 步骤一数据读取和可视化1234import numpy as npimport pandas as pddf_ads = pd.read_csv('advertising.csv')df_ads.head() 步骤二数据的相关分析1234import matplotlib.pyplot as pltimport seaborn as snssns.heatmap(df_ads.corr(),cmap='YlGnBu',annot=True)plt.show() 通过相关系分析，可以得知销售额和通过微信投入的是最有效地正比 12345sns.pairplot(df_ads, x_vars =['wechat','weibo','others'], y_vars ='sales', height=4, aspect=1,kind='scatter' ) 步骤三数据集清洗和规范化 上面的图可以发现微信广告的投入和销售额的相关性比较高，所以就只保留微信投入和销售金额 12345X = np.array(df_ads.wechat) # 构建特征集。y = np.array(df_ads.sales) # 构建标签集print(X.ndim)print(X.shape)print(X) 对于回归问题的数值类型数据集，机器学习模型读入的规范格式应该是2D张量.形状为(样本数,标签数) 步骤三拆分变形后的数据集12345X = X.reshape(len(x),1)y = y.reshape(len(y),1) # 对特征及和标签集进行变形from sklearn.model_selection import train_test_splitX_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=0) # 拆分数据集 步骤四数据归一化归一化，相当于数据的分布不变，但是值都落入一个小的特定区间。 常见的一个归一化公式如下 x = x-min(x) / max(x)-min(x) 1234567891011121314151617181920212223'''from sklearn import preprocessingmin_max_scaler = preprocessing.MinMaxScaler()#默认为范围0~1，拷贝操作#min_max_scaler = preprocessing.MinMaxScaler(feature_range = (1,3),copy = False)#范围改为1~3，对原数组操作x_minmax = min_max_scaler.fit_transform(x)'''# 1表示横轴，方向从左到右；0表示纵轴，方向从上到下。当axis=1时，数组的变化是横向的，而体现出来的是列的增加或者减少。# 自行定义一个def scaler(train,test): min = train.min(axis=0) max = train.max(axis=0) gap = max-min train -= min train /= gap test -=min test /= gap return train, testX_train, X_test = scaler(X_train, X_test)y_train, y_test = scaler(y_train, y_test)plt.plot(X_train,y_train,'r.',label ='Training data')plt.xlabel('wechat')plt.ylabel('sales')plt.legend()plt.show() 步骤五选择合适的机器学习模型 确定选用什么类型的模型 确定模型的具体参数 说明 y = ax+b （a代表直线的斜率,b是截距也就是与y轴相交的位置） y = wx+b (w替换成a代表权重,参数b称作为偏置) 假设函数 y-hat = wx+b h(x) = wx+b (h(x)就是假设函数,也可以叫做预测函数) 机器学习的目标就是确定假设函数h(x)同时也是在确定w和b 损失函数 比如一个模型3x+5和100x+1,哪一个更好，损失是对糟糕预测的惩罚。损失也是误差，也称作成本或代价，也就是当前预测值和真实值之间的差距体现。因为每一组不同的参数，机器会针对样本数据集算一次平均损失，计算平均损失是每一个机器学习的必要环节 损失函数的表现形式为L(w,b) 损失函数一般有 L2损失函数，L1损失函数,平均偏差误差函数 (回归) 交叉熵损失函数,多类SVM损失函数(分类) 均方误差函数的实现过程: 对于每一个样本y-yhat,这是预测值和真实值的差异，但损失值与参数w和b有关 将损失值进行平方，平方后都变为正数，这个值叫做单个样本的平方损失 所有平方损失相加，根据数量求平均值。 12345678# 定义损失函数def loss_function(X,y,weight,bias): y_hat =weight*X + bias loss = y_hat-y cost =np.sum(loss**2)/2*len(X) # 这里2相当于去抵消平方后的产生的洗漱 return costprint(loss_function(X_train,y_train,weight=5,bias=3))print(loss_function(X_train,y_train,weight=100,bias=1)) # 系数越小也合适 通过梯度下降找到最佳参数 训练机器，成为拟合的过程。为了确定内部的w和b。怎么才知道他们的最佳值了。最无脑的方式就是，随其生成1万个w和b的不同组合。然后挨个计算。确定一万种最优的。不过最好的理想结果是每做一次都更接近真相。也就是最精髓的梯度下降 通过凸函数确保有最小损失点。比如L和W单独看。 w和b共同作用 关于梯度下降的实现 通过导数，描述函数在某点附近的变化率。求导后为梯度为正值。说明L随着W的增大而增大，反之减小 梯度具有两个特征也就是方向和大小，通过梯度下降法会沿着负梯度方向走一步，以降低损失 关于学习速率 求导知道了后，接下来是学习速率，也就alpha 梯度下降实现 123456789101112131415def gradient_descent(X,y,w,b,lr,iter): l_history = np.zeros(iter) w_history = np.zeros(iter) b_history = np.zeros(iter) for i in rang(iter): y_hat = w*x+b loss = y_hat-y deruvative_w = X.T.dot(loss)/len(x) # 权重求导 deruvative_b = sum(loss)*1/len(x) w = w - lr*deruvative_w b = b - lr*deruvative_b l_history[i] = loss_fuction(X,y,w,b) w_history[i] = w b_history[i] = b return l_history,w_history,b_history 实现线性回归并调试参数 12345678910111213iterations = 100alpha =1weight =-5bias =3print('损失值:',loss_function(X_train,y_train,weight,bias))plt.plot(X_train,y_train,'r.',label='Training data')line_X = np.linspace(X_train.min(),X_train.max(),500)line_y = [weight*xx + bias for xx in line_X]plt.plot(line_X,line_y,'b--',label='current')plt.xlabel('wechat')plt.ylabel('sales')plt.legend()plt.show() 调整学习速率 如果损失函数和求导过程没有出现错误,一般造成损失过大的在于学习速率 通过比较学习速率和迭代次，选择最优 123456loss_history,weight_history,bias_history = gradient_descent(X_train,y_train,weight,bias,alpha,iterations)plt.plot(loss_history,'g--',label='loss curve')plt.xlabel('iter')plt.ylabel('loss')plt.legend()plt.show() # 学习 做完这一切也就是找到了最佳的两个参数 关于多元线性回归基于以上的同等道理 下面贴出代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import numpy as np # 导入NumPy数学工具箱import pandas as pd # 导入Pandas数据处理工具箱from keras.datasets import boston_housing #从Keras中导入mnist数据集#读入训练集和测试集(X_train, y_train), (X_test, y_test) = boston_housing.load_data()def cost_function(X, y, W): # 手工定义一个MSE均方误差函数，W此时是一个向量# X -&gt; 是一个矩阵，形状是(N,4),N是数据集大小，4是特征数量# W -&gt; 是一个向量，形状是(4,1)（1*）# y_hat = X.dot(weight) # 这是假设函数,其中已经应用了Python的广播功能# y_hat = np.dot(X,weight) # 也是正确的 y_hat = X.dot(W.T) # 也是正确的 点积运算 h(x)=w_0*x_0 + w_1*x_1 + w_2*x_2 + w_3*x_3 # y_hat = np.dot(X,weight.T) # 也是正确的# y_hat = weight.dot(X) # 错误 shapes (4,) and (160,4) not aligned: 4 (dim 0) != 160 (dim 0)# y_hat = np.dot(weight,X) # 错误 shapes (4,) and (160,4) not aligned: 4 (dim 0) != 160 (dim 0) loss = y_hat-y # 求出每一个y’和训练集中真实的y之间的差异 cost = np.sum(loss**2)/len(X) # 这是均方误差函数的代码实现 return cost # 返回当前模型的均方误差值def gradient_descent(X, y, W, lr, iter): # 定义梯度下降函数 l_history = np.zeros(iter) # 初始化记录梯度下降过程中损失的数组 W_history = np.zeros((iter,len(W))) # 初始化权重数组 for iter in range(iter): # 进行梯度下降的迭代，就是下多少级台阶 y_hat = X.dot(W) # 这个是向量化运行实现的假设函数 loss = y_hat-y # 中间过程, y_hat和y真值的差 derivative_W = X.T.dot(loss)/(2*len(X)) #求出多项式的梯度向量 derivative_W = derivative_W.reshape(len(W)) W = W - alpha*derivative_W # 结合下降速率更新权重 l_history[iter] = cost_function(X, y, W) # 损失的历史记录 W_history[iter] = W # 梯度下降过程中权重的历史记录 return l_history, W_history # 返回梯度下降过程数据 #首先确定参数的初始值iterations = 12000; # 迭代12000次alpha = 0.00001; #学习速率设为0.00001weight = np.array([0.5,1.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]) # 权重向量#计算一下初始值的损失print ('当前损失：',cost_function(X_train, y_train, weight))# 定义线性回归模型def linear_regression(X, y, weight, alpha, iterations): loss_history, weight_history = gradient_descent(X, y, weight, alpha, iterations) print("训练最终损失:", loss_history[-1]) # 打印最终损失 y_pred = X.dot(weight_history[-1]) # 预测 traning_acc = 100 - np.mean(np.abs(y_pred - y)/y)*100 # 计算准确率 print("线性回归训练准确率: &#123;:.2f&#125;%".format(traning_acc)) # 打印准确率 return loss_history, weight_history # 返回训练历史记录 loss_history, weight_history = linear_regression(X_train, y_train, weight, alpha, iterations) loss_history, weight_history = gradient_descent(X_train, y_train, weight, alpha, iterations) print("权重历史记录：", weight_history)print("损失历史记录：", loss_history) 其他代码123456789from sklearn.linear_model import LinearRegression #导入线性回归算法模型model = LinearRegression() #使用线性回归算法model.fit(X_train, y_train) #用训练集数据，训练机器，拟合函数，确定参数from sklearn.linear_model import Ridge #导入线性岭回归算法模型 model = Ridge() #使用线性回归算法model.fit(X_train, y_train) #用训练集数据，训练机器，拟合函数，确定参数y_pred = model.predict(X_test) #预测测试集的Y值print("线性回归预测评分：", model.score(X_test, y_test)) #评估预测结果 参考文章https://blog.csdn.net/VariableX/article/details/107166602 使用岭回归和LASSO回归，主要针对自变量之间存在多重共线性或者自变量个数多于样本量的情况。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
        <tag>线性回归算法</tag>
        <tag>多元线性</tag>
        <tag>底层实现</tag>
        <tag>进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习平凡之路二]]></title>
    <url>%2F2021%2F03%2F24%2F2021-03-24-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%87%A1%E4%B9%8B%E8%B7%AF%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[机器学习平凡之路二 数学知识 python部分基础 数学 函数 函数视为一种模型，这种模型是对客观世界复杂事物之间的关系简单模拟 在函数中,一个事物输出随着另一个事物的输入的变化而变化 函数的输入和输出,很多情况下都是数字.函数也可以反映非数学之间的关系 函数需要注意的是输入集中的每一个元素X都要被照顾到。函数的输出值是独一无二的 机器学习中的函数 机器学习基本上等价于寻找函数的过程,机器学习到的函数,实现了从特征到结果的一个特定推断。机器学习不是注重特征到标签之间的因果逻辑，更多的是注重期间的相关关系 四方上下曰宇，往故来今曰宙。仰光宇宙之大，俯察品类之盛 如果决定是一个好函数，训练集和验证集上的预测准确并且能够泛化到测试集中，就是好函数 机器学习算法得到的函数，往往能看到数据背后隐藏着的，肉眼不能发现的秘密 机器学习算法，可以得到不同的函数。深度学习的函数相当于一大堆线性函数的跨层堆叠。不管什么样的学习，都是对样本集中特征到标签的关系总结。 函数分类 线性函数 线性函数只拥有一个变量一阶多项式函数，函数就和直线一样，比如y=-x+5或者y=0.5x+2,线性函数适合模拟简单的关系。比如房屋面积和期售价之间可能会呈线性关系 二次函数和多次函数 函数中自变量X中最大的指数被称为函数的次数。比如y=x的二次方，二次函数是凸函数，随着函数的次数升高，将不再是只有一个最低点的凸函数，此事将出现局部最低点 激活函数 激活函数在机器学习算法中实现的是非线性，阶跃性质的变换 比如y=1(x&gt;0),y=0(x&lt;0) 比如Sigmoid函数，，e是一个自然常数，约等于2.72 比如ReLU函数，y=max(x,0) 比如Leaky ReLU函数，y=max(&amp;x,x) . &amp;代表斜率 对数函数 对数函数是指数函数的逆运算，原来的指数就是对数的底。 函数变化趋势机器学习就是研究y如何随着X而变，通过求导和微分来实现的 导数是定义在连续函数的基础之上的，导数是引导，导航,它与函数上连续两个点之间变化趋势，也就是变化的方向相关 函数变化趋势至少由两个点体现,A趋近于B的时候,求其变换的极限。这就是导数。导数的值和它附近的一小段连续函数有关。如果没有那么一段连续的函数，就无法计算其切线的斜率。函数在该点也就是不可导的。 通过求导，实现了以直代曲。也发现了y值随X值变化的方向。也就是在机器学习中可以得到标签y随特征X而变化的方向。导数是针对一个变量而言的函数变化趋向，对于多元的函数，关于一个变量的导数为偏导数。 凸函数 凸函数可以沿着导数给出的方向滚到最低点。在机器学习中无法达到全局最低点是很不理想的情况 梯度 对多元函数的各参数求偏导数，然后把所求的各个参数的偏导数以向量的形式写出来，就是梯度 比如:下山,已知远处的位置比此处低很多。如何下山，每走一个位置求解当前的位置的梯度。然后沿着梯度的负方向，也就是往最陡峭的地方向下一步走。 梯度下降的作用: 机器学习的本质是找到最优的函数 如何衡量函数是否最优，方法是尽量减小预测值和真值间的误差 可以建立误差和模型参数之间的函数 梯度下降能够引导我们走到凸函数的全局最低端，也就是找到误差最小时的参数。 机器学习的数据结构在机器学忠，用于存储数据的结构叫作张量。张量是机器学习程序中的数字容器。本质上就是各种不同维度的数组。 张量的维度称为轴axis。轴的个数称为阶(rank)。张量的形状(shple)就是张量的阶加上每个阶的维度 标量scalar。包含一个数字的的张量，标量的功能主要用于流程控制，设置参数等。 向量有一组数字组成的数组叫做向量(vector),也就是一阶张量。 比如 X_train是一个2D的矩阵，是404个样本数据的集合。y_train是一个向量，是一个404维的标签向量 向量的维度:表示沿着某个轴上的元素个数 而X_train[0]，相当于是一个13维向量(也就是1D张量)，简单的说就是包含13个特征 向量的点积两个向量之间可以进行乘法运算，向量的点积结果是一个值，也就是一个标量，比如 矩阵(2D张量)矩阵是2D张量一般形状为 (样本轴,特征轴)，比如城市交通数据集，包含城市的街道名，等28个交通数据特征。共800个街道。张量形状为(800,28) 矩阵的点积矩阵相乘，第一个矩阵的列数必须等于第二个矩阵的行数。(m,n)乘以(n,m)得到一个矩阵(m,m),公式自行百度 序列数据 比如 第一轴: 样本轴,一年记录下来的数据共365个。也就是365维向量 第二轴:时间步轴,每天一共24小时，每小时4个15分钟，共96维 第三轴：特征轴,一共是温度，湿度，风力3个维度 也就是对于时间数据集的形状为3D张量(样本,时间,标签) 图像数据图像数据本身包含高度，宽度，在加上颜色深度的通道。对于图像数据集来说形状为(样本,图像高度,图像宽度,颜色通道) 在机器学习中，数据是一批一批的进行处理 视频数据视频数据需要5D张量也就是(样本,帧，高度，宽度，颜色深度) python中张量的创建和运算机器学习中张量大多是通过Numpy数组来实现的 创建数组 机器学习一般先从文本文件中把所有样本读取到Dataframe格式的数据，然后用array方法转为Numpy数组，也就是变为张量。然后进行后续的操作 通过索引和切片访问张量中的数据索引既是访问张量某个具体的数据 切片就是访问一个范围内的数据 张量的操作 python中的广播Python的广播功能就是自动自发地把一个变成一排的向量，把一个低维的数组变为高维的数组张量的的形状和第一位加数保持一致 向量和矩阵的点积运算 向量a = [a1,a2,…,an] 向量b = [b1,b2,…,bn] aXb = a1xb1+a2xb2 +…+anxbn 矩阵形状（a,b）和 （b,c）结果为（a,c） 概率某公司男生和女生各占50%，烟民占总人数的10%，女烟民占1%，遇到一个烟民的概率可能性多大 事件B —-烟民 事件A —-女生 P（B） —-10% 随便遇到一个烟民的概率 P（A）—-50% 随便遇到一个女生的概率 p(B|A) 1% 已知100个人里面才有一个烟民 已知A ，B的概率 p(A|B) = 1% X 50% /10% = 5% 已知B，A的概率 条件概率就是已知事件发生的时候，前者的概率 这个就是贝叶斯定理 其他正态分布 自行百度 标准差(sigma)是根据方差进行计算出来的。方差是一组资料中实际数值与算术平均数的差值做平方结果相加之后，除以总数，标准差是方差算术平方根 方差和标准差都是数据相对期望值的离散程度 一般数据标准化，就是样本特征值减去期均值，然后除以期标准差进行缩放]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
        <tag>快速进阶</tag>
        <tag>算法</tag>
        <tag>数学</tag>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习平凡之路一]]></title>
    <url>%2F2021%2F03%2F20%2F2021-03-20-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%87%A1%E4%B9%8B%E8%B7%AF%E4%B8%80%2F</url>
    <content type="text"><![CDATA[机器学习平凡之路一 一些概念 一些操作 基本的机器学习术语 机器学习项目结构 一些概念机器学习是AI技术的分支,深度学习是机器学习的技术之一 机器学习的关键内涵在于利用计算机的运算能力从大量的数据中发现一个函数或者模型，通过她来模拟现实世界事物之间的关系，从而预测或者判断的功能 自变量在机器学习中叫做特征，也可以叫做标签。或者叫做标记也可以 比如:爸爸的身高(自变量X1),妈妈的身高(自变量X2),可能会影响孩子的身高(因变量y) 机器学习是在已知数据集的基础上，反复计算通过比较贴切的函数，找到之间的关系 机器学习中监督学习需要标签数据,无监督学习不需要标签数据,半监督学习介于2者之间 深度学习:就是层数较多,结构比较复杂的神经网络的机器学习，这个过程中会产生数据由非结构化到结构化的转变 注意:简单的说就是一张32px X 32px的图片通过深度学习转换为机器能够看明白的编码 强化学习：研究智能体如何基于环境做出行动反应,以取得最大化的累积奖励 机器学习两大场景回归回归问题通常用来预测一个值,标签的值是连续的 分类分类问题是将事物标记一个类别的标签，结果为离散值，也就是类别中的一个选项 其它聚类就是在没有便签的情况下，将数据按照特征的性质分成不同的簇 关联规则就是找到特征之间的影响关系 时间序列指内部结构随时间呈现规律性变化的数据集，类似金融市场，太阳活动等 机器学习不是万能的，只能作用于和已知数据集类似的数据，优势在于计算量，速度和准确性。暂时没有形成人类的智力思维模式 一些操作 图形展示 预测结果可以看到随着家庭的收入增高，房价也是随之水涨船高。 基本术语 术语 定义 数学描述 示例 数据集 数据的集合 {(x1,y1),…,(xn,yn)} 比如1000个房屋的面积，楼层，以及房价 样本 数据集中的一条具体记录 (x1,y1) 一个房屋的数据记录 标签 预测的结果也称作为目标 y 房价 有样本标签 特征，标签，用于训练 (x,y) 800个房屋信息 无标签样本 有特征,无标签 (x,?) 200个房屋信息不带房价 模型 样本的特征映射到预测标签 f(x) 通过特征信息确定房价的函数 模型中的参数 参数确定了机器学习的模型 f(x) f(x) = 3x+2中的3和2 模型的映射结果 通过模型获取到的无标签样本的标签 y’ 200个预测出来的房价 特征的维度指的是特征的数目,不同的数据维度有多有少，比如房屋面积就是特征，图片100px X 100px,每一个像素是一个特征，颜色通道有3个，那就是就3万个特征 标签就是机器学习要输出的结果 模型就是函数，就是执行预测的工具 机器学习项目结构 函数模型 评估函数的优劣 确定最优的函数 步骤一 步骤二 步骤三 步骤四 步骤五 问题的定义 数据的收集和预处理 模型的选择 选择机器学习模型 超参数调试和性能优化 问题的定义可以按照痛点,现状,目标来进行思考 数据的收集和预处理 可视化:通过分析工具或者Excel对数据有一个基本的了解 数据向量化:把原始数据格式化,让机器变得可以读取。将文字转为one-hot编码，类别变为0,1 处理坏数据和缺失值 特征缩放自行百度 特征工程和特征提取也就是选择最有价值的特性 图像识别 注意：改变格式，是因为keras要求图像数据集导入卷积网络模型为4阶张量,最后一阶代表颜色深度，灰度图像只有一个颜色通道，设置值为1，one-hot编码请自行百度 选择模型使用前先读https://blog.csdn.net/monk1992/article/details/89947267 2.0以下的版本 注意:以上代码包含2个2维卷积层,2个最大池化层,2个遗忘层,防止过度拟合.最后通过全连接层，通过分类器输出预测标签 最新版本的代码参考 12345678910111213141516171819import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersfrom tensorflow.keras.models import Sequential, load_modelmodel = tf.keras.Sequential()model.add(layers.Conv2D(32, (3, 3), activation='relu', # 添加Conv2D层 input_shape=(28,28,1))) # 指定输入数据样本张量的类型model.add(layers.MaxPooling2D(pool_size=(2, 2))) # 添加MaxPooling2D层model.add(layers.Conv2D(64, (3, 3), activation='relu')) # 添加Conv2D层model.add(layers.MaxPooling2D(pool_size=(2, 2))) # 添加MaxPooling2D层model.add(layers.Dropout(0.25)) # 添加Dropout层model.add(layers.Flatten()) # 展平model.add(layers.Dense(128, activation='relu')) # 添加全连接层model.add(layers.Dropout(0.5)) # 添加Dropout层model.add(layers.Dense(10, activation='softmax')) # Softmax分类激活，输出10维分类码# 编译模型model.compile(optimizer='rmsprop', # 指定优化器 loss='categorical_crossentropy', # 指定损失函数 metrics=['accuracy']) # 指定验证过程中的评估指标 训练机器,确定参数 通过训练可以看出accuracy代表训练集上的预测准确率,val_accuracy代表验证集上的预测准确率 关于超参数调试和性能优化 机器学习重在评估 机器训练的过程，对于模型内部参数的评估是通过损失函数进行的 机器训练结束后，还要进行验证。现在是指明使用accuracy，使用分类的准确率做为验证指标 k折验证将数据划分为大小相通的k个分区。每个分区打出的分数取平均分数。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
        <tag>快速进阶</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向用户开发界面(完结)]]></title>
    <url>%2F2021%2F03%2F11%2F2021-03-11-%E9%9D%A2%E5%90%91%E7%94%A8%E6%88%B7%E5%BC%80%E5%8F%91%E7%95%8C%E9%9D%A2(%E5%AE%8C%E7%BB%93)%2F</url>
    <content type="text"><![CDATA[面向用户开发界面1.使用functionView 2.使用class-basedView 使用functionView合理编排url根据上次的需求有博客首页,博文详情页,分类列表页，标签列表页，友链展示页 决定的url可以有: 博客首页:127.0.0.1:8080 博文详情页:127.0.0.1:8080/post/.html 分类列表页:127.0.0.1:8080/category// 标签列表页:127.0.0.1:8080/tag/ 友链展示页:127.0.0.1:8080/links 定义相关的url在urls.py中代码: 12345678910111213141516# view相当于视图控制层from blog.views import post_detail, post_listfrom config.views import linksurlpatterns = [ url(r'^admin/', custom_site.urls), url(r'^super_admin/',admin.site.urls), url(r'^$',post_list), # 代表定义了一个组，匹配后面的\d+ url(r'^category/(?P&lt;category_id&gt;\d+)/$',post_list), url(r'^tag/(?P&lt;tag_id&gt;\d+)/$',post_list), url(r'^post/(?P&lt;post_id&gt;\d+).html$',post_detail), url(r'^links/$',links)] 完整的url参数: url(正则表达式字符串,视图函数,固定参数,此url的名称) 编写相关View的代码1234567891011121314# Create your views here.from django.http import HttpResponse# 这个函数暂时现在可以处理种类和标签的请求def post_list(request, category_id=None,tag_id=None): content = 'post _list category_id=&#123;category_id&#125;, tag_id=&#123;tag_id&#125;'.format( category_id = category_id, tag_id = tag_id ) return HttpResponse(content)def post_detail(request, post_id): return HttpResponse('detail') render基础用法12345def post_list(request, category_id=None,tag_id=None): return render(request,'blog/list.html',context=&#123;'name':'post_list'&#125;)def post_detail(request, post_id): return render(request,'blog/detail.html',context=&#123;'name':'post_detail'&#125;) render一共6个参数: request对象 模版名称 字典类型数据,可以传递到模版中 页面编码类型 状态码 使用哪种模版引擎解析 配置模版 编写相应的页面和逻辑12345678910111213141516171819202122232425# 这个函数暂时现在可以处理种类和标签的请求def post_list(request, category_id=None,tag_id=None): if tag_id: try: tag = Tag.objects.get(id=tag_id) except Tag.DoesNotExist: post_list = [] else: post_list = tag.post_set.filter(status=Post.STATUS_NORMAL) # eles代表程序正常执行一样执行 # post_set是反向生成了一个外键名字叫xxx_set else: post_list = Post.objects.filter(status=Post.STATUS_NORMAL) if category_id: post_list = post_list.filter(category_id=category_id) return render(request,'blog/list.html',context=&#123;'post_list':post_list&#125;)def post_detail(request, post_id): try: post = Post.objects.get(id=post_id) except Post.DoesNotExist: post = None return render(request,'blog/detail.html',context=&#123;'post': post&#125;) 页面展示为 12345678910111213141516171819202122232425&lt;!--list.html --&gt;&lt;ul&gt;&#123;% for post in post_list %&#125;&lt;li&gt; &lt;a href="/post/&#123;&#123; post.id &#125;&#125;.html"&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt; &lt;div&gt; &lt;span&gt;作者:&#123;&#123; post.owner.username &#125;&#125;&lt;/span&gt; &lt;span&gt;分类:&#123;&#123; post.category.name &#125;&#125;&lt;/span&gt; &lt;/div&gt; &lt;p&gt;&#123;&#123; post.desc &#125;&#125;&lt;/p&gt;&lt;/li&gt;&#123;% endfor %&#125;&lt;/ul&gt;&lt;!--detail.html --&gt;&#123;% if post %&#125;&lt;h1&gt;&#123;&#123; post.title &#125;&#125;&lt;/h1&gt;&lt;div&gt; &lt;span&gt;作者:&#123;&#123; post.owner.username &#125;&#125;&lt;/span&gt; &lt;span&gt;分类:&#123;&#123; post.category.name &#125;&#125;&lt;/span&gt;&lt;/div&gt;&lt;hr/&gt;&lt;p&gt;&#123;&#123; post.content &#125;&#125;&lt;/p&gt;&#123;% endif %&#125; 重构页面视图可以在模型中构建api方法 12345678910111213141516171819202122232425262728@staticmethoddef get_by_tag(tag_id): try: tag = Tag.objects.get(id=tag_id) except Tag.DoesNotExist: tag = None post_list =[] else: post_list = tag.post_set.filter(status=Post.STATUS_NORMAL)\ .select_related('owner','category') return post_list, tag@staticmethoddef get_by_category(category_id): try: category = Category.objects.get(id=category_id) except Category.DoesNotExist: category = None post_list = [] else: post_list = category.post_set.filter(status=Post.STATUS_NORMAL)\ .select_related('owner','category')@classmethoddef latest_posts(cls): queryset = cls.Objects.filter(status=cls.STATUS_NORMAL) return queryset# 参考文章 https://blog.csdn.net/guanmaoning/article/details/106746740 123456789101112131415# 这个函数暂时现在可以处理种类和标签的请求def post_list(request, category_id=None,tag_id=None): tag = None category = None if tag_id: post_list, tag = Post.get_by_tag(tag_id) elif category_id: post_list, category = Post.get_by_category(category_id) else: post_list = Post.latest_posts() context = &#123; 'category': category, 'tag': tag, 'post_list': post_list &#125; 其余页面代码大同小异 关于注解属性的文章可以参考 https://zhuanlan.zhihu.com/p/64487092 关于渲染不同的数据到不同的页面中，可以参考一下代码： 123456789101112131415161718192021222324def content_html(self): """ 通过直接渲染模板 """ from blog.models import Post # 避免循环引用 from comment.models import Comment result = '' if self.display_type == self.DISPLAY_HTML: result = self.content elif self.display_type == self.DISPLAY_LATEST: context = &#123; 'posts': Post.latest_posts() &#125; result = render_to_string('config/blocks/sidebar_posts.html', context) elif self.display_type == self.DISPLAY_HOT: context = &#123; 'posts': Post.hot_posts() &#125; result = render_to_string('config/blocks/sidebar_posts.html', context) elif self.display_type == self.DISPLAY_COMMENT: context = &#123; 'comments': Comment.objects.filter(status=Comment.STATUS_NORMAL) &#125; result = render_to_string('config/blocks/sidebar_comments.html', context) return result 整理模版代码抽象基础模版抽象出base.html 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;博客系统&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;顶部分类: &#123;% for cate in navs %&#125; &lt;a href="/category/&#123;&#123; cate.id &#125;&#125;"&gt;&#123;&#123; cate.name&#125;&#125;&lt;/a&gt; &#123;% endfor %&#125;&lt;/div&gt;&lt;hr/&gt;&#123;% block main %&#125;&#123;% endblock %&#125;&lt;hr/&gt;&lt;div&gt;底部分类: &#123;% for cate in navs %&#125; &lt;a href="/category/&#123;&#123; cate.id &#125;&#125;"&gt;&#123;&#123; cate.name&#125;&#125;&lt;/a&gt; &#123;% endfor %&#125;&lt;/div&gt;&lt;div&gt;侧边栏展示:&#123;% for sidebar in sidebars %&#125;&lt;h4&gt;&#123;&#123; sidebar.title &#125;&#125;&lt;/h4&gt; &#123;&#123; sidebar.content_html &#125;&#125;&#123;% endfor %&#125;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 其余代码参考如下： 123456789101112131415161718192021222324&#123;% extends './base.html' %&#125;&#123;% block title %&#125;&#123;% if tag %&#125;标签页: &#123;&#123; tag.name&#125;&#125;&#123;% endif %&#125;&#123;% endblock %&#125;&#123;% block main %&#125;&#123;% if category %&#125;分类页: &#123;&#123; category.name&#125;&#125;&#123;% endif %&#125;&lt;ul&gt;&#123;% for post in post_list %&#125;&lt;li&gt; &lt;a href="/post/&#123;&#123; post.id &#125;&#125;.html"&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt; &lt;div&gt; &lt;span&gt;作者:&#123;&#123; post.owner.username &#125;&#125;&lt;/span&gt; &lt;span&gt;分类:&#123;&#123; post.category.name &#125;&#125;&lt;/span&gt; &lt;/div&gt; &lt;p&gt;&#123;&#123; post.desc &#125;&#125;&lt;/p&gt;&lt;/li&gt;&#123;% endfor %&#125;&lt;/ul&gt;&#123;% endblock %&#125; 关于url解耦123url(r&apos;^post/(?P&lt;post_id&gt;\d+).html$&apos;,post_detail name=&apos;post-detail&apos;),&lt;a href=&quot;&#123;% url &apos;post-detail&apos; post.id %&#125;&quot;&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt; 使用class-based viewhttps://www.cnblogs.com/donghaiming/p/11007505.html 分页参考代码如下 https://blog.csdn.net/bibinGee/article/details/104859388 关于类视图 当然可以查阅书籍159-163 https://blog.csdn.net/pyrans/article/details/82763314 使用静态资源参考 https://www.cnblogs.com/sch01ar/p/11508002.html 关于django定义中间件 关于restframwork和一些其他的包插件等，可以到官方市场和博客中查阅 感言关于django，一个项目需要流程化，比如工作流等特别定制等，除此之外基本都可以考虑使用djangoAdmin来解决 关于django的学习成本主要在djangoAdmin和ORM上。如果需要自行画页面就需要加上django的模版 关于部署和java保持一致。加载类似tomcat的服务器。然后用nginx做分流]]></content>
      <categories>
        <category>django开发</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web开发</tag>
        <tag>快速构建</tag>
        <tag>ORM</tag>
        <tag>日志管理</tag>
        <tag>管理后台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发django管理后台]]></title>
    <url>%2F2021%2F02%2F22%2F2021-02-22-django%E5%90%8E%E5%8F%B0%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[开发django管理后台 配置admin进行操作 定制admin 复用admin 配置admin进行操作关于django的站点可以参考 采用文档的原话：管理有很多用于定制的钩子，但要注意不要试图专门使用这些钩子。如果您需要提供一个更以流程为中心的接口，抽象掉数据库表和替代的实现细节，那么可能是时候编写自己的视图了 编写blogAdmin代码123456789101112131415161718from django.contrib import admin# Register your models here.from .models import Post, Category, Tag# 注册管理模型@admin.register(Category)class CategoryAdmin(admin.ModelAdmin): # 用于在更改列表中显示更改哪些字段 list_display = ('name','status','is_nav','create_time') # 使用该fields选项可以在“添加”和“更改”页面上的表单中进行简单的布局更改 fields = ('name','status','is_nav')@admin.register(Tag)class TagAdmin(admin.ModelAdmin): list_display = ('name','status','create_time') fields = ('name','status') 接下激活虚拟环境 执行命令 123manage.py createsuperuser# 启动服务 输入:地址/adminmanage.py runserver 修复小bug因为我们的模型都是有关联作者的，这个时候实际上fields上面是缺少作者选项的。添加进去就可以了。但是会存在任何作者把创建的内容改为任意作者。这个时候我们需要重写savemodel方法，引用官方文档说明: 修改代码后如下: 12345678910111213141516171819202122232425262728from django.contrib import admin# Register your models here.from .models import Post, Category, Tag# 注册管理模型@admin.register(Category)class CategoryAdmin(admin.ModelAdmin): # 用于在更改列表中显示更改哪些字段 list_display = ('name','status','is_nav','create_time') # 使用该fields选项可以在“添加”和“更改”页面上的表单中进行简单的布局更改 fields = ('name','status','is_nav') def save_model(self, request, obj, form, change): # request获取的是当前已经登录的用户 obj就是对应的注册的模型 obj.owner = request.user return super(CategoryAdmin,self).save_model(request, obj, form, change)@admin.register(Tag)class TagAdmin(admin.ModelAdmin): list_display = ('name','status','create_time') fields = ('name','status') def save_model(self, request, obj, form, change): obj.owner = request.user return super(TagAdmin,self).save_model(request, obj, form, change) 运行结果如下: 对于django2.1下没有查看的权限可以参考https://blog.csdn.net/u011519550/article/details/100171861 同时:如果只想看到自己建立的数据可以: 细致的配置post管理后台1.先说2个东西 1234# 一个可以用来解析视图甚至admin，从url中寻找路径from django.urls import reverse# 格式化一段html代码from django.utils.html import format_html 2.增加以下代码 1234567891011121314151617181920212223242526272829303132333435363738394041@admin.register(Post)class PostAdmin(admin.ModelAdmin): # 更改列表显示的字段,这里的operator是自定义的方法格式化了一段html代码 list_display = [ 'title', 'category', 'status', 'create_time','operator' ] # 用来配置哪些字段可以作为链接。点击它们就可以进入编辑页面 list_display_links = [] # 配置页面过滤器,意味着可以通过种类的值对数据进行过滤 list_filter = ['category',] # 配置可以搜索的字段 search_fields = ['title', 'category__name'] # 动作相关的配置 actions_on_top = True actions_on_bottom = True # 编辑页面 save_on_top = True fields = ( ('category', 'title'), 'desc', 'status', 'content', 'tag', ) def operator(self, obj): return format_html( '&lt;a href="&#123;&#125;"&gt;编辑&lt;/a&gt;', reverse('admin:blog_post_change',args=(obj.id,)) # 这里就是从url中寻找地址 ) operator.short_description = '操作' def save_model(self, request, obj, form, change): obj.owner = request.user return super(TagAdmin,self).save_model(request, obj, form, change) 同理如果我们要增加分类下面有多少文章可以 1234def post_count(self, obj): return obj.post_set.count()post_count.short_description = '文章数量' 还有一个问题我们要显示文案的名字需要重写 str方法 每个model需要重写此方法 12def __str__(self): return self.name 展示为: 照猫画虎(comment与和config) comment 123456789from django.contrib import adminfrom .models import Comment# Register your models here.@admin.register(Comment)class CommentAdmin(admin.ModelAdmin): list_display = ('target', 'nickname', 'content', 'website', 'create_time') config 12345678910111213141516171819202122232425from django.contrib import adminfrom .models import Link, SideBar# Register your models here.@admin.register(Link)class LinkAdmin(admin.ModelAdmin): list_display = ('title', 'href', 'status', 'weight', 'create_time') fields = ('title', 'href', 'status', 'weight') def save_model(self, request, obj, form, change): obj.owner = request.user return super(LinkAdmin,self).save_model(self, request, obj, form, change)@admin.register(SideBar)class SideBarAdmin(admin.ModelAdmin): list_display = ('title', 'display_type', 'content', 'create_time') fields = ('title', 'diplay_type', 'content') def save_model(self, request, obj, form, change): obj.owner = request.user return super(SideBarAdmin,self).save_model(self, request, obj, form, change) 最后效果如下: admin定制自定义过滤器只能过滤当前用户的文章，代码如下：在PostAdmin上面添加 12345678910111213class CategoryOwnerFilter(admin.SimpleListFilter): '''自定义过滤器只展示当前用户分类''' title = '分类过滤器' parameter_name = 'owner_category' def lookups(self, request, model_admin): return Category.objects.filter(owner=request.user).values_list('id', 'name') def queryset(self,request,queryset): category_id = self.value() if category_id: return queryset.filter(category_id=self.value()) return queryset 解释说明: title: 用于展示标题 parameter_name: 查询时url参数的名字相当于?owner_category=1,可以根据配置简答的过滤器来观察参数 lookups： 返回要展示的内容和查询用的id queryset： 根据url Query的内ring返回列表页数据。 ?owner_category=1 那么self.value就是1 列表数据过滤解决用户在列表页只看到自己创建的文章 在PostAdmin中重写get_queryset方法 123def get_queryset(self, request): qs = super(PostAdmin,self).get_queryset(request) return qs.filter(owner=request.user) admin编辑页面配置1exclude = ('owner',) # 可以用于排除不需要什么样的字段 fieldsets控制页面布局12345678910111213141516171819fieldsets = ( ('基础配置',&#123; 'description': '基础配置描述', 'fields': ( ('title', 'category'), 'status' ) &#125;), ('内容',&#123; 'fields':( 'desc', 'content' ), &#125;), ('额外信息',&#123; 'classes': ('collapse',), 'fields': ('tag', ) &#125;)) 自定义静态资源引入在PostAdmin下: 12345class Media: css = &#123; "all": ("https://cdn.bootcss.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css",) &#125; js = ("https://cdn.bootcss.com/bootstrap/4.0.0-beta.2/js/bootstrap.bundle.js",) 自定义form利用modelForm可以定制，比如文章描述字段希望是textarea Form是和model耦合在一起的。Form的逻辑和model是一致的,model是对数据库字段的抽象，form是对用户输入以及model展示数据的抽象 123456789from django import formsclass PostAdminForm(forms.ModelForm): desc = forms.CharField(widget=forms.Textarea, label='摘要', required=False)@admin.register(Post)class PostAdmin(admin.ModelAdmin): form = PostAdminForm '''其余省略''' 同一页面编辑关联数据分类下面可以编辑文章 12345678910class PostInline(admin.TabularInline): # 也有stackedInline fields = ('title', 'desc') extra = 1 # 这控制了表单集除初始表单外还将显示的其他表单的数量。默认值为3 model = Post# 注册管理模型@admin.register(Category)class CategoryAdmin(admin.ModelAdmin): inlines = [PostInline,] '''其余省略''' 定制站点讲文章分类等数据的管理与用户模块等分开 定义一个custom_site.py 12345678from django.contrib.admin import AdminSiteclass CustomSite(AdminSite): site_header = 'djwwj' site_title = 'djwwj管理后台' index_title = '首页'custom_site = CustomSite(name='cus_admin') PostAdmin中修改为 12345from djwwj.custom_site import custom_site@admin.register(Post, site=custom_site)# 以及调整链接reverse('cus_admin:blog_post_change',args=(obj.id,)) # 这里就是从url中寻找地址 /admin/blog/post/1/change/ ) 最后更改url 123456from .custom_site import custom_siteurlpatterns = [ url(r'^admin/', custom_site.urls), url(r'^super_admin/',admin.site.urls)] 其实就是通过两套url对业务进行了划分 权限和用户用户以及权限可以参考文档 https://zhuanlan.zhihu.com/p/26188198 https://docs.djangoproject.com/zh-hans/3.1/topics/auth/default/ https://docs.djangoproject.com/zh-hans/3.1/topics/auth/customizing/ 操作日志如果是大型项目针对业务可以参考 https://www.cnblogs.com/gaosai/p/10322924.html 关于自带的LogEntry 参考https://www.wandouip.com/t5i330704/ 12345from django.contrib.admin.models import LogEntry@admin.register(LogEntry, site=custom_site)class LogEntryAdmin(admin.ModelAdmin): list_display = ['object_repr','object_id','action_flag','user','change_message']]]></content>
      <categories>
        <category>django开发</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web开发</tag>
        <tag>快速构建</tag>
        <tag>ORM</tag>
        <tag>日志管理</tag>
        <tag>管理后台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发之规范和细节]]></title>
    <url>%2F2021%2F02%2F20%2F2021-02-20-django%E5%BC%80%E5%8F%91%E4%B9%8B%E8%A7%84%E8%8C%83%E5%92%8C%E7%BB%86%E8%8A%82%2F</url>
    <content type="text"><![CDATA[·django开发之规范和细节 编码规范 项目准备 model层字段介绍 编码规范12345678910111213141516171819Beautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren&apos;t special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one-- and preferably only one --obvious way to do it.Although that way may not be obvious at first unless you&apos;re Dutch.Now is better than never.Although never is often better than *right* now.If the implementation is hard to explain, it&apos;s a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea -- let&apos;s do more of those! 适当的缩进 优选空格 适当的长度 项目准备构建虚拟环境在某盘某个目录下执行命令: 1python -m venv typeidea-env 激活环境 1234D:\Envs\typeidea-env&gt;cd ScriptsD:\Envs\typeidea-env\Scripts&gt;activate.bat## 在其目录下安装djangopip install Django==1.11 构建项目 1234(typeidea-env) D:\Envs\typeidea-env\Scripts&gt;cd ..(typeidea-env) D:\Envs\typeidea-env&gt;mkdir typeidea(typeidea-env) D:\Envs\typeidea-env&gt;cd typeidea(typeidea-env) D:\Envs\typeidea-env\typeidea&gt;django-admin startproject typeidea 关于项目依赖 12##启动项目 报错参考https://www.pianshen.com/article/82141167778/python manage.py runserver 拆分setting适应不同的环境构建settings文件夹.目录结构如下 注意:base.py基于外部的settings.py文件 新增develop配置文件如上图所示，最后修改manage.py和wsgi.py识别新的配置文件 123## os.environ.setdefault("DJANGO_SETTINGS_MODULE", "djwwj.settings")profile = os.environ.get('TYPEIDEA_PROFILE','develop')os.environ.setdefault("DJANGO_SETTINGS_MODULE", "djwwj.settings.%s" % profile) 并且设置一个环境变量 TYPEIDEA_PROFILE = developvscode设置django参考 编写model层代码 在django中有一个app应用的概念。每个app应该是一个自组织的应用。可以根据model的业务性质分别进行处理 根据上面的规划：model可以划分blog相关，配置相关，评论相关 构建blog App执行命令 1(typeidea-env) D:\Envs\typeidea-env\typeidea\djwwj&gt;manage.py startapp blog blog相关的model分类大概有种类，标签以及帖子，构建的model如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970from django.db import models# user来源自django自带的认证中form django.contrib.auth.models import User# Create your models here.# 种类类class Category(models.Model): # 状态申明 STATUS_NORMAL = 1 STATUS_DELETE = 0 STATUS_ITEMS = ( (STATUS_NORMAL,'正常'), (STATUS_DELETE,'删除') ) # 字段申明 name = models.CharField(max_length=50, verbose_name='名称') # 正整数或0类型 PositiveIntegerField status = models.PositiveIntegerField(default=STATUS_NORMAL,choices=STATUS_ITEMS, verbose_name='状态') is_nav = models.BooleanField(default=False, verbose_name='是否为导航') # 外键表明的是多对一 参考文章:https://blog.csdn.net/hpu_yly_bj/article/details/78939748 owner = models.ForeignKey(User, verbose_name='作者') create_time = models.DateTimeField(auto_now_add=True, verbose_name='创建时间') # 每个类都有一个源类型可以配置 class Meta: verbose_name = verbose_name_plural = '分类'# 标签类class Tag(models.Model): # 状态申明 STATUS_NORMAL = 1 STATUS_DELETE = 0 STATUS_ITEMS = ( (STATUS_NORMAL,'正常'), (STATUS_DELETE,'删除') ) # 字段申明 name = models.CharField(max_length=10, verbose_name='名称') status = models.PositiveIntegerField(default=STATUS_NORMAL,choices=STATUS_ITEMS, verbose_name='状态') owner = models.ForeignKey(User, verbose_name='作者') create_time = models.DateTimeField(auto_now_add=True, verbose_name='创建时间') class Meta: verbose_name = verbose_name_plural = '标签' # 帖子class Post(models.Model): # 状态申明 STATUS_NORMAL = 1 STATUS_DELETE = 0 STATUS_ITEMS = ( (STATUS_NORMAL,'正常'), (STATUS_DELETE,'删除') ) # 字段申明 title = models.CharField(max_length=255 , verbose_name='标题') desc = models.CharField(max_length=1024, verbose_name='摘要') content = models.TextField(verbose_name='正文' help_text='正文必须为Markdown格式') status = models.PositiveIntegerField(default=STATUS_NORMAL,choices=STATUS_ITEMS, verbose_name='状态') category = models.ForeignKey(Category, verbose_name='分类') # 一个帖子对应多个标签,一个标签对应多个帖子 tag = models.ManyToManyField(Tag, verbose_name='标签') owner = models.ForeignKey(User, verbose_name='作者') create_time = models.DateTimeField(auto_now_add=True, verbose_name='创建时间') class Meta: verbose_name = verbose_name_plural = '文章' # 排序可以参考 https://blog.csdn.net/old_man31/article/details/86377988 ordering = ['-id'] # 根据id进行降序排序 注意:上面总体构建的步骤就是规划模型—–&gt;设计模型——&gt;构建模型 构建config App同理我们构建配置选项，model里面主要是连接和侧边栏 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from django.db import modelsfrom django.contrib.auth.models import User# Create your models here.# 连接类class Link(models.Model): # 状态申明 STATUS_NORMAL = 1 STATUS_DELETE = 0 STATUS_ITEMS = ( (STATUS_NORMAL,'正常'), (STATUS_DELETE,'删除') ) # 字段申明 title = models.CharField(max_length=50, verbose_name='标题') href = models.URLField(verbose_name='链接') status = models.PositiveIntegerField(default=STATUS_NORMAL,choices=STATUS_ITEMS, verbose_name='状态') weight = models.PositiveIntegerField(default=1, choices=zip(range(1,6),range(1,6)), verbose_name='权重', help_text='权重高展示顺序靠前') owner =models.ForeignKey(User, verbose_name='作者') create_time = models.DateTimeField(auto_now_add=True, verbose_name='创建时间') class class Meta: verbose_name = verbose_name_plural = '友链'# 侧边栏class SideBar(models.Model): STATUS_SHOW = 1 STATUS_HIDE = 0 STATUS_ITEMS = ( (STATUS_SHOW, '展示'), (STATUS_HIDE, '隐藏') ) SIDE_TYPE = ( (1, 'HTML'), (2, '最新文章'), (3, '最热文章'), (4, '最热评论') ) # 申明字段 title = models.CharField(max_length=50, verbose_name='标题') display_type = models.PositiveIntegerField(default=1, choices=SIDE_TYPE, verbose_name='展示类型') content = models.CharField(max_length=500, blank=True, verbose_name='内容', help_text='设置不为HTML类型,可为空') status = models.PositiveIntegerField(default=STATUS_SHOW, choices=STATUS_ITEMS, verbose_name='状态') owner = models.ForeignKey(User, verbose_name='作者') create_time = models.DateTimeField(auto_now_add=True, verbose_name='创建时间') class class Meta: verbose_name = verbose_name_plural = '侧边栏' 构建comment App在这里暂时将评论和文章耦合起来。当然以后可以独立出来 123456789101112131415161718192021222324252627from django.db import models# 和文章耦合起来from blog.models import Post# Create your models here.#评论类class Comment(models.Model): # 状态申明 STATUS_NORMAL = 1 STATUS_DELETE = 0 STATUS_ITEMS = ( (STATUS_NORMAL,'正常'), (STATUS_DELETE,'删除') ) # 申明字段 target = models.ForeignKey(Post, verbose_name='评论目标') content = models.CharField(max_length=2000, verbose_name='内容') nickname = models.CharField(max_length=50, verbose_name='昵称') website = models.URLField(verbose_name= '网站') email = models.EmailField(verbose_name= '邮箱') status = models.PositiveIntegerField(default=STATUS_NORMAL, choices=STATUS_ITEMS, verbose_name='状态') create_time = models.DateTimeField(auto_now_add=True, verbose_name='创建时间') class class Meta: verbose_name = verbose_name_plural = '评论' 到此3个model类型构建完毕。还有值得修改的地方 一系列流程在installedapps添加 文件在bast.py 1234567891011INSTALLED_APPS = [ 'blog', 'config', 'comment', 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles',] 在djwwj目录下执行数据库迁移的操作 12345manage.py makemigrationsmanage.py migrate# sqlite3如果看不到，可以参考https://blog.csdn.net/foryouslgme/article/details/52034149# 可以将文件放到djwwj目录下来查看manage.py dbshell model层说明常用的字段类型 数值型 1.AutoField 自增主键,可以被重写 2.BooleanField 布尔类型字段,一般记录状态标记 3.DecimalField decima 数据精度比较高的字段。注意需要在python中使用Decimal类型进行转换 4.IntegerField 整数字段,不自增 5.PostiveIntegerField 只包含正整数 6.SmallIntegerField smallint 小整数 字符型 1.CharField 基础的varchar类型 2.UrlField 对url的特殊处理 3.UUIDField 存放唯一id 4.EmailField 对email的处理 5.FileField 对文件的特殊处理,在admin展示可以自动生成一个上传文件的按钮 6.TextField 存放正文类容 7.ImageField 处理图片相关的数据 日期类型 分别为DateField 和 DateTimeField 以及 TimeField 就不在细说了 关系类型 ForeignKey 多对一 OneToOneField 一对一 以及 ManyToManyField 多对多 1# 可以参考文章https://www.cnblogs.com/navysummer/p/10200154.html 字段参数类型1.null 空类型 2.blank 不能为空 3.choices可选项 4.db_column对应数据库字段类型 5.db_index 索引配置 6.default 默认配置 7.editable 是否可编辑 8.error_messages 检查异常是提示 9.help_text 字段提示语 10.primary_key 主键设置 11.unique 唯一约束 12.unique_for_data/month/year 可以针对日期，月和年的约束 13.verbose_name 字段展示相应的文案 14.validators 自定义逻辑校验 QuerySet的使用QuerySet的主要作用是数据库的所有查询以及有更新的交互都是需要这个来完成的 在model层中django提供了一个objects属性来提供数据操作的接口。并且支持链式操作，同时queryset是懒加载的 常用的接口支持链式调用1.all接口等于查询所有 2.filter接口根据条件过滤数据 3.exclude根据条件排除之外，和filter相反 4.reverse接口 结果倒序 5.distinct 去重查询 6.none接口 返回空 不支持链式调用1.get接口根据条件进行查询 2.create接口创建一个model对象 3.get_or_create根据条件进行查找,没有就创建 4.update_or_create 根据条件更新没有就创建 5.lastest接口返回最新的记录 6.earliest接口获取第一个记录 7.last接口获取最后一条 8.exists 返回布尔值.判断是否存在 9.bulk_create接口 批量创建记录 10.in_bluk 批量查询 11.update接口 批量更新 12.delete接口 批量删除 13.values接口 明确只需要某个返回字段值，不需要实例时 14 values_list接口 返回的是元组的queryset 进阶接口defer 不需要的字段做延迟加载，但是在循环查询中会产生N+1，重复查询的问题 only接口 与defer相反 select_related 关联查询 针对一对多 也可以解决N+1的问题 prefetch_related 关联查询 针对多对多的 常用的字段查询针对QuerySet 方法 filter()、exclude() 和 get() 的关键字参数。 contains 包含相似查询 icontains 同上，忽略大小写 exact 精确匹配 in 指定某个集合 gt 大于 gte 大于等于 lt 小于 lte 小于等于 startswith endwith 以什么开始，什么结尾 range 用于时间范围查找 进阶查询F 用来保证数据避免出现竞争状态 保证数据的原子性 Q 执行and 或者 or 的复杂表达式 聚合运算可以参考文档也可以 使用annotate() 执行更简便的操作 执行原生sql可以通过raw接口来执行]]></content>
      <categories>
        <category>django开发</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web开发</tag>
        <tag>快速构建</tag>
        <tag>ORM</tag>
        <tag>模型设计</tag>
        <tag>查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ消息队列]]></title>
    <url>%2F2021%2F01%2F26%2F2021-01-26-RabbitMQ%2F</url>
    <content type="text"><![CDATA[RabbitMQ消息队列 消息队列的概念 windows下面安装RabbitMQ RabbitMQ的初步使用 RabbitMQ的几种模式 springboot整合RabbitMQ 关于持久化操作,消息确认(自动和手动)，事务管理 消息队列的概念首先消息队列是应用程序之间的一种通信办法,其次，在应用程序中可以将一些无需及时返回的以及耗时的业务提取出来,通过异步的方式,当然异步的方式主要就是节省了服务器的响应时间，从而提高系统的吞吐量 消息队列的应用场景一般在应用解耦、异步处理(提高系统响应速度)、流量削峰(高峰堆积消息，峰后继续处理消息)、日志处理、通讯上面。 消息队列模型(AMQP和JMS)AMQP高级消息队列协议，是一个进程间传递异步消息的网络协议，更准确的说是一种binary wire-level protocol（链接协议）。这是其和JMS的本质差别，AMQP不从API层进行限定，而是直接定义网络交换的数据格式. JMS即Java消息服务（JavaMessage Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 注意:JMS是定义了统一的接口，来对消息操作进行统一；AMQP是通过规定协议来统一数据交互的格式,JMS限定了必须使用Java语言；AMQP只是协议，不规定实现方式，因此是跨语言的。JMS规定了两种消息模式；而AMQP的消息模式更加丰富,简单的说就好比一个是已经开发好的应用,一个定义了一系列的标准。 关于消息队列的产品 kafka Apache下的一个子项目，使用scala实现的一个高性能分布式Publish/Subscribe消息队列系统。 快速持久化：通过磁盘顺序读写与零拷贝机制，可以在O(1)的系统开销下进行消息持久化 高吞吐：在一台普通的服务器上既可以达到10W/s的吞吐速率 高堆积：支持topic下消费者较长时间离线，消息堆积量大； 完全的分布式系统：Broker、Producer、Consumer都原生自动支持分布式，依赖zookeeper自动实现复杂均衡 rabbitmq RocketMQ是一款分布式、队列模型的消息中间件，具有以下特点 ： 能够保证严格的消息顺序,提供丰富的消息拉取模式 高效的订阅者水平扩展能力.实时的消息订阅机制 支持事务消息，亿级消息堆积能力. 生产者不会将消息直接发送给队列，消息在发送给客户端时先在中心队列排队。对路由(Routing)，负载均衡(Load balance)、数据持久化都有很好的支持 支持的模式有以下(来源于官网): windows下面安装RabbitMQ因为RabbitMQ基于erlang语言,所以首先先安装erlang语言，安装过程主要为 下载并安装erlang语言，配置相应的环境变量。CMD执行 1erl # 截图如下 2.下载并安装rabbitmq,然后在sbin目录下执行 12rabbitmq-plugins enable rabbitmq_management # 截图如下rabbitmq-plugins disable rabbitmq_management # 该命令为关闭 3.在此目录下查看rabbitmq状态 1rabbitmqctl status # 截图如下 4.输入地址http://localhost:15672/ 默认账户密码guest 关于用户 角色说明： 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker)可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management)仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 关于 Virtual Hosts配置Virtual Hosts就是虚拟主机的意思.相当于一个独立的数据库，数据库之间不受影响.一般以/开头 当然同理可以不同的用户能访问的虚拟注意不一样 RabbitMQ的初步使用1.创建一个maven项目,pom.xml文件如下 12345678910111213&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.创建生产者和消费者都需要提供一个连接对象。先封装一下 123456789101112131415161718192021222324252627282930313233import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;public class Util &#123; public static Connection getConnection() throws Exception&#123; //1、创建链接工厂对象 ConnectionFactory factory = new ConnectionFactory(); //2、设置RabbitMQ服务主机地址 factory.setHost("localhost"); //3、设置RabbitMQ服务端口 factory.setPort(5672); //4、设置虚拟主机名字，默认/-factory.setVirtualHost("szitheima") factory.setVirtualHost("/test"); //5、设置用户连接名 factory.setUsername("guest"); //6、设置链接密码 factory.setPassword("guest"); //7、创建链接 Connection connection = factory.newConnection(); return connection; &#125; public static void main(String[] args) &#123; try &#123; Connection con = Util.getConnection(); System.out.println("连接成功"); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 结果如下: RabbitMQ的几种模式模式一简单发送消息生产者:也就是要发送消息的程序. 消费者：消息的接受者，会一直等待消息到来. 消息队列:生产者向其中投递消息，消费者从其中取出消息. 生产者代码如下： 1234567891011121314public class P &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); //定义队列.分别对应名字,持久化,独占连接,自动删除,附加参数 channel.queueDeclare("hello1",true,false,false,null); //构建消息 String message = "第一条消息"; //分别对应交换机,路由值,其他参数,消息主题 channel.basicPublish("","hello1",null,message.getBytes("utf-8")); channel.close(); con.close(); &#125;&#125; 可以看到有一条消息待读 消费者代码如下: 12345678910111213141516171819202122232425262728293031323334353637import java.io.IOException;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope;import com.rabbitmq.client.AMQP.BasicProperties;import com.wwj.util.Util;public class C &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); channel.queueDeclare("hello1",true,false,false,null); Consumer c = new DefaultConsumer(channel) &#123; //重写处理传递的方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String routingKey = envelope.getRoutingKey(); String exchange = envelope.getExchange(); long deliveryTag = envelope.getDeliveryTag(); String message = new String(body,"utf-8"); System.out.println( "routingKey:" + routingKey + ",exchange:" + exchange + ",deliveryTag:" + deliveryTag + ",message:" + message); &#125;; &#125;; //创建消费者 分别对应主题,应答策略,消费者回调方法 channel.basicConsume("hello1",true,c); //如果不关闭.消费者一直存在 &#125;; &#125; 以下可以看到消息在被读取后就删除了,消费者一直挂起中 模式二多个消费者(有竞争关系的)生产者代码如下: 1234567891011121314151617181920import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.wwj.util.Util;public class P &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); //定义队列.分别对应名字,持久化,独占连接,自动删除,附加参数 channel.queueDeclare("hello1",true,false,false,null); //构建10条消息 for (int i = 1; i &lt; 11; i++) &#123; String message = "第"+i+"条消息"; //分别对应交换机,路由值,其他参数,消息主题 channel.basicPublish("","hello1",null,message.getBytes("utf-8")); &#125; channel.close(); con.close(); &#125;&#125; 构建多个消费者，代码一样，参照模式一 先启动消费者，然后启动生产者，观察 相当于10个相同的任务,被雇佣的2个员工分担了 模式三(发布订阅模式)注意：生产者是通过发布消息是通过交换机传递到队列中 关于交换机的说明 交换机，。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有常见以下3种类型： ​ Fanout：广播，将消息交给所有绑定到交换机的队列 ​ Direct：定向，把消息交给符合指定routing key 的队列 ​ Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 生产者代码如下: 123456789101112131415161718192021import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.wwj.util.Util;public class P &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); //改为定义交换机 channel.exchangeDeclare("exchange1", BuiltinExchangeType.FANOUT); //构建10条消息 for (int i = 1; i &lt; 11; i++) &#123; String message = "第"+i+"条消息"; //分别对应交换机,路由值,其他参数,消息主题 channel.basicPublish("exchange1","",null,message.getBytes("utf-8")); &#125; channel.close(); con.close(); &#125;&#125; 消费者代码如下: 1234567891011121314151617181920212223242526272829303132333435363738import java.io.IOException;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope;import com.rabbitmq.client.AMQP.BasicProperties;import com.wwj.util.Util;public class C1 &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); channel.queueDeclare("q1",true,false,false,null); //通过绑定的方式将主题绑定到交换机中 channel.queueBind("q1", "exchange1", ""); Consumer c = new DefaultConsumer(channel) &#123; //重写处理传递的方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String routingKey = envelope.getRoutingKey(); String exchange = envelope.getExchange(); long deliveryTag = envelope.getDeliveryTag(); String message = new String(body,"utf-8"); System.out.println( "routingKey:" + routingKey + ",exchange:" + exchange + ",deliveryTag:" + deliveryTag + ",message:" + message); &#125;; &#125;; //创建消费者 分别对应主题,应答策略,消费者回调方法 channel.basicConsume("q1",true,c); //如果不关闭.消费者一直存在 &#125;;&#125; 同样启动消费者,然后观察结果 可以看到消费者都消费了10条消息。q1和q2主题绑定在了同一个交换机上面 模式四(有选择性的接收)主要是在exchange交换上加上了路由值。可以将路由值理解为分类值 生产者代码如下： 123456789101112131415161718192021222324252627282930313233343536import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.wwj.util.Util;public class P &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); //需要将交换机类型改为定向 channel.exchangeDeclare("exchange1", BuiltinExchangeType.DIRECT); //构建10条消息 for (int i = 1; i &lt; 4; i++) &#123; String message = "第"+i+"条消息"; //定义分类值 String rk = ""; //代表rk为不同的类型 switch (i)&#123; case 1: rk = "apple"; break; case 2: rk = "huawei"; break; case 3: rk = "xiaomi"; break; &#125; //分别对应交换机,路由值,其他参数,消息主题 channel.basicPublish("exchange1",rk,null,message.getBytes("utf-8")); &#125; channel.close(); con.close(); &#125;&#125; 消费者代码如下：消费者1消费apple 消费者2消费huawei和xiaomi 12345678910111213141516171819202122232425262728293031323334353637import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope;import com.rabbitmq.client.AMQP.BasicProperties;import com.wwj.util.Util;public class C2 &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); channel.queueDeclare("q2",true,false,false,null); //通过绑定的方式将主题绑定到交换机中 channel.queueBind("q2", "exchange1", "huawei"); channel.queueBind("q2", "exchange1", "xiaomi"); Consumer c = new DefaultConsumer(channel) &#123; //重写处理传递的方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String routingKey = envelope.getRoutingKey(); String exchange = envelope.getExchange(); long deliveryTag = envelope.getDeliveryTag(); String message = new String(body,"utf-8"); System.out.println( "routingKey:" + routingKey + ",exchange:" + exchange + ",deliveryTag:" + deliveryTag + ",message:" + message); &#125;; &#125;; //创建消费者 分别对应主题,应答策略,消费者回调方法 channel.basicConsume("q2",true,c); //如果不关闭.消费者一直存在 &#125;;&#125; 同样观察结果 可以不同的类别分发到了不同主题中 模式伍(基于特定规则的接收)在模式四的基础上，增加了通配符，也就是类别可以无限细化.因为routingkey 一般都是有一个或多个单词组成，多个单词之间以“ . ”分割 #：匹配一个或多个词 *：匹配不多不少恰好1个词 比如item.#：能够匹配item.insert.abc 或者 item.insert,item.*：只能匹配item.insert 生产者代码如下: 1234567891011121314151617181920212223242526272829303132333435363738import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.wwj.util.Util;public class P &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); //需要将交换机类型改为主题 channel.exchangeDeclare("exchange1", BuiltinExchangeType.TOPIC); //构建10条消息 for (int i = 1; i &lt; 5; i++) &#123; String message = "第"+i+"条消息"; //定义分类值 String rk = ""; //代表rk为不同的类型 switch (i)&#123; case 1: rk = "apple"; break; case 2: rk = "huawei"; break; case 3: rk = "xiaomi"; break; case 4: rk = "huawei.rongyao"; break; &#125; //分别对应交换机,路由值,其他参数,消息主题 channel.basicPublish("exchange1",rk,null,message.getBytes("utf-8")); &#125; channel.close(); con.close(); &#125;&#125; 消费者如下: 1234567891011121314151617181920212223242526272829public class C2 &#123; public static void main(String[] args) throws Exception &#123; Connection con = Util.getConnection(); Channel channel = con.createChannel(); channel.queueDeclare("q2",true,false,false,null); //通过绑定的方式将主题绑定到交换机中 channel.queueBind("q2", "exchange1", "huawei.#"); channel.queueBind("q2", "exchange1", "xiaomi"); Consumer c = new DefaultConsumer(channel) &#123; //重写处理传递的方法 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String routingKey = envelope.getRoutingKey(); String exchange = envelope.getExchange(); long deliveryTag = envelope.getDeliveryTag(); String message = new String(body,"utf-8"); System.out.println( "routingKey:" + routingKey + ",exchange:" + exchange + ",deliveryTag:" + deliveryTag + ",message:" + message); &#125;; &#125;; //创建消费者 分别对应主题,应答策略,消费者回调方法 channel.basicConsume("q2",true,c); //如果不关闭.消费者一直存在 &#125;;&#125; 观察结果 Springboot整合RabbitMQ创建springboot项目pom.xml如下： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;srb&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 分别在src/main/java下构建启动程序 123456789101112131415161718192021@SpringBootApplicationpublic class App &#123; public static void main(String[] args)&#123; SpringApplication.run(App.class, args); &#125;&#125;@RestControllerpublic class TController &#123; @RequestMapping("t") public String t() &#123; return "ok"; &#125;&#125;server.port=8032 整合RabbitMQ添加依赖 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 修改springboot的配置文件 123456789101112#rabbitmq连接参数spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest# 开启发送确认spring.rabbitmq.publisher-confirms=true# 开启发送失败退回spring.rabbitmq.publisher-returns=true# 开启ACKspring.rabbitmq.listener.direct.acknowledge-mode=manualspring.rabbitmq.listener.simple.acknowledge-mode=manual 初始化交换机和主题 123456789101112131415161718192021222324252627282930313233343536373839404142434445import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.Queue;import org.springframework.amqp.core.TopicExchange;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitConfig &#123; /** * 队列可以设置以下参数 * durable: 是否持久化；exclusive: 是否独享、排外的；autoDelete: 是否自动删除 * @return */ @Bean public Queue firstQueue() &#123; return new Queue("q1"); &#125; @Bean public Queue secondQueue() &#123; return new Queue("q2"); &#125; //具体用什么模式在这里定义不同的交换机类型 FanoutExchange DirectExchange TopicExchange @Bean TopicExchange exchange() &#123; return new TopicExchange("exchage1"); &#125; //配置不同队列到交换机上(选择不同的策略) @Bean Binding bindingExchangeMessage() &#123; return BindingBuilder.bind(firstQueue()).to(exchange()).with("q1"); &#125; @Bean Binding bindingExchangeMessage2() &#123; return BindingBuilder.bind(secondQueue()).to(exchange()).with("q2.#"); &#125;&#125; 构建生产者 123456789101112131415161718192021@Componentpublic class Produce &#123; @Autowired private RabbitTemplate rabbitTemplate; public void sen1() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println("生产者发送消息，序号为: " + i); rabbitTemplate.convertAndSend("exchage1", "q1", String.valueOf(i)); &#125; &#125; public void send2() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println("生产者发送消息，序号为: " + i); rabbitTemplate.convertAndSend("exchage1", "q2.#", String.valueOf(i)); &#125; &#125;&#125; 构建消费者 1234567891011121314151617181920212223@Componentpublic class Consumer &#123; @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "q1", autoDelete = "false"), exchange = @Exchange(value = "exchange1", type = ExchangeTypes.TOPIC), key = "q1.#")) public void process1(Message message, Channel channel) throws IOException &#123; System.out.println(new String(message.getBody())); channel.basicAck(message.getMessageProperties().getDeliveryTag(), true); &#125; @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "q1", autoDelete = "false"), exchange = @Exchange(value = "exchange1", type = ExchangeTypes.TOPIC), key = "q1.#")) public void process2(Message message, Channel channel) throws IOException &#123; System.out.println("拒绝消息"+new String(message.getBody())); channel.basicReject(message.getMessageProperties().getDeliveryTag(), true); &#125; @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "q2", autoDelete = "false"), exchange = @Exchange(value = "exchange1", type = ExchangeTypes.TOPIC), key = "q2.#")) public void process3(Message message, Channel channel) throws IOException &#123; System.out.println(new String(message.getBody())); channel.basicAck(message.getMessageProperties().getDeliveryTag(), true); &#125;&#125; 最后在启动文件中加入@EnableRabbit 观察如下： 调用send2发送消息 接下来调用send1 关于持久化操作,消息确认(自动和手动)，事务管理 持久化操作。如果队列与消息不持久化，那么服务在崩溃了之后，消息会丢失。所以可以在构建队列的时候设置durable，以及auto-delete设置为false 消息确认自动和手动：rabbitmq默认确认方式为自动，也就是消息一旦发出立即认为本次投递已经被正确处理，不管消费者端是否成功处理本次投递,那么有可能的情况就是消费者崩掉以后，消息丢失的情况会产生 选择手动，通过channel.basicAck 确认 和channel.basicReject 拒绝。一般出现异常的时候，catch异常再拒绝入列 事务管理:。生产中不建议使用事务模式，性能比较低，尽量使用手动确认模式]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>web开发</tag>
        <tag>java</tag>
        <tag>解耦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发第一次]]></title>
    <url>%2F2021%2F01%2F17%2F2021-01-17-django%E5%BC%80%E5%8F%91%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[django开发需求的描述用户端 可以通过搜索到博客内容 能够根据关键词进行搜索。然后展示出文章列表 能够根据某个分类查看所有关于这一分类的文章 首页看到新到旧的文章列表 能够订阅，能够评论，能够配置友链 作者端 后台需登录进入 创建分类和标签 能够用markdown进行编写 上传文章配图 配置导航 及时更新,收到对应的订阅 ER关系说明 sql语句如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101CREATE TABLE `user` ( `id` INTEGER PRIMARY KEY AUTO_INCREMENT);CREATE TABLE `category` ( `id` INTEGER PRIMARY KEY AUTO_INCREMENT, `name` VARCHAR(255) NOT NULL, `created_time` DATETIME, `is_nav` INTEGER, `owner` INTEGER);CREATE INDEX `idx_category__owner` ON `category` (`owner`);ALTER TABLE `category` ADD CONSTRAINT `fk_category__owner` FOREIGN KEY (`owner`) REFERENCES `user` (`id`) ON DELETE SET NULL;CREATE TABLE `link` ( `id` INTEGER PRIMARY KEY AUTO_INCREMENT, `title` VARCHAR(255) NOT NULL, `href` VARCHAR(255) NOT NULL, `status` VARCHAR(255) NOT NULL, `created_time` DATETIME, `weight` INTEGER, `owner` INTEGER);CREATE INDEX `idx_link__owner` ON `link` (`owner`);ALTER TABLE `link` ADD CONSTRAINT `fk_link__owner` FOREIGN KEY (`owner`) REFERENCES `user` (`id`) ON DELETE SET NULL;CREATE TABLE `post` ( `id` INTEGER PRIMARY KEY, `title` VARCHAR(255) NOT NULL, `description` VARCHAR(255) NOT NULL, `content` VARCHAR(255) NOT NULL, `status` VARCHAR(255) NOT NULL, `create_time` DATETIME, `updated_time` DATETIME, `category` INTEGER, `user` INTEGER);CREATE INDEX `idx_post__category` ON `post` (`category`);CREATE INDEX `idx_post__user` ON `post` (`user`);ALTER TABLE `post` ADD CONSTRAINT `fk_post__category` FOREIGN KEY (`category`) REFERENCES `category` (`id`) ON DELETE SET NULL;ALTER TABLE `post` ADD CONSTRAINT `fk_post__user` FOREIGN KEY (`user`) REFERENCES `user` (`id`) ON DELETE SET NULL;CREATE TABLE `comment` ( `id` INTEGER PRIMARY KEY AUTO_INCREMENT, `nickname` VARCHAR(255) NOT NULL, `email` VARCHAR(255) NOT NULL, `website` VARCHAR(255) NOT NULL, `content` VARCHAR(255) NOT NULL, `created_time` DATETIME, `post` INTEGER);CREATE INDEX `idx_comment__post` ON `comment` (`post`);ALTER TABLE `comment` ADD CONSTRAINT `fk_comment__post` FOREIGN KEY (`post`) REFERENCES `post` (`id`) ON DELETE SET NULL;CREATE TABLE `sidebar` ( `id` INTEGER PRIMARY KEY AUTO_INCREMENT, `type` VARCHAR(255) NOT NULL, `title` VARCHAR(255) NOT NULL, `status` INTEGER, `content` VARCHAR(255) NOT NULL, `created_time` DATETIME, `owner` INTEGER);CREATE INDEX `idx_sidebar__owner` ON `sidebar` (`owner`);ALTER TABLE `sidebar` ADD CONSTRAINT `fk_sidebar__owner` FOREIGN KEY (`owner`) REFERENCES `user` (`id`) ON DELETE SET NULL;CREATE TABLE `tag` ( `id` INTEGER PRIMARY KEY AUTO_INCREMENT, `name` VARCHAR(255) NOT NULL, `status` VARCHAR(255) NOT NULL, `created_tinme` DATETIME, `owner` INTEGER);CREATE INDEX `idx_tag__owner` ON `tag` (`owner`);ALTER TABLE `tag` ADD CONSTRAINT `fk_tag__owner` FOREIGN KEY (`owner`) REFERENCES `user` (`id`) ON DELETE SET NULL;CREATE TABLE `post_tag` ( `post` INTEGER NOT NULL, `tag` INTEGER NOT NULL, PRIMARY KEY (`post`, `tag`));CREATE INDEX `idx_post_tag` ON `post_tag` (`tag`);ALTER TABLE `post_tag` ADD CONSTRAINT `fk_post_tag__post` FOREIGN KEY (`post`) REFERENCES `post` (`id`);ALTER TABLE `post_tag` ADD CONSTRAINT `fk_post_tag__tag` FOREIGN KEY (`tag`) REFERENCES `tag` (`id`) 框架基础关于django的几个模块参考官方的文档https://docs.djangoproject.com/en/3.1/ Model部分包含 1.1 models 模型的定义相关使用说明 1.2 querysets 在model的基础上查看数据以及定义过滤 1.3 model instances 单个记录，如果CRUD操作 1.4 Migrations 表结构的调整，迁移等操作 1.5 Advanced 使用原生sql，聚合，事务，搜索等相关操作 1.6 其他:数据库优化等操作 View部分包含 2.1 The basics：url配置，增加缓存以及增加限制等 2.2 reference 静态文件和404页面处理。请求和回复对象 2.3 File uploads 文件上传下载存储等 2.4 class-based views 构建和复用view 2.5 advanced 导出csv和pdf格式 2.6 中间件涉及安全和session，缓存等 模版 3.1 the basics 基本配置模版和语法 3.2 逻辑操作 3.3 高效的配置渲染模版 form表单 4.1 基础语法使用 4.2 进阶 与model一起操作 编写一个简单的学员管理系统先安装虚拟环境 12pip install virtualenvwrapperpip install virtualenvwrapper-win 创建一个文件夹student-env为虚拟环境目录,并执行初始化虚拟环境 （默认构建在用户下面的ENV环境下。可以做更改,需要新增系统变量） 1mkvirtualenv student-env 激活虚拟环境 1workon student-env 停止或者删除环境 12deactivatermvirtualenv student-env 安装django1.11 1pip install django==1.11 创建项目切换到自己喜欢的目录，构建django项目（注意在虚拟环境进行操作） 12mkdir student_housedjango-admin startproject student_sys 创建App（创建模块）(出现错误可参考https://blog.csdn.net/qq_28194001/article/details/86709006) 12cd student_syspython manage.py startapp student 编写模块代码VS配置环境参照https://blog.csdn.net/cierlongbu/article/details/103753452 在model.py中编写 12345678910111213141516171819202122232425class Student(models.Model): SEX_ITEMS = [ (1,'男'), (2,'女'), (0,'未知') ] STATUS_ITEMS = [ (0,'申请'), (1,'通过'), (2,'拒绝') ] name = models.CharField(max_length=128, verbose_name='姓名') sex = models.IntegerField(choices=SEX_ITEMS, verbose_name='性别') profession = models.CharField(max_length=128, verbose_name='职业') email =models.EmailField(verbose_name= 'Email') qq = models.CharField(max_length=128, verbose_name='QQ') phone = models.CharField(max_length=128, verbose_name='电话') status = models.IntegerField(choices=STATUS_ITEMS,default=0,verbose_name='审核状态') created_time = models.DateField(auto_now_add=True,editable=False,verbose_name='创建时间') def __str__(self): return '&lt;Student: &#123;&#125;&gt;'.format(self.name) class Meta: verbose_name = verbose_name_plural = '学员信息' 在admin.py中编写 12345678910111213141516class StudentAdmin(admin.ModelAdmin): list_display = ('id','name','sex','profession','email','qq','phone','status','created_time') list_filter = ('sex','status','created_time') search_fields = ('name','profession') fieldsets = ( (None,&#123; 'fields':( 'name', ('sex','prefession'), ('email','qq','phone'), 'status', ) &#125;), )admin.site.register(Student, StudentAdmin) 注册到setting文件中 123456789INSTALLED_APPS = [ 'student', 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles',] 123456789LANGUAGE_CODE = &apos;zh-Hans&apos;TIME_ZONE = &apos;Asia/Shanghai&apos;USE_I18N = TrueUSE_L10N = TrueUSE_TZ = True 在项目的根目录下执行: 1234python manage.py makemigreations # 创建数据库迁移文件python manage.py migrate # 创建表python manage.py createsuperuser #创建超级用户python manage.py runserver #启动服务 效果如下： 关于前台页面的开发在student.py 中 1234# 定义了一个index方法def index(request): words = 'World!' return render(request,'index.html',context=&#123;'words':words&#125;) # 在student的templates中寻找index.html,并且上下文内容包含words 注意：在工作空间的json中加入可以解决在django中编写html的问题 1234567"files.associations": &#123; "**/*.html": "html", "**/templates/**/*.html": "django-html", "**/templates/**/*": "django-txt", "**/requirements&#123;/**,*&#125;.&#123;txt,in&#125;": "pip-requirements" &#125;, "emmet.includeLanguages": &#123;"django-html": "html"&#125; 在创建的templates的index.html中编写 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;学员管理系统&lt;/title&gt;&lt;/head&gt;&lt;body&gt; Hello &#123;&#123; words &#125;&#125;!&lt;/body&gt;&lt;/html&gt; 在urls.py中配置映射目录 12345678from django.conf.urls import urlfrom django.contrib import adminfrom student.views import indexurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^$',index,name='index') # 匹配所有映射给index函数处理 r代表使用原生字符] 重新调整123456# 定义了一个index方法def index(request): # words = 'World!' # return render(request,'index.html',context=&#123;'words':words&#125;) # 在student的templates中寻找index.html,并且上下文内容包含words students = Student.objects.all() # 获取所有学员信息 return render(request,'index.html',context=&#123;'students':students&#125;) 1234567&lt;body&gt; &lt;ul&gt; &#123;% for student in students %&#125; &lt;li&gt;&#123;&#123;student.name&#125;&#125; - &#123;&#123;student.get_status_display&#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt;&lt;/body&gt; get_status_display自动调用带有choices 效果如下： 提交数据(使用form)创建一个forms.py文件 12345678910111213141516171819from django import formsfrom .models import Studentclass StudentForm(forms.ModelForm):# 定义元数据,模型参照student，并且设置显示的字段 class Meta: model = Student fields = ( 'name','sex','profession', 'email','qq','phone' ) # 检验QQ必须为数据(示例) def clean_qq(self): cleaned_data = self.cleaned_data['qq'] if not cleaned_data.isdigit(): raise forms.ValidationError('必须为数字') return int(cleaned_data) 修改view.py 123456789101112131415161718192021222324252627282930# 定义了一个index方法def index(request): # words = 'World!' # return render(request,'index.html',context=&#123;'words':words&#125;) # 在student的templates中寻找index.html,并且上下文内容包含words students = Student.objects.all() # 获取所有学员信息 # 以下为新增代码 if request.method == 'POST': form = StudentForm(request.POST) if form.is_valid(): # 对于手动创建student 可以利用form直接进行保存 # cleaned_data = form.cleaned_data # student = Student() # student.name = cleaned_data['name'] # student.sex = cleaned_data['sex'] # student.email = cleaned_data['email'] # student.profession = cleaned_data['profession'] # student.qq = cleaned_data['qq'] # student.phone = cleaned_data['phone'] # student.save() form.save() return HttpResponseRedirect(reverse('index')) else: form = StudentForm() context =&#123; 'students':students, 'form':form &#125; return render(request,'index.html',context=context) 页面调整如下： 12345678910111213&lt;body&gt; &lt;ul&gt; &#123;% for student in students %&#125; &lt;li&gt;&#123;&#123;student.name&#125;&#125; - &#123;&#123;student.get_status_display&#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &lt;hr&gt; &lt;form action="/" method="post"&gt; &#123;% csrf_token %&#125; &#123;&#123; form &#125;&#125; &lt;input type="submit" value="提交"&gt; &lt;/form&gt;&lt;/body&gt; 注意:csrf_token是对安全性进行检验 最终效果如下： 优化一般将数据操作逻辑封装到model层中 123@classmethoddef get_all(cls): return cls.objects.all() 使用class-based view复用在views.py中构建以下代码: 1234567891011121314151617181920212223242526272829303132333435from django.views import View## 使用class-based view 复用class IndexView(View): template_name = 'index.html' def get_context(self): students = Student.get_all() context =&#123; 'students':students &#125; return context ## 匹配get请求 def get(self,request): context = self.get_context() form = StudentForm() context.update( &#123; 'form':form &#125; ) return render(request,self.template_name,context=context) ## 匹配post请求 def post(self,request): form = StudentForm(request.POST) if form.is_valid(): form.save() return HttpResponseRedirect(reverse('index')) context =self.get_context() context.update(&#123; 'form':form &#125;) return render(request,self.template_name,context=context) urls.py中引入： 1234567from student.views import indexfrom student.views import IndexViewurlpatterns = [ url(r'^admin/', admin.site.urls), ## url(r'^$',index,name='index') url(r'^$',IndexView.as_view(),name='index')] 注意：as_view 就是对get和post方法的包装 使用中间件构建一个middlewares.py文件，代码如下： 1234567891011121314151617181920212223242526272829303132class TimeItMiddleware(MiddlewareMixin): def process_request(self,request): strs = "1. 处理requset请求，第一个被调用，" "处理request中认证头之类" print(strs) return def process_view(self,request,func,*args,**kwargs): strs = "2. 用于view处理,其中func即是调用的view" print(strs) if request.path != reverse('index'): return None start = time.time() #这里调用了view做处理 response = func(request) costed = time.time() - start print("process view used %d seconds" % (costed,)) return response def process_exception(self,request,Exception): strs = "0. 用来处理全部流程中的异常" print(strs) pass def process_template_response(self,request,response): strs = "3. 如果处理渲染模板使用了render,就会调用到这里" print(strs) return response def process_response(self,request,response): strs = "4. 所有的流程执行完后会返回response给浏览器,在返回之前会调用到这里" print(strs) return response 加入到setting配置中的中间件中: 12345678910MIDDLEWARE = [ 'student.middlewares.TimeItMiddleware', 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] 关于单元测试参考的文章很多,可以参考https://www.cnblogs.com/fiona-zhong/p/10554197.html]]></content>
      <categories>
        <category>django开发</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web开发</tag>
        <tag>快速构建</tag>
        <tag>ORM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析完结]]></title>
    <url>%2F2020%2F09%2F29%2F2020-09-29-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%8C%E7%BB%93%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[数据分析完结章数据准备 纯python时区计数 使用pandas进行时区计数 处理缺失值 可视化操作 处理复杂字符串 可视化操作 分析电影 测量评价分歧假设想找到男性和女性观众最具分歧的电影 假设通过评分的方差或者标准差来衡量 分析婴儿名字 目标 根据给定的名字,对婴儿名字随时间比例进行可视化 确定一个名字的相对排位 每年最受欢迎的名字或者流行度最好或者最低的名字 分析名字的趋势 分析名字的来源 整理数据集 分析名字趋势 计算命名的多样性 最后一个字母 男孩名字变成女孩名字 农业数据分析 选举分析 按雇主和职业进行统计 捐赠金额分桶 按州进行计算]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据重组</tag>
        <tag>数据聚合</tag>
        <tag>数据分组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据建模]]></title>
    <url>%2F2020%2F09%2F28%2F2020-09-28-python%E5%BB%BA%E6%A8%A1%2F</url>
    <content type="text"><![CDATA[python建模在机器学习的学习库中,有2个比较流行的建模数据包statsmodel和大名鼎鼎的scikit-learn.statsmodels更关注统计推断，提供不确定估计和参数p-value。相反的，scikit-learn注重预测。 pandas与建模代码结合 评估线性模型泰坦尼克代码示例 简单示例]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据重组</tag>
        <tag>数据聚合</tag>
        <tag>数据分组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之高阶pandas]]></title>
    <url>%2F2020%2F09%2F27%2F2020-09-27-%E9%AB%98%E7%BA%A7pandas%2F</url>
    <content type="text"><![CDATA[高阶pandas背景和目标一个列经常会包含重复值,汇聚成了一个小型的不同值的集合。通过unique和values_counts,允许从一个数组中提取不同的值,并计算这些不同值的频率 在数据库的操作中,使用维度表示一种最佳实践，维度包含了不同的值,并将主要观测值存储为引用维度表的整数键 这种按照整数展现的方式成为分类或者字典编码的实现 pandas中的Categorical类型(可分类类型) 通过函数转为categorical对象 其他方式 使用categorical对象进行计算 使用分类获得更高性能 分类方法 创建虚拟替换变量 高阶的groupby应用在分组操作中有一个内建方法叫做transform,可以达到: 产生一个标量值,广播到个分组的尺寸数据中 产生一个与输入分组尺寸相同的对象 不可改变它的输入 分组的时间重新采样 其他方式 注:还有一个pipe管道的方法暂时没有用.后续代码有涉及到在进行查阅]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据重组</tag>
        <tag>数据聚合</tag>
        <tag>数据分组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据的时间序列]]></title>
    <url>%2F2020%2F09%2F25%2F2020-09-24-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[时间序列 说明 时间序列的数据是比较重要的结构化数据形式,在多个时间观测或者测量的数据形成了时间序列 许多的时间序列是固定频率的,也就表明数据是根据相同规则出现的.同样的时间序列可以是不规则的,没有固定的时间单位和偏移量 标记时间的方式可能有时间戳;固定的时间区间;时间间隔;实验时间或消耗时间 日期和时间数据的类型以及工具在python的标准库中包含了日期和时间数据的类型.有datetime,time,calendar等 字符串和datetime互相转换 使用pd中的to_datetime进行格式转换 时间序列基础pandas的基础时间序列是由时间戳索引的Series,通常表示为字符串或者是datetime对象 索引,子集,选择 含有重复索引的时间序列在某些情况下,可能会有多个数据观察值落在特定的时间戳上. 日期范围,频率和移位时间序列的频率不是固定的,但是经常有需要处理固定频率的场景,例如每日,每月.这意味着在必要的时候向时间序列引入缺失值。比如通过resample方法将样本时间序列转换为固定的每日频率数据 频率和日期偏置pandas中频率是由基础频率和倍数组成的.基础频率通常会有字符串别名. 移位日期在Serise和DataFrame中都有一个shift方法进行简单日期前后位移 使用偏移进行移位日期 时区处理 时间区间和区间算术时间区间表示的是时间范围,Period类表示的正式这种数据类型 示例 重新采样和频率转换重新采样指的是将时间序列从一个频率转换到另一个频率的过程,将高频率聚合到低频率为向下采样,反之为向上采样 向下采样 开端-峰值-谷值-结束 向上采样 使用区间进行重新采样 移动窗口函数统计和其他通过移动窗口或指数衰减而运行的函数是用于时间序列操作的数组变换的一个重要类别。这些函数称作为移动窗口函数。函数会自动排除缺失数据 指数加权函数指定一个常数衰减因子以向更多近期观测值提供更多权重值,可以替代使用具有相等加权观察值的静态窗口尺寸的方法 二元移动窗口函数]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据重组</tag>
        <tag>数据序列</tag>
        <tag>数据时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分组和聚合操作]]></title>
    <url>%2F2020%2F09%2F11%2F2020-09-11-%E6%95%B0%E6%8D%AE%E5%88%86%E7%BB%84%E5%92%8C%E8%81%9A%E5%90%88%2F</url>
    <content type="text"><![CDATA[通过将数据进行分组以及聚合,能够更加能够看到数据的重要性,越来越接近我的想法了. 数据聚合和分组操作​ 对数据及进行分类，在每一组数据应用聚合函数或者转换函数,这是非常重要的一个部分.一般在数据载入,合并,准备数据集之后,可能需要计算分组统计或者数据透视表用于报告或可视化的目的。pandas提供一个灵活的groupby接口,允许一种自然的方式对数据集进行切片,切块和总结。 ​ 我们可以通过pandas对象或者Numpy数据执行复杂的组操作 1. 使用一个或者多个键将pandas对象拆分为多块 2. 计算组汇总统计信息以及应用组内变化或其他操作 3. 计算数据透视表和交叉表 4. 执行分位数分析以及其他统计组分析GroupBy机制一般聚合操作中所有的动作为拆分-应用-联合,数据包含在pandas对象中,可以是不同的数据结构.之后可以根据一个或者多个键分离到各组中,可以沿着行或者列.分组操作后，一个函数就可以应用到各个组中,产生新的值。注意:axis=0 代表着以行为单位从上至下计算,axis=1代表着以列为单位从左至右计算 分组键 分组键可以是多种形式的,不一定是完全相同的类型: 与需要分组的轴长度一致的值列表或者值数组 DataFrame的列名的值 可以将分组轴向上的值和分组名称相匹配的字典或者Series 可以在轴索引或者索引中单个标签上调用的函数 示例说明 遍历分组对象group对象支持迭代 选择一列或者所有列的子集 使用字典和Serise进行分组 使用函数分组 根据索引层级进行分组 数据聚合聚合是指所有根据数组产生标量值的数据转换过程，也就是类似统计函数一样. 逐列以及多函数应用 不同的操作方式0 不同的操作方式1 返回不带行索引的聚合数据 apply应用:通用拆分-应用-联合 压缩分组键 分位数以及桶分析 根据分位数 使用指定分组值填充缺失值在清除缺失值，有时候可以用dropna去除缺失值,有时候可能需要进行修正.fillna是一个可以填充缺失值的方法 其他示例 随机采样和排列在Series中有sample方法可以帮助我们进行随机采样 分组加权平均和相关性加权平均连接 相关示例 逐组线性回归(了解) 数据透视表和数据交叉表 交叉表是用于统计分组频率的特殊透视表]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据重组</tag>
        <tag>数据聚合</tag>
        <tag>数据分组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据制图]]></title>
    <url>%2F2020%2F08%2F26%2F2020-08-26-%E6%95%B0%E6%8D%AE%E5%88%B6%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[通过将数据进行可视化操作,数据就变得越来越美丽了 绘图与可视化 python提供了很多可以制作静态或者动态的可视化文件的库 python中提供了一个库叫做matplotlib库 可视化数据能够直观的展现数据分析的结果 简明的matplotlib入门 图片与子图matplotlib绘制的图片位于Figure对象中,使用plt.figure生成一个新的图片 通常是不能用新的空白图片进行绘图的,需要使用add_subplot创建一个或者多个子图 说明:也就是Figure对象中可以允许有多个子图 制图的补充说明 获取制图对象 这个时候就可以通过索引方便的获取制图对象、 调整子图之间的间距 颜色,标记和线类型matplotlib的主函数plot接收带有x和y轴的数组。以及一些可选的字符串缩写参数来指明颜色和线类型 参考文章 刻度,标签和图例在pyplot接口设计为交互式使用,包含了像xlim,xticks和xticklabels等方法,分别控制了绘图范围,刻度位置以及刻度标签 设置标题,轴标签,刻度和刻度标签 添加图例 注释与子图加工在plt中使用text,arrow和annote方法用来添加注释和文本 text方式用于给定坐标x和y并绘制对应的说明 相关示例注释可以同时绘制文本和箭头,示例中展现标普500指数从2007年以来的收盘价。并标注2008到2009金融危机的重要日期 除此之外还可以绘制多种常见的图形对象 图片保存到文件 使用pandas和seaborn进行绘图折线图Series和DateFrame都有一个plot的属性。默认情况下绘制的是折线图 柱状图bar()和barh()方法分别绘制垂直和水平的柱状图,Series和DataFrame索引将会被用作x的刻度或者是y的刻度 DataFrame 相关示例* 根据星期日期和派对规模形成交叉表* 使用seaborn进行制图 直方图和密度图 直方图 直方图是一种条形图,用于给出值频率的离散显示,数据点被分成离散的,均匀间隔的箱，并且绘制每个箱中数据点的数量 密度图 密度图是一种与直方图相关的图形列表。通过计算可能产生的观测数据的连续概率分布 一次性绘制直方图和密度图 散点图和点图散点图和点图可以用于检验两个一维数据序列之间的关系 参考文章 分面网格和分类数据]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据重塑</tag>
        <tag>数据展现</tag>
        <tag>可视化操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据规整之连接,联合与重塑]]></title>
    <url>%2F2020%2F07%2F24%2F2020-07-23-%E6%95%B0%E6%8D%AE%E8%A7%84%E6%95%B4%E4%B9%8B%E8%BF%9E%E6%8E%A5%E8%81%94%E5%90%88%E9%87%8D%E5%A1%91%2F</url>
    <content type="text"><![CDATA[这章可以在以后的数据分析案例中,慢慢的体会。但最终的目的就是为了组装自己想要的数据 数据规整之连接,联合与重塑首先数据可能分布在多个文件或者数据库中,或以某种不易于分析的格式进行排列。而现在我们要做的就是如何连接,联合与重塑 分层索引分层索引是pandas的重要特性,允许在一个轴向上拥有多个索引层级。分层索引提供了一种在更低维度的形式中处理更高维度数据的方式 筛选数据子集 DataFrame中分层索引 重排序和层级排序有时需要重新排列轴上的层级顺序，或者按照特定的层级对数据进行排序。使用swaplevel接收两个层级序号或者层级名称。返回一个层级变更的新对象，但是数据是不变的 按层级进行汇总统计DataFrame和Series有一个level选项。可以在某个特定的轴上面进行聚合 使用DataFrame的列进行索引 联合与合并数据集 pandas.merge可以根据一个或者多个键进行连接。 pandas.concat是对象在轴向上进行黏合或堆叠 combine_first允许将重叠的数据拼接在一起。以使用一个对象中的值填充另一个对象中的缺失值 数据风格的连接 左右连接以及outer并集 注意事项 多对多连接是行的笛卡尔积，使用多个键进行合并时传入一个列名的列表即可，在处理重叠的列名的时候可以使用suffixes进行重新命名 根据索引合并 沿轴向连接一个是通过Numpy的concatenate函数，也可以使用pandas的concat函数 联合重叠数据可以理解为填补Series或者DataFrame的缺失值,使用Combine_first 重塑和透视多层索引在DataFrame中提供一种一致性的方式用于重排列数据。 statck简单的说就是转为低维度多层级的Series(堆叠) 也可以叫做列中的数据透视到行 unstack简单的说就转为层级感强烈的DataFrame(拆堆) 也可以叫做行中的数据透视到列 长变宽 宽变长pivot方法的反操作是pandas.melt,需要注意的是，需要配置key哪些列是分组指标]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据重塑</tag>
        <tag>层级拆分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之清洗与准备2]]></title>
    <url>%2F2020%2F07%2F23%2F2020-07-22-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E6%B8%85%E6%B4%97%E4%B8%8E%E5%87%86%E5%A4%872%2F</url>
    <content type="text"><![CDATA[继续刚. 数据清洗与准备2python在字符串和文本操作上具有很大的便利性,字符串对象是大部分的文本操作简单化,对于复杂的模式匹配和文本操作。正则表达式是可能需要的。pandas允许将字符串和正则表达式应用到整个数据数组上。同时也能处理数据缺失带来的问题 字符串操作字符串对象方法 查找和定位字符串 index和find方法的区别在于,使用index方法没有找到时会抛出一个异常 计数和替换字符串 正则表达式python中提供了re模块进行正则表达式的使用，一般单个表达式称作为regexre模块主要有三个主题:匹配，替代，拆分 match和search和findall groups​ 假设将每个地址分为三个部分.可以使用括号模式包起来 pandas中向量化字符串函数]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据清洗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之清洗与准备1]]></title>
    <url>%2F2020%2F07%2F02%2F2020-07-02-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E6%B8%85%E6%B4%97%E4%B8%8E%E5%87%86%E5%A4%871%2F</url>
    <content type="text"><![CDATA[数据清洗也是我们的首要准备的，不完美的数据永远都是不完美的 数据清洗与准备1 数据分析和建模的过程中,大量的时间都花在了数据准备上 pandas和内置的python工具提供了一个高级,灵活和快速的工具集 着重关注于如何处理缺失值,重复值,字符串操作和其他分析数据转换工具 处理缺失值​ pandas对象的所有描述性统计信息默认情况下是排除缺失值的 ​ pandas对象中表现缺失值的方式对大部分用户来说还是OK的。对于数值型数据,pandas使用浮点值NaN。一般称作为容易检测到的标识值 注意:在统计应用学中,NA数据可以是不存在的数据或者是存在但不可观察的数据 python内建的None值在对象数组中也被当做NA处理 过滤缺失值​ 使用pandas.isnull和布尔值索引手动的过滤缺失值,但dropna在过滤缺失值非常有用.在Series上使用dropna,它会返回Series中所有的费控数据与其索引值 处理Series 处理DateFrame​ 处理DataFrame对象时,有可能需要删除全部为NA或者包含有NA的行或者列。dropna默认情况下会删除包含缺失值的行 过滤DataFrame的行的相关方法涉及时间序列数据。如果要保留一定数量的观察值的行。可以用thresh参数表示 补全缺失值有时候我们可能需要多种方式补全数据,而不是单纯的过滤缺失值。我们可以使用fillna的方法补全缺失值,调用该方法时可以使用一个常数替代缺失值 fillna的基本操作 额外操作 Series填充(mean()平均值 median()中位数 max()最大值 min()最小值 sum()求和 std()标准差) 数据转换删除重复值​ 由于各种原因,DataFrame中会出现重复的行 ​ 默认方法都是按照对列进行操作。可以指定数据的任何子集检测是否有重复 使用函数或映射进行数据转换 ​ Series的map方法接受一个函数或者一个包含映射关系的字典型对象 函数级操作 替代值使用fillna填充缺失值,map可以用来修改一个对象中的子集的值。但是replace提供了更为简单的灵活的实现。对于Series使用map，对于DataFrame来说使用apply或者applymap 重命名轴索引 创建数据集转换后的版本,使用rename 离散化和分箱​ 连续值经常需要离散化或者分离成‘箱子’进行分析。 ​ 现架设某项研究中一组人群的数据,你想将他们分组，放入离散的年龄框中 注意：pandas返回的对象是一个特殊的categorical对象，输出了描述由pandas.cut计算出的箱。里面指定了不同类别的名称以及codes属性中的ages 进阶操作​ pandas一般根据数据中的最大值和最小值计算出等长的箱 ​ 使用qcut可以定义等长的箱以及自定义分位数 检测和过滤异常值​ 过滤和转换异常值一般是应用数组。比如 置换和随机抽样​ 使用np.random中的permutation可以对DataFrame中的Series或行进行置换（随机排序）,调用该操作可以根据需要的轴长度产生一个表示新顺序的整数数组 ​ 计算指标/虚拟变量​ 将分类变量转换为虚拟或者指标矩阵是另一种转换操作,如果DataFrame中的一列有K个不同的值,则可以衍生一个K列的值为1和0的矩阵或DataFrame，在pandas中有一个get_dummies函数可以实现 处理一行属于多类别的数据 与cut等离散化函数结合使用]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据清洗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之Excel与WebApis交互]]></title>
    <url>%2F2020%2F03%2F16%2F2020-03-16-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E8%AF%BB%E5%8F%96Excel%E4%B8%8EWebApis%E4%BA%A4%E4%BA%92%2F</url>
    <content type="text"><![CDATA[其实你会发现转来转去二维数组就在我们身边，json数组放对象，table就是活生生的二维空间。真的是答案就在我们的身边。继续前行，数据清洗和准备，我来了 数据分析之读取Excel与WebApis交互 读取Excel操作 WebApis交互 读取Excel操作pandas的ExcelFile和readExcel支持读取和存储Excel 数据写入Excel 与webapi交互无论是国内还是国外,都可以找一些公共的api,并且尽量的根据逻辑转换为df或者series 其实你会发现表格和json数据里面构建对象就是一个二维数组 数据库交互有些数据来自与数据库,无论非关系还是关系数据库 转化为DataFrame的2种方式 安装源 pip3 install sqlalchemy -i https://pypi.tuna.tsinghua.edu.cn/simple]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据处理</tag>
        <tag>数据加载</tag>
        <tag>Excel读取</tag>
        <tag>mysql数据库读取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之数据加载,存储与文件格式一]]></title>
    <url>%2F2020%2F03%2F12%2F2020-03-12-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%2C%E5%AD%98%E5%82%A8%E4%B8%8E%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%B8%80%2F</url>
    <content type="text"><![CDATA[越来越有意思了,坚持坚持 数据加载,存储与文件格式 读写文本格式的数据 读写文本格式的数据利用pandas的数据输入和输出,输入和输出划分几个大类:读取文本文件,加载数据库中的数据,利用webapi操作网络资源 pandas提供了一些用于将表格型数据读取为DataFrame对象的函数,其中readcsv和readtable是比较常用的 读取逗号分隔 指定分隔符读取 针对无标题行的文件 多个列层次化索引 有些表格并未用特定的分隔符 跳过注释 缺失值处理一般来说缺失值要么为空,要么没有.pandas会用一组经常出现的标记值进行识别.比如NA或者Null 通过na_value替换值 逐块读取文本文件在处理很大的文件时,找出大文件中参数以便后续处理. 通过nrows指定读取几行 逐块读取 将数据学出到文本格式 弥补缺失值 Series中使用 处理分隔符格式 转化为符合要求的数据格式 JSON数据123456789obj = &quot;&quot;&quot;&#123;&quot;name&quot;: &quot;Wes&quot;, &quot;places_lived&quot;: [&quot;United States&quot;, &quot;Spain&quot;, &quot;Germany&quot;], &quot;pet&quot;: null, &quot;siblings&quot;: [&#123;&quot;name&quot;: &quot;Scott&quot;, &quot;age&quot;: 30, &quot;pets&quot;: [&quot;Zeus&quot;, &quot;Zuko&quot;]&#125;, &#123;&quot;name&quot;: &quot;Katie&quot;, &quot;age&quot;: 38, &quot;pets&quot;: [&quot;Sixes&quot;, &quot;Stache&quot;, &quot;Cisco&quot;]&#125;]&#125;&quot;&quot;&quot; json之间的转换 向一个DataFrame传入一个字典列表 特殊json假定json数组中每个对象是表格中的一行 web信息收集安装所需要的库 12pip3 install lxml -i http://pypi.douban.com/simple/pip3 install bs4 html5lib -i https://pypi.tuna.tsinghua.edu.cn/simple 小例子看出现频率最高的 解析html1pip3 install requests -i https://pypi.tuna.tsinghua.edu.cn/simple 有待改进 再次优化]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>数据加载</tag>
        <tag>爬取数据</tag>
        <tag>推导式转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之Pandas基础三]]></title>
    <url>%2F2020%2F03%2F11%2F2020-03-11-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas%E5%9F%BA%E7%A1%80%E4%B8%89%2F</url>
    <content type="text"><![CDATA[协方差和相关系数非常的有意思,可以让你衍生出现在就想关心数据应该怎么组合 pandas基础三 汇总和计算描述统计 汇总和计算描述统计pandas对象拥有一组常用的数学和统计方法,大部分是属于约简和汇总统计。用于从series提取单个值或者从DataFrame的行或者列中提取一个series,都是基于没有缺失数据假设构建的 返回一个列的所有的和 按照行进行求和运算 求平均值 间接统计和累计统计,以及多次汇总 例如，两组数的集合{0,5,9,14}和{5,6,8,9}其平均值都是7，但第二个集合具有较小的标准差。标准差可以当作不确定性的一种测量。例如在物理科学中，做重复性测量时，测量数值集合的标准差代表这些测量的精确度。当要决定测量值是否符合预测值，测量值的标准差占有决定性重要角色：如果测量平均值与预测值相差太远（同时与标准差数值做比较），则认为测量值与预测值互相矛盾。这很容易理解，因为如果测量值都落在一定数值范围之外，可以合理推论预测值是否正确。标准差应用于投资上，可作为量度回报稳定性的指标。标准差数值越大，代表回报远离过去平均数值，回报较不稳定故风险越高。相反，标准差数值越小，代表回报较为稳定，风险亦较小 计算均方差，要看样本量是等概率，还有概率的。如果没有概率，直接计算离差的平方=（样本金额-平均值）的平方，然后所以样本量的离差平方求和，再除以（样本个数-1），然后开根号，就是标准差。如果有概率的话，只需要在计算合计数时考虑加权平均，不用再除以个数-1，直接开根号。 对于非数值的统计 相关系数与协方差1、协方差是一个用于测量投资组合中某一具体投资项目相对于另一投资项目风险的统计指标,通俗点就是投资组合中两个项目间收益率的相关程度,正数说明两个项目一个收益率上升,另一个也上升,收益率呈同方向变化.如果是负数,则一个上升另一个下降,表明收益率是反方向变化.协方差的绝对值越大,表示这两种资产收益率关系越密切；绝对值越小表明这两种资产收益率的关系越疏远.2、由于协方差比较难理解,所以将协方差除以两个投资方案投资收益率的标准差之积,得出一个与协方差具有相同性质却没有量化的数.这个数就是相关系数.计算公式为相关系数=协方差/两个项目标准差之积. 关于相关系数可以参考如下2篇文章 协方差和相关系数 计算相关系数 总结其实协方差和相关系数除了公式还要琢磨之外,更多的应该理解他们的作用。其实也是看待一件事物和另一件事物的紧密性,也可以叫做关联度.可以用到彩票,交易,产业发展组合]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>Pandas</tag>
        <tag>汇总统计</tag>
        <tag>协方差和相关系数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之Pandas基础二]]></title>
    <url>%2F2020%2F03%2F06%2F2020-03-06-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas%E5%9F%BA%E7%A1%80%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[pandas基础二 基本功能 基本功能介绍Series和DataFrame的数据的基本操作 重新索引pandas对象的一个重要方法是reindex,其作用是创建一个新对象,它的数据符合新的索引 索引会根据reindex进行重排.如果某个索引值不存在,引入缺失值 对于时间序列的有序数据,重新索引需要一些插值处理.method选项可以操作,ffill是使用前面的值填充，bfill是使用后面的值填充。 如果使用dataFrame,reindex可以修改行索引和列.只传递一个序列时,会重新索引结果的行 同样的可以用column重新索引 丢弃指定轴上的项丢弃某条轴上面的一个或多个项很简单,只要有一个索引数组和列表即可 针对series 针对DataFrame 索引,选取和过滤Series索引的工作方式类似numpy的索引,不过Series索引不只是整数 切片运算有一些不同,其尾部是包含的 针对DataFrame进行索引就是获取一个或者多个列 通过布尔类型 用loc和iloc进行选取对于dataFrame的行的标签索引可以使用loc和iloc,从DataFrame选择行和列的子集 通过2个方法选择一行和多列 同样适用于一个标签或者多个标签的切片 一些方法 算术预算和数据对齐pandas重要的功能可以对不同索引的对象进行算术运算.对象相加时,存在不同的索引对.结果的索引就是该索引对的并集. 注意:Dataframe相加,没有共用的列或者行标签.结果都会是空 在算术方法中填充值 现在出现了na值,我填充一个特殊值怎么做 可用的方法 同理 DataFrame和Series之间的运算先看一个二维数组和一维数组相加 同理,2者相加也一样 如果某个索引值找不到,则形成并集 函数应用和映射Numpy的ufuncs也可以用于操作pandas对象 附上重新对二维数组的理解 排序和排名根据条件对数据集进行排序也是一种重要的内置计算,对行和列索引进行排序可以使用sortindex,返回一个已排序的新对象 升序或者降序 按值对series排列使用sortvalues 排序DataFrame时,可以根据一个或者多个列中的值,使用sorvalues中的by即可 rank方法rank是通过为各组分配一个平均排名的方式破坏平级关系 针对dataframe]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>Pandas</tag>
        <tag>Series和DateFrame基本功能</tag>
        <tag>排序筛选和rank</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之Pandas基础一]]></title>
    <url>%2F2020%2F03%2F04%2F2020-03-04-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas%E5%9F%BA%E7%A1%80%E4%B8%80%2F</url>
    <content type="text"><![CDATA[数据分析之路漫漫,贵在坚持.梅花香自苦寒来 pandas基础一 pandas的数据结构说明 pandas的数据结构介绍 pandas的数据结构说明pandas含有使数据清洗和分析工作变得更快更简单的数据结构和操作工具 pandas是基于Numpy数组构建的,特别是基于数组的函数和不适用for循环的数据处理 特点 pandas是专门为处理表格和混杂数据设计的 而Numpy更适合处理统一的数值数组数据 用的最多的是使用Series 和 DataFrame 注意:别忘记安装pandas库 pandas数据结构介绍pandas主要有2个非常重要的数据结构,分别是Series和DataFrame,他们提供了一种可靠的易于使用的基础 SeriesSeries类似于一维数组的对象,由一组数据以及一组与之相关的数据标签组成 自定义索引 一些运算 类比定长的有序字典 通过字典创建Series 检测缺失值 重要功能Series最重要的一个功能是会根据运算的索引标签自动对齐数据 Series对象本身和索引都有一个name属性,这个属性和pandas的其它关键功能非常密切 DataFrameDataFrame是一个表格型的数据结构,含有一组有序的列,每列可以是不同的值类型。 DataFrame既有行索引也有列索引.其中的数据是以一个或多个二维快存放的 通过head方法取前5行数据 可以指定具体列进行排列 如果传入列数据找不到产生缺失值 通过字典表及或者属性方式可以获取一个series 行值和列值得获取 使用del删除列 处理另一种常见的数据(嵌套字典)嵌套字典转换为dataframe,外层字典的键作为列,内层键作为行索引 可以用T方法进行行和列的交换 索引对象pandas的索引对象负责管理元数据,无论构建哪种类型,用到的任何数组和序列都会转换成一个Index 注意:与集合不同,pandas的索引是可以包含重复的标签 索引一些方法和属性]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>Pandas初始</tag>
        <tag>Series和DateFrame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python之Numpy基础三]]></title>
    <url>%2F2020%2F03%2F03%2F2020-03-03-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bpython%20Numpy%E5%9F%BA%E7%A1%80%E4%B8%89%2F</url>
    <content type="text"><![CDATA[Numpy数组的基础就结束了,让我们进入更高级的pandas(盼达)学习。 Numpy基础三 线性代数 伪随机数生成 随机漫步示例 线性代数Numpy提供了一个用于矩阵乘法的dot函数. 关于线性代数,现在熟知dot函数.后续分析中涉及到线性代数在回来补充 伪随机数生成numpy.random模块对python内置的random进行了补充,增加了一些用于高效生成多种概率分布的样本值的函数 随机数生成种子通过np.random.seed(1234)更改随机数生成种子 numpy.random的数据生成函数使用了全局的随机种子,要避免全局状态.可以使用numpy.random.RandomState 随机漫步随机漫步理论]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>Numpy使用</tag>
        <tag>Numpy简单结束</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python之Numpy基础二]]></title>
    <url>%2F2020%2F03%2F02%2F2020-03-02-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bpython%20Numpy%E5%9F%BA%E7%A1%80%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[打好基础,再接再厉 Numpy基础二 通用函数:快速的元素级数组函数 利用数组进行数据处理 用于数组的文件输入输出 通用函数通用函数是一种对ndarray中数据执行元素级运算的函数 意味着这些函数都是简单的元素级的变体 返回浮点数数组的小数和整数部分 常用的一元函数和二元函数 利用数组进行数据处理Numpy数组可以将许多种数据处理任务表述为见解的数据表达式 用数组表达式代替循环的做法通常叫做矢量化 示例1二维坐标系中,X轴可以取三个值1,2,3, Y轴可以取三个值7,8, 请问可以获得多少个点的坐标?显而易见是6个:(1,7)(2,7)(3,7)(1,8)(2,8)(3,8) 同理 将条件逻辑表述为数组运算np.where函数是三元表达式矢量化版本 示例1 np.where第二个和第三个参数不必是数组.where通常用于根据另一数组产生一个新的数组 示例2 数学和统计方法通过数组上的一组数学函数对整个数组或者某个轴向的数据进行统计计算 累加函数 用于布尔类型数组的方法 np数组的排序和python内置的列表类型一样,Numpy也可以通过sort方法进行排序 多维数组以及定位 唯一化以及其他集合逻辑通过unique用于找出数组中唯一值,并返回已排序的结果 其他函数通过np.in1d用于测试一个数组中的值在另一数组中的成员资格,返回布尔类型数组 用于数组的文件输入输出np.save和np.load是读写磁盘数组数据的2个主要函数,保存的扩展名为.npy]]></content>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>Numpy使用</tag>
        <tag>文件的输入输出读写</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python之Numpy基础一]]></title>
    <url>%2F2020%2F02%2F28%2F2020-02-28-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bpython%20Numpy%E5%9F%BA%E7%A1%80%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Numpy可以好好补补数学.捡起了儿时的快乐 数组和矢量计算 Numpy介绍 Numpy中ndarray:一种多维数组对象 备注:矢量（vector）是一种既有大小又有方向的量，又称为向量。一般来说，在物理学中称作矢量，例如速度、加速度、力等等就是这样的量。舍弃实际含义，就抽象为数学中的概念──向量。在计算机中，矢量图可以无限放大永不变形. Numpy的功能 ndarray,一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组 用于对整组数据进行快速运算的标准数学函数(无需编写循环) 用于读写磁盘数据的工具以及用于操作内容映射文件的工具 线性代数,随机数生成以及傅里叶变换功能 主要的功能 用于数据整理和清算,子集构造和过滤,转换等快速的矢量化数据运算 常用的数组算法,如排序,唯一化,集合运算等 高效的描述统计和数据聚合/摘要运算 用于异构数据集的合并/连接运算的数据对齐和关系型数据运算 将条件逻辑表述为数组表达式 数据的分组运算(聚合,转换,函数应用等) Numpy的优势 Numpy是在一个连续的内存块中存储数据,独立于其他的python内置对象 Numpy可以在整个数组上执行复杂的计算,而不需要python的for循环 Numpy中的ndarray一种多维数组对象,关于多维数组可以参考 关于多维数组解释好的文章 操作1 操作2ndarray是一个通用的同构数据多位容器,所有元素必须是相同类型的,每个数组都一个shape(一个表示各维度大小的元组)和一个dtype(用于描述数组数据类型的对象) 创建ndarray(从零开始)创建数组最简单的方法就是使用array函数 通过其他方式创建数组在np.array可以通过zeros和ones创建指定长度和形状的全0或者全1数组 ndarray的数据类型dtype是一个特殊的对象,讲一块内容解释为特定数据类型所需的信息 类型转换 Numpy数组的运算数组很重要,不用编写循环即可对数据执行批量运算 不同大小数组之间的运算叫做广播 基本的索引和切片数组切片是原始数组的视图,视图上的任何修改都会直接反应到源数组上 在进行切片的时候该值会自动传播,以为着跟列表的区别在,数组切片是原始数据的修改。数据不会被复制 如果明确要复制,使用arr[5:8].copy 对于高维度数组,在一个二维数组中,各索引位置上的元素不再是标量而是一维数组 对于各个元素进行递归访问,可以传入一个以逗号隔开的索引列表选取单个元素 二维数组索引方式 三维数组索引方式 测试用例 切片索引ndarray的切片语法和列表的一维对象差不多,二维稍微有点区别 布尔类型索引 通知在匹配完后,同样可以进行切片的操作 一些常见操作 花式索引花式索引是一个Numpy术语,利用整数数组进行索引 花式索引和切片不一样,总是将数据复制到新数组中 数组转置和轴对换转置是重塑的一种特殊形式,数组不仅有transpose方法,还有一个特殊的T属性 三轴转换 如何理解轴转换]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>Numpy使用</tag>
        <tag>矩阵相乘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python文件和操作系统]]></title>
    <url>%2F2020%2F02%2F21%2F2020-02-21-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPython%E6%96%87%E4%BB%B6%E5%92%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[文件和操作系统 文件的读写操作 文件的字节与编码 文件的读写操作打开一个文件以便读写,可以使用内置的open函数填充一个相对路径或者是绝对路径 1234567r:读取文件，若文件不存在则会报错w:写入文件，若文件不存在则会先创建再写入，会覆盖原文件a:写入文件，若文件不存在则会先创建再写入，但不会覆盖原文件，而是追加在文件末尾rb,wb:分别于r,w类似，但是用于读写二进制文件r+:可读、可写，文件不存在也会报错，写操作时会覆盖w+:可读，可写，文件不存在先创建，会覆盖a+:可读、可写，文件不存在先创建，不会覆盖，追加在末尾 注意：这里的覆盖是指每次重新打开文件进行操作时覆盖原来的，如果是在打开文件中则不会覆盖 文件的字节和编码 前期回顾]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>文件操作</tag>
        <tag>字符编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python函数]]></title>
    <url>%2F2020%2F02%2F20%2F2020-02-20-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bpython%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数即是对象,函数也可以叫做方法 函数 函数的定义 命名空间,作用域和局部函数 函数即是对象 匿名函数 错误和异常处理 函数的定义函数是在python中最重要的代码组织和复用手段,如果需要重读的使用或者非常类似的代码,就需要写一个函数,通过给函数起一个名字,可以提高代码的可读性 命名空间,作用域和局部函数函数可以访问到不同作用域中的变量:全局(global) 和 局部(local) 注意:任何函数中赋值的变量默认都是被分配到局部命名空间(local namespace)中的,局部空间是在函数被调用时创建的,函数参数会立即填入该命名空间 返回多个值 函数也是对象详见代码示例: 第一种:常规方式 第二种:将需要执行的方法作为操作列表 第三种:通过内置的map函数,可以在一组数据上应用一个函数 匿名函数(就是函数没有名字) 生成器迭代器和生成器对比 生成器表达式生成器表达式就是将列表推导式两端的方括号改为圆括号 itertoole模块itertoole有许多常见的算法生成器 注意:其余功能可以参考相关文档 错误和异常处理f = open(path,&apos;w&apos;) try: xxx_to() except: print(&apos;xxx&apos;) finally: f.close()]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>函数和方法</tag>
        <tag>异常机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python数据结构和序列]]></title>
    <url>%2F2020%2F02%2F18%2F2020-02-18-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bpython%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[每个数据结构都是语言设计者的精心设计,推导式也是有趣的部分 python的数据结构,函数和文件 数据结构和序列,函数,文件讲分为3个部分进行叙述 数据结构和序列python的数据结构有元组,列表,字典,集合 元组元组是一个固定长度,不可改变的python序列对象,创建元组最简单的方式就是用逗号进行分隔 如何元组中某个对象是可变的,可以在原位上进行修改 元组可以相接与复制 拆分元组拆分和数值交换 拆分迭代元组或者列表序列 tuple方法元组有一个方法和列表保持一致是叫做count,可以统计某个值出现的频率 列表与元组对比,列表的长度可变,内容可以被修改,可以用方括号定义,或者用list函数 添加和删除元素 通过in或者not in可以检查列表是否包含该数据 串联和组合列表 排序通过使用sort函数对一个列表原地排序 二分搜索和维护已排序的列表在python中bisect模块支持二分查找和向已排序的列表插入值 切片切片的目的主要选取大多数序列类型的一部分,切片的基本形式就是strat:stop 切片的起始元素是包含的,但不包含结束元素,因此结果中包含的元素个数为stop-start 递进切片 切片的规律可以如下图所示 序列函数enumerate函数迭代一个序列的时候,想知道当前项的序号 sorted函数sorted函数可以从任意序列的元素返回一个新的排好序的列表 zip函数zip函数可以将多个列表，元组或其它序列组合成一个元组列表 reversed函数reversed可以从后向前迭代一个序列 字典字典是python最为重要的数据结构,也可以叫做哈希映射或关联数组.以键值的方式构成,键值都可以是python对象 创建字典的方法之一是使用尖括号,用冒号进行键和值的分隔 删除的2种方式 键值的迭代与字典融合 通过序列创建字典 对单词进行分类 关于有效的键类型键通常是不可变的标量类型,list是不被允许的 集合集合是无序,不可重复的元素的集合,可以理解为字典,只有键没有值,创建集合有2种方式,通过set函数或者使用尖括号set语句 集合支持合并,交集,等集合运算 集合中常用的方法123456789101112131415161718S.add(e) 在集合中添加一个新的元素e；如果元素已经存在，则不添加S.remove(e) 从集合中删除一个元素，如果元素不存在于集合中，则会产生一个KeyError错误S.discard(e) 从集合S中移除一个元素e;S.clear() 清空集合内的所有元素S.copy() 将集合进行一次浅拷贝S.pop() 从集合S中删除一个随机元素;如果此集合为空，则引发KeyError异常S.update(s2) 用 S与s2得到的全集更新变量S以下内容可以用运算符操作代替 S.difference(s2) 用S - s2 运算，返回存在于在S中，但不在s2中的所有元素的集合S.difference_update(s2) 等同于 S = S - s2S.intersection(s2) 等同于S &amp; s2S.intersection_update(s2) 等同于S = S &amp; s2S.isdisjoint(s2) 如果S与s2交集为空返回True,非空则返回FalseS.issubset(s2) 如果S与s2交集为非空返回True,空则返回FalseS.issuperset(...) 如果S为s2的子集返回True,否则返回FalseS.symmetric_difference(s2) 返回对称补集,等同于 S ^ s2S.symmetric_difference_update(s2) 用S 与 s2的对称补集更新 SS.union(s2) 生成 S 与 s2的全集 列表,集合,字典推导式以及嵌套推导式语法格式如下:[expr for val in colletion if condition] 嵌套推导式(稍难)]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>数据结构</tag>
        <tag>序列</tag>
        <tag>推导式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python基础语法2]]></title>
    <url>%2F2020%2F02%2F17%2F2020-02-17-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bpython%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%952%2F</url>
    <content type="text"><![CDATA[继续前进,这是python基础知识的完结,后续我们将进阶到数据结构,函数和文件 python数据类型和控制流 标量类型是什么,如何使用 控制流式什么,如何使用 标量类型在python的标准库中,有一些内建的类型,用来处理数值数据,字符串,布尔值,日期类型.单值类型成为标量类型 None 表明python里面的控制 str 字符串类型,有以UTF-8为基准 bytes 原生的ascii字节 float 双精度浮点数 bool True或false值 int 任意精度整数 数值类型int可以存储任意大的数 字符串字符串的表现,可以用单引号和双引号,有换行的可以用三引号 python的字符串是不可变的,不能修改字符串 许多python对象可以转换为字符串,字符串是一个有序列的unicode字符,可以像列表和元组一样处理(用于切片) 用r来表示字符本身,字符串合并,字符串格式化 字节和Unicode 布尔值 类型转换 关于特殊的NoneNone是python的空值类型,一个函数没有明确的返回值,就默认返回为none 日期和时间python内建的datetime模块提供了datetime,date,time类型,datetime结合date和time是常使用的 1234567891011121314151617181920212223%a 星期的英文单词的缩写：如星期一， 则返回 Mon%A 星期的英文单词的全拼：如星期一，返回 Monday%b 月份的英文单词的缩写：如一月， 则返回 Jan%B 月份的引文单词的缩写：如一月， 则返回 January%c 返回datetime的字符串表示，如03/08/15 23:01:26%d 返回的是当前时间是当前月的第几天%f 微秒的表示： 范围: [0,999999]%H 以24小时制表示当前小时%I 以12小时制表示当前小时%j 返回 当天是当年的第几天 范围[001,366]%m 返回月份 范围[0,12]%M 返回分钟数 范围 [0,59]%P 返回是上午还是下午–AM or PM%S 返回秒数 范围 [0,61]。。。手册说明的%U 返回当周是当年的第几周 以周日为第一天%W 返回当周是当年的第几周 以周一为第一天%w 当天在当周的天数，范围为[0, 6]，6表示星期天%x 日期的字符串表示 ：03/08/15%X 时间的字符串表示 ：23:22:08%y 两个数字表示的年份 15%Y 四个数字表示的年份 2015%z 与utc时间的间隔 （如果是本地时间，返回空字符串）%Z 时区名称（如果是本地时间，返回空字符串） 时间替换和时间差 控制流在python中有若干的关键字进行条件逻辑,循环,以及其他控制流操作 if,elif,else for循环contiunecontiune代表着当次循环跳过,继续进行下一次的循环 breakbreak代表着跳出整个循环,并结束循环的过程 while循环 passpass是python中的非操作语句,代码块不需要执行任何动作 rangerang函数返回一个迭代器,用来产生一个均匀分布的整数序列 注意:虽然range可以产生任意大的序号.所耗用的时长和内容比较小 三元表达式]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>面向对象</tag>
        <tag>语言基础2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之python基础语法1]]></title>
    <url>%2F2020%2F02%2F16%2F2020-02-15-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bpython%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%951%2F</url>
    <content type="text"><![CDATA[从语言思维来牢记基础,对于我们用语言来创造是必要的. python语言基础 语言的艺术 语言的标准 语言的艺术 语言的语义 python语言在编写的时候强调的是可读性,简洁,清晰. 语言使用缩进而不是括号 使用tab或者4个空格来组织自己的代码 增加可读性,简洁 万物皆对象 在python所构建的数据都是对象,而这个对象拥有一致性也就是目标和目的是一致的 每个数字,字符串,数据结构等都是对象,对象中都有自己的数据类型和内部数据 注释 注释注重解释 函数和对象上的方法调用 定义函数,调用函数,定义对象,对象方法调用 语言的标准变量和参数的传递 变量即是创建一个名字,而等号右边则是这个变量所代表的含义即是数据 a和b都是同一个引用,指向的是具体的对象 赋值=绑定,传递对象赋值称作为绑定,把一个名字绑定给一个对象,变量名可能被称为绑定变量 把对象传递给函数的时候,不会复制,而是直接引用 动态引用和强类型 注意知晓元组类型 属性和方法对象都拥有属性和方法 对象拥有属性和方法 鸭子类型如果不关心对象的类型,只关心是否有些方法和用途,这种称作为鸭子类型,比如你只想关心这个对象是否可以迭代.那么可以 关于模块的引入引入模块有三种形式 引入整个模块 引入模块中的某个部分 引入的模块构建一个别名 二元运算符和比较运算符 1234567891011121314151617181920212223242526272829a+b : a加ba-b : a减ba*b : a乘ba/b : a除以ba//b:a整除以b,表示的是返回a除以b的结果的整数部分，而不是证明了a能被b整除。要证明a能被b整除，可以是if a%b==0: 或者a/b＝int 等等a**b : a的b次方a&amp;b : a与b,对于整数则是按位ANDa|b : a或b,对于整数则是按位ORa^b : 对布尔值，a异或b,对于整数则是按位异或a==b : a和b相等则为Turea!=b: a和b不相等则为Turea&lt;=b,a&lt;b : 小于等于，小于a&gt;=b,a&gt;b : 大于等于，大于a is b: a和b是同一个python对象则为Turea is not b: a和b不是同一个python对象则为Ture 在python中is是判断对象,==才是判断对象里面的内容是否一样 可变和不可编对象在python的大多数对象中,如:列表,字典,Numpy数组和用户自定义类型都是可变的 但是对于字符串和元组是不可变的]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>语言基础</tag>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之常用操作]]></title>
    <url>%2F2020%2F02%2F14%2F2020-02-14-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[熟知一些基本操作,能够加快你的学习效率。 python日常操作 python交互工具jupyter_notebook日常使用 notebook的使用命令窗口中输入jupyter notebook可以在切换到自己要写笔记的目录中 在notenook中第一次操作 注意:我们在使用的时候可以输入关键字的用Tab键进行补全操作 Tab补全说明1.Tab补全不是万能的,会尽可能的补全你的代码.按下Tab会搜索已输入的变量(对象,函数等等) 2.同样的tab也适应于模块 3.同样适用与函数 自省操作通过自省可以关注对象的类型 针对自定义函数 其余额外的命令 %run命令可以用来执行某一个位置上的py文件 %load命令可以将代码导入到某一个位置中 使用Ctrl+C可以随时终端执行中的程序 魔术命令魔术命令是指在指令面前加上%,可以是普通任务更快捷,更方便 注意:没下载numpy的话可以执行 pip3 install numpy 常用的魔术命令%quickref 显示IPython的快速参考 %magic 显示所有魔术命令的详细文档 %debug 从最新的异常跟踪的底部进入交互式调试器 %hist 打开命令的输入（可选输出）历史 %pdb 在异常发生后自动进入调试器 %paste 执行剪贴板中的Python代码 %cpaste 打开一个特殊的提示符以便于手工粘贴待执行的Python代码 %reset 删除interactive命名空间中的全部变量、名称 %page OBJECT 通过分页器打印出OBJECT %run script.py 执行Python脚本文件 %prun statement 通过cProfile执行statement,并打印分析器的输出结果 %time statement 报告statement的执行时间 %timeit statement 多次执行statement以计算系综合平均执行时间。对那些执行时间非常小的代码有用 %who、%who_ls、whos 显示interactive命名空间中定义的变量，信息级别/冗余度可变 %xdel variable 删除variable,并尝试清除其在IPython中的对象上的一切引用 后面在使用的时候可以在回过来进行查找 集成美丽的制图同样的需要安装制图执行命令:pip3 install matplotlib -i https://pypi.douban.com/simple/ 知识补充1.np.random.randn(50) 代表着返回一组标准正态分布的随机值,范围在-1.96～+1.96 2.numpy.cumsum()代表着累加求和 1 1+2 1+2+3 依次类推 3.plt.plot()代表着线性制图 %matplotlib inline 用于省掉plt.show()]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>数据的禅意</tag>
        <tag>日常操作</tag>
        <tag>初次接触</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析前的准备工作]]></title>
    <url>%2F2020%2F02%2F14%2F2020-02-14-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%89%8D%E7%9A%84%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[做好数据分析,先好好理解数据和工具 数据分析前的准备工作 数据与python python处理数据问题上面重要的库 环境安装以及常用的学习工具与开发工具 数据与python数据数据这个词是抽象的,我们如何认识数据,有2个点我们需要我们作为前提 数据有可能代表是世界,人等一切事物,及时杂乱无序,但是也在当中存在规律 从数据中找到合适的规律和特点,那么我们需要结构化数据。那么结构化的数据有哪些？比如:表格类型的数据,多维数组,通过关键列构建的表格类型数据等 注意:大部分数据集都能转换成结构化的数据,结构化只是一种形式,更多的还是人自主的思维能力.比如:一组新闻文章里面的内容可以提取出词频表,而这个表就可以对于以后的情感进行分析 为什么选择用python python作为胶水语言可以随时沾和随时撕掉 python语言在设计的过程中就是构建以数据为中心的应用型数据 python适用于构建分析应用和一些常见的通用系统(日常的管理系统) 注:python作为一种解释性语言没有编译性语言的运行时间效率要高.这也是python的不足之处 python重要的库 Numpy (数值处理) 可以构建快速高效的多维数组对象(ndarray) 可以用于对数组执行数学运算和计算.提供了大量的函数 可以用于读写硬盘中基于数组的数据集的工具 常见的线性代数等包含随机数的生成 pandas (面板数据) 能够处理大量结构化数据 常用的2个对象一个是DataFrame和Series,分别是面向列的二维表结构以及一个一维的标签化数组对象 提供复杂精细的索引功能,能够快速的完成重塑,切片,切块,聚合以及选取数据子集等操作 matplotlib 绘制图表以及其他二维数据可视化的工具 ipython与jupyter 2个都是良好的交互工具 ipython用于运行，调试，测试等操作 jupyter良好的学习笔记工具 Scipy与scikit-learn与statsmodels Scipy解决计算中各种标准问题域 scikit-learn机器学习的工具包,偏重于预测 statsmodels统计分析包,偏重于统计与推断 环境安装以及常用的学习工具python环境的安装python环境的安装不在进行说明,只是需要注意的是检查不同系统的变量设置,macos系统比较特殊,需要检查.bash_prifile中是否添加 ipython jupyter 1.更新pippython -m pip install -U pip setuptools 2.安装,使用国内源满速安装pip install jupyter -i https://pypi.tuna.tsinghua.edu.cn/simple 3.在命令中直接jupyter notebook]]></content>
      <categories>
        <category>大数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>数据的禅意</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams晋阶之路(归约和聚合)]]></title>
    <url>%2F2020%2F01%2F08%2F2020-01-08-kafkaStream%E6%99%8B%E9%98%B6%E4%B9%8B%E8%B7%AF(%E5%BD%92%E7%BA%A6%E5%92%8C%E8%81%9A%E5%90%88)%2F</url>
    <content type="text"><![CDATA[归约比聚合相对容易,但是聚合可以做更多的事情 知识点 归约和聚合概念 解决实际需求 如何归约 如何聚合 归约和聚合概念1.归约即是reduce,代表着累加求和，无论是在现在的python已经jdk新特性中都有体现 2.聚合即是aggregate,代表着聚集合并在一起的操作,一般来说归约和聚合在一起是一种完美的搭配 相对参考的文章 解决实际需求 比如股票在不断的交易。累计计算从开始成交的总和 总和有的情况下,获取交易量前5.(按照成交量决定) 如何归约(代码示例)reduce构建一个普通的用户交易记录123456789101112131415161718public class StockTransaction &#123; //股票标记 private String symbol; //股票领域 private String sector; //股票分类 private String industry; //成交量 private int shares; //成交价格 private double sharePrice; //用户编号 private String customerId; //交易时间 private Date transactionTimestamp; //是否成交 private boolean purchase;&#125; 构建一个提取交易量的记录类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ShareVolume &#123; //股票标记 private String symbol; //成交量 private int shares; //股票领域 private String industry; public String getSymbol() &#123; return symbol; &#125; public void setSymbol(String symbol) &#123; this.symbol = symbol; &#125; public int getShares() &#123; return shares; &#125; public void setShares(int shares) &#123; this.shares = shares; &#125; public String getIndustry() &#123; return industry; &#125; public void setIndustry(String industry) &#123; this.industry = industry; &#125; public ShareVolume() &#123; // TODO Auto-generated constructor stub &#125; public ShareVolume(String symbol, int shares, String industry) &#123; super(); this.symbol = symbol; this.shares = shares; this.industry = industry; &#125; //构建一个shareVolume对象 public static ShareVolume buildInstance(StockTransaction st) &#123; ShareVolume sv = new ShareVolume(st.getSymbol(), st.getShares(), st.getIndustry()); return sv; &#125; //构建一个统计总和对象 public static ShareVolume sum(ShareVolume s1,ShareVolume s2) &#123; ShareVolume sv = new ShareVolume(); sv.setIndustry(s2.getIndustry()); sv.setSymbol(s1.getSymbol()); sv.setShares(s1.getShares()+s2.getShares()); return sv; &#125;&#125; 分别构建对应的序列化器12345678910111213public class ShareVolumeSerde extends WrapperSerde&lt;ShareVolume&gt; &#123; public ShareVolumeSerde() &#123; super(new JsonSerializer&lt;&gt;(), new JsonDeserializer&lt;&gt;(ShareVolume.class)); &#125;&#125;-------------------public class StockTransactionSerde extends WrapperSerde&lt;StockTransaction&gt; &#123; public StockTransactionSerde() &#123; super(new JsonSerializer&lt;&gt;(), new JsonDeserializer&lt;&gt;(StockTransaction.class)); &#125;&#125; 构建流程序 先看下reduce接口 123456789101112public interface Reducer&lt;V&gt; &#123; /** * 合二为一 * Aggregate the two given values into a single one. * * @param value1 the first value for the aggregation * @param value2 the second value for the aggregation * @return the aggregated value */ V apply(final V value1, final V value2);&#125; 流程序代码示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class RG_Stream &#123; public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;KTable-aggregations&quot;); props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;KTable-aggregations-id&quot;); props.put(ConsumerConfig.CLIENT_ID_CONFIG, &quot;KTable-aggregations-client&quot;); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;); props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;30000&quot;); props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, &quot;10000&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, &quot;1&quot;); props.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, &quot;10000&quot;); props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName()); props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, new StockTransactionSerde().getClass().getName()); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); /** * 构建流 */ StreamsConfig streamsConfig = new StreamsConfig(props); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); KeyValueMapper&lt;String, ShareVolume, String&gt; classKey1 = (key, sharevolume) -&gt; sharevolume.getSymbol(); KStream&lt;String, ShareVolume&gt; shareStream = streamsBuilder.stream(&quot;STTOPIC&quot;,Consumed.with(Serdes.String(),new StockTransactionSerde())) .mapValues(st -&gt;ShareVolume.buildInstance(st)); shareStream.print(Printed.&lt;String, ShareVolume&gt;toSysOut().withLabel(&quot;股票信息&quot;)); KTable&lt;String, ShareVolume&gt; shareKTable = shareStream .selectKey(classKey1) .groupByKey(Serialized.with(Serdes.String(), new ShareVolumeSerde())) .reduce(ShareVolume::sum); shareKTable.toStream().print(Printed.&lt;String, ShareVolume&gt;toSysOut().withLabel(&quot;股票成交量总量变更&quot;)); // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125; &#125; 注意:在流内部设置从最先开始消费,这个配置大于初始配置。 代码测试 开起zookeeper 开起kafka 创建主题”STTOPIC” 启动流程序 模拟数据发送 123456789101112131415161718192021222324public class TestProducer2 &#123; public static void main(String[] args) &#123; //模拟数据 StockTransaction record = new StockTransaction(); record.setSymbol(&quot;好当家&quot;); record.setSector(&quot;食品&quot;); record.setIndustry(&quot;生产类&quot;); record.setShares(1000); record.setSharePrice(5.00); record.setCustomerId(&quot;001&quot;); record.setTransactionTimestamp(new Date()); record.setPurchase(true); //配置生产者 Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); properties.put(&quot;acks&quot;, &quot;1&quot;); properties.put(&quot;retries&quot;, &quot;3&quot;); properties.put(&quot;compression.type&quot;, &quot;snappy&quot;); KafkaProducer&lt;String, StockTransaction&gt; kp = new KafkaProducer&lt;String,StockTransaction&gt;(properties,new StringSerializer(),new JsonSerializer&lt;StockTransaction&gt;()); kp.send(new ProducerRecord&lt;String, StockTransaction&gt;(&quot;STTOPIC&quot;, record)); kp.close(); &#125;&#125; 结论如下: 即使是断掉程序，在重启程序后，计算依然保持从头开始 如何聚合(代码示例)aggregate在聚合之前,归约是聚合的一种形式。归约操作是将产生相同类型的对象,聚合也是对结果求和。但是可以返回不同的类型 现在有一个需求,获取股票交易量前5的，降序产生 构建一个降序的优先级队列并构建序列化器 12345678910111213141516171819202122232425262728293031public class FixedSizePriorityQueue&lt;T&gt; &#123; private TreeSet&lt;T&gt; inner; private int maxSize; public FixedSizePriorityQueue(Comparator&lt;T&gt; comparator, int maxSize) &#123; this.inner = new TreeSet&lt;&gt;(comparator); this.maxSize = maxSize; &#125; public FixedSizePriorityQueue&lt;T&gt; add(T element) &#123; inner.add(element); if (inner.size() &gt; maxSize) &#123; inner.pollLast(); &#125; return this; &#125; public FixedSizePriorityQueue&lt;T&gt; remove(T element) &#123; if (inner.contains(element)) &#123; inner.remove(element); &#125; return this; &#125; public Iterator&lt;T&gt; iterator() &#123; return inner.iterator(); &#125;&#125; 改进流式程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class RG_Stream &#123; public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;KTable-aggregation&quot;); props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;KTable-aggregations-i&quot;); props.put(ConsumerConfig.CLIENT_ID_CONFIG, &quot;KTable-aggregations-clien&quot;); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;); props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;30000&quot;); props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, &quot;10000&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, &quot;1&quot;); props.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, &quot;10000&quot;); props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName()); props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, new StockTransactionSerde().getClass().getName()); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); /** * 构建流 */ StreamsConfig streamsConfig = new StreamsConfig(props); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); /** * 使用reduce */ KeyValueMapper&lt;String, ShareVolume, String&gt; classKey1 = (key, sharevolume) -&gt; sharevolume.getSymbol(); KStream&lt;String, ShareVolume&gt; shareStream = streamsBuilder.stream(&quot;ST2&quot;,Consumed.with(Serdes.String(),new StockTransactionSerde())) .mapValues(st -&gt;ShareVolume.buildInstance(st)); shareStream.print(Printed.&lt;String, ShareVolume&gt;toSysOut().withLabel(&quot;股票信息&quot;)); KTable&lt;String, ShareVolume&gt; shareKTable = shareStream .selectKey(classKey1) .groupByKey(Serialized.with(Serdes.String(), new ShareVolumeSerde())) .reduce(ShareVolume::sum); shareKTable.toStream().print(Printed.&lt;String, ShareVolume&gt;toSysOut().withLabel(&quot;股票成交量总量变更&quot;)); /** * 使用aggreate */ Comparator&lt;ShareVolume&gt; comparator = (s1,s2) -&gt; s2.getShares()-s1.getShares(); FixedSizePriorityQueue&lt;ShareVolume&gt; fixedQueue = new FixedSizePriorityQueue&lt;&gt;(comparator, 5); ValueMapper&lt;FixedSizePriorityQueue, String&gt; valueMapper = fpq -&gt;&#123; StringBuilder builder = new StringBuilder(); Iterator&lt;ShareVolume&gt; iterator = fpq.iterator(); int counter= 1; while (iterator.hasNext()) &#123; ShareVolume stockVolume = iterator.next(); if (stockVolume != null) &#123; builder.append(counter++).append(&quot;)&quot;).append(stockVolume.getSymbol()) .append(&quot;:&quot;).append(NumberFormat.getInstance().format(stockVolume.getShares())).append(&quot; &quot;); &#125; &#125; return builder.toString(); &#125;; //pair重新生成 new key-value pair KTable&lt;String, String&gt; fixKTable = shareKTable.groupBy((k, v) -&gt; KeyValue.pair(v.getIndustry(), v), Serialized.with(Serdes.String(), new ShareVolumeSerde())) .aggregate(() -&gt; fixedQueue, (k, v, agg) -&gt; agg.add(v), (k, v, agg) -&gt; agg.remove(v), Materialized.with(Serdes.String(), new FixedSizePriorityQueueSerde())) .mapValues(valueMapper); //peek可用于作日志记录 .peek((k,v) -&gt; System.out.println(&quot;key值&quot;+k+&quot;------value&quot;+v)); fixKTable.toStream() .print(Printed.&lt;String, String&gt;toSysOut().withLabel(&quot;股票信息&quot;)); // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125; &#125; 额外附属的操作(添加对复杂对象的序列化适配器) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class FixedSizePriorityQueueAdapter extends TypeAdapter&lt;FixedSizePriorityQueue&lt;ShareVolume&gt;&gt; &#123; private Gson gson = new Gson(); /** * 需要被序列化的对象 */ @Override public void write(JsonWriter writer, FixedSizePriorityQueue&lt;ShareVolume&gt; value) throws IOException &#123; if (value == null) &#123; writer.nullValue(); return; &#125; Iterator&lt;ShareVolume&gt; iterator = value.iterator(); List&lt;ShareVolume&gt; list = new ArrayList&lt;&gt;(); while (iterator.hasNext()) &#123; ShareVolume stockTransaction = iterator.next(); if (stockTransaction != null) &#123; list.add(stockTransaction); &#125; &#125; writer.beginArray(); for (ShareVolume transaction : list) &#123; writer.value(gson.toJson(transaction)); &#125; writer.endArray(); &#125; /** * 反序列化实例 */ @Override public FixedSizePriorityQueue&lt;ShareVolume&gt; read(JsonReader reader) throws IOException &#123; List&lt;ShareVolume&gt; list = new ArrayList&lt;&gt;(); reader.beginArray(); while (reader.hasNext()) &#123; list.add(gson.fromJson(reader.nextString(), ShareVolume.class)); &#125; reader.endArray(); Comparator&lt;ShareVolume&gt; c = (c1, c2) -&gt; c2.getShares() - c1.getShares(); FixedSizePriorityQueue&lt;ShareVolume&gt; fixedSizePriorityQueue = new FixedSizePriorityQueue&lt;&gt;(c, 5); for (ShareVolume transaction : list) &#123; fixedSizePriorityQueue.add(transaction); &#125; return fixedSizePriorityQueue; &#125;&#125; 注册到反序列化器中(修订) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class JsonDeserializer&lt;T&gt; implements Deserializer&lt;T&gt; &#123; private Gson gson; private Class&lt;T&gt; deserializedClass; private Type reflectionTypeToken; public JsonDeserializer(Class&lt;T&gt; deserializedClass) &#123; this.deserializedClass = deserializedClass; init(); &#125; public JsonDeserializer(Type reflectionTypeToken) &#123; this.reflectionTypeToken = reflectionTypeToken; init(); &#125; private void init () &#123; GsonBuilder builder = new GsonBuilder(); builder.registerTypeAdapter(FixedSizePriorityQueue.class, new FixedSizePriorityQueueAdapter().nullSafe()); gson = builder.create(); &#125; public JsonDeserializer() &#123; &#125; @Override @SuppressWarnings(&quot;unchecked&quot;) public void configure(Map&lt;String, ?&gt; map, boolean b) &#123; if(deserializedClass == null) &#123; deserializedClass = (Class&lt;T&gt;) map.get(&quot;serializedClass&quot;); &#125; &#125; @Override public T deserialize(String s, byte[] bytes) &#123; if(bytes == null)&#123; return null; &#125; Type deserializeFrom = deserializedClass != null ? deserializedClass : reflectionTypeToken; return gson.fromJson(new String(bytes),deserializeFrom); &#125; @Override public void close() &#123; &#125; &#125;&#125; FixedSizePriorityQueueSerde修订 123456public class FixedSizePriorityQueueSerde extends WrapperSerde&lt;FixedSizePriorityQueue&gt;&#123; public FixedSizePriorityQueueSerde() &#123; super(new JsonSerializer&lt;&gt;(), new JsonDeserializer&lt;&gt;(new TypeToken&lt;FixedSizePriorityQueue&lt;ShareVolume&gt;&gt;() &#123;&#125;.getType())); &#125;&#125; 注意: ShareVolume同时实现compareble 后续代码改进:可以考虑修订comparetor 测试代码通过 关机重启 数据计算保持一致]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>数据状态</tag>
        <tag>聚合</tag>
        <tag>归约</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams晋阶之路(KTable)]]></title>
    <url>%2F2020%2F01%2F03%2F2020-01-03-kafkaStream%E6%99%8B%E9%98%B6%E4%B9%8B%E8%B7%AF(KTable)%2F</url>
    <content type="text"><![CDATA[只有清晰的明白流和表，你才有可能明白聚合以及开窗 知识要点 流与表的关系 记录流概念 更新记录和日志 2者之间的对比 工作原理 流与表的关系在生活中,我们无时无刻都在产生一些事件,每个事件上面都可以看成在历史的记录中不断的添加一笔新的操作.而这些记录与其他的记录无关，都是独立的。 记录流的概念流被定义为无限的事件序列 例如股票市场中,每只股票的报价都是一个离散时间,它们彼此之间没有任何关联。即使一家公司股票有多次报价。在某个时候我们称作为记录流,如图: 每个时间就是一个插入项，为表中每个插入项建立一个地增量为1的key 更定记录和变更日志如果讲事件流看成是一个日志,更新流可以看成是一个不断在变更的日志。 如上图所示，如果以股票名字作为主键。那么动作发生将是更新操作。 注意:日志和变更日志都是讲记录追加到文件末尾,在日志中可以看到所有的记录.但是在变更日志中,对任何一个给定键只保留最新记录。 对于变更日志和更新流来说,我们用KTable进行抽象的表现与描述 2者之间的对比通过代码我们来进行呈现说明 构建股票信息类StockMsg 123456public class StockMsg &#123; //股票价格 private double stockPrice; //股票名字 private String stockName; &#125; 改进通用化序列器 123456789101112131415161718192021222324252627282930313233343536373839404142public class WrapperSerde&lt;T&gt; implements Serde&lt;T&gt;&#123; private JsonSerializer&lt;T&gt; serializer; private JsonDeserializer&lt;T&gt; deserializer; public WrapperSerde() &#123; super(); // TODO Auto-generated constructor stub &#125; public WrapperSerde(JsonSerializer&lt;T&gt; serializer, JsonDeserializer&lt;T&gt; deserializer) &#123; this.serializer = serializer; this.deserializer = deserializer; &#125; @Override public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123; // TODO Auto-generated method stub &#125; @Override public void close() &#123; // TODO Auto-generated method stub &#125; @Override public Serializer&lt;T&gt; serializer() &#123; // TODO Auto-generated method stub return serializer; &#125; @Override public Deserializer&lt;T&gt; deserializer() &#123; // TODO Auto-generated method stub return deserializer; &#125;&#125; 类序列器的构建 123456public class StockSerde extends WrapperSerde&lt;StockMsg&gt;&#123; public StockSerde() &#123; super(new JsonSerializer&lt;&gt;(), new JsonDeserializer&lt;&gt;(StockMsg.class)); &#125;&#125; 构建流式程序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class KTVSKS_Stream &#123; public static void main(String[] args) &#123; Properties props = new Properties(); // stream流的名字 props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;KStreamVSKTable_app&quot;); // 消费者组名字 props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;KStreamVSKTable_group&quot;); // 消费者名字 props.put(ConsumerConfig.CLIENT_ID_CONFIG, &quot;KStreamVSKTable_client&quot;); // 每次消费最新的数据 props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;); // 自动提交偏移 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;30000&quot;); props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, &quot;15000&quot;); // 服务器地址 props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); // 并行的线程数 props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, &quot;1&quot;); props.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, &quot;10000&quot;); props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName()); props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, new StockSerde().getClass().getName()); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); /** * 构建流 */ StreamsConfig streamsConfig = new StreamsConfig(props); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); // 分别创建KStream和KTable实例并打印 KeyValueMapper&lt;String, StockMsg, String&gt; classKey1 = (key, stock) -&gt; stock.getStockName(); KStream&lt;String, StockMsg&gt; stockStream = streamsBuilder.stream(&quot;STOCKTOPIC&quot;); KStream&lt;String, StockMsg&gt; ssKStream = stockStream.selectKey(classKey1); ssKStream.to(&quot;STOCKTOPICTABLE&quot;); ssKStream.print(Printed.&lt;String, StockMsg&gt;toSysOut().withLabel(&quot;股市交易流&quot;)); KTable&lt;String, StockMsg&gt; stocKTable = streamsBuilder.table(&quot;STOCKTOPICTABLE&quot;); stocKTable.toStream().print(Printed.&lt;String, StockMsg&gt;toSysOut().withLabel(&quot;股市交易表&quot;)); // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125;&#125; 模拟生产者 12345678910111213141516public static void main(String[] args) &#123; //模拟数据 StockMsg record = new StockMsg(); record.setStockName(&quot;好当家&quot;); record.setStockPrice(3.09); //配置生产者 Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); properties.put(&quot;acks&quot;, &quot;1&quot;); properties.put(&quot;retries&quot;, &quot;3&quot;); properties.put(&quot;compression.type&quot;, &quot;snappy&quot;); KafkaProducer&lt;String, StockMsg&gt; kp = new KafkaProducer&lt;String,StockMsg&gt;(properties,new StringSerializer(),new JsonSerializer&lt;StockMsg&gt;()); kp.send(new ProducerRecord&lt;String, StockMsg&gt;(&quot;STOCKTOPIC&quot;, record)); kp.send(new ProducerRecord&lt;String, StockMsg&gt;(&quot;STOCKTOPICTABLE&quot;, record)); kp.close(); &#125; 测试 启动zookeeper 启动kafka 创建主题–STOCKTOPIC 和 STOCKTOPICTABLE 启动流程序 (需要指定key值) 模拟数据发送 注意:表始终在更新以最新的标准被基准，当然前提是流有进行过选择对应的key值 工作原理1.在创建KTable的时候,同时在后台创建了一个追踪流状态的状态存储,从而创建了一个更新流。创建后会有一个内容名称，但是 不能显式的进行交互式访问。但是KTable通过使用Materialized(计量)可以进行显式的查询 2.KTable何时进行更新,并发往下游处理器. 因素 较高的数据流入速率将增加发送更新记录的频率 不同键越多 通过配置cache.max.bytes.buffering以及commit.intrval.ms达到更新的设置 cache.max.bytes.buffering设置缓存缓冲大小 设置该缓存用于删除具有相同键重复的更新记录。使用持久化存储时就可以显著提升性能 commit.intrval.ms设置提交时间间隔 提交间隔参数用来指定保存数据的频率，它会强制刷新，将最新的记录更新，并发送到下游 注意:默认的提交时间是30秒以及默认10M缓存，当然在上线之前，肯定要平衡大小和时间以及处理的线程数。这个是需要进行考量的。]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>数据状态</tag>
        <tag>数据表</tag>
        <tag>遇见未来聚合和开窗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams晋阶之路(连接能力)]]></title>
    <url>%2F2019%2F12%2F30%2F2019-12-30-kafkaStream%E6%99%8B%E9%98%B6%E4%B9%8B%E8%B7%AF(%E8%BF%9E%E6%8E%A5)%2F</url>
    <content type="text"><![CDATA[连接以为可以观测时间,有了时间,我们才会具有洞察力. 知识点 连接的目的,增加洞察力 时间戳的定义以及分类 连接的目的在前期我们通过给定谓词(也就是加入筛选条件)将流分为了2类，比如钥匙类和小五金类 如何让这2个不同的流连接在一起,能够观察增加需求能力。 连接的要求 2个流以上 有一个相同的key,作为连接的条件 前期code如下 12345678910111213141516171819202122232425262728293031323334353637383940public class JoinStream &#123; private static final Logger LOG = LoggerFactory.getLogger(JoinStream.class); public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;SecondZmart-Kafka-Streams-App&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); // 配置当前时间 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); // 加载配置 StreamsConfig streamsConfig = new StreamsConfig(props); // 构建序列化器 // 默认的 Serde&lt;String&gt; stringSerde = Serdes.String(); // 自定义的(可优化) JsonSerializer&lt;PurchaseRecord&gt; ps = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;PurchaseRecord&gt; pds = new JsonDeserializer&lt;&gt;(PurchaseRecord.class); // 构建自定义序列化器 Serde&lt;PurchaseRecord&gt; PurchaseRecordSerde = Serdes.serdeFrom(ps, pds); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); //初次屏蔽处理器 KStream&lt;String, PurchaseRecord&gt; PurchaseRecordStream = streamsBuilder .stream(&quot;transactions&quot;, Consumed.with(stringSerde, PurchaseRecordSerde)) .mapValues(pr -&gt; ActionUtil.mask(pr)); //定义谓词,以及选择key键 Predicate&lt;String,PurchaseRecord&gt; isOne = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;钥匙套&quot;); Predicate&lt;String,PurchaseRecord&gt; isTwo = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;小五金&quot;); //获得分流的集合,并且在之前选择相同的key值 KStream&lt;String, PurchaseRecord&gt;[] branchesStream = PurchaseRecordStream.selectKey((k,v)-&gt; v.getFirstName()+v.getLastName()) .branch(isOne,isTwo); &#125;&#125; 如何建立连接 连接的记录,需要创建一个ValueJoiner&lt;V1,V2,R&gt;对象.V1和V2代表着接收的2个连接对象,他们应该有相同的key.类型可以不同。R代表着可以选择组合后返回的新的对象 新的合并对象设计 对象设计如下: 1234567public class CorrelatedPurchase &#123; private Date firstDate; private Date seconDate; private List&lt;String&gt; purchaseListItem; private double totalAmount; &#125; ValueJoiner设计代码如下: 123456789101112131415161718192021222324252627public class PurchaseJoiner implements ValueJoiner&lt;PurchaseRecord, PurchaseRecord, CorrelatedPurchase&gt; &#123; @Override public CorrelatedPurchase apply(PurchaseRecord value1, PurchaseRecord value2) &#123; Date date1 = value1 != null ? value1.getPurchaseDate():null; Date date2 = value2 != null ? value2.getPurchaseDate():null; String purchaseName1 = value1 != null ? value1.getItemPurchased():null; String purchaseName2 = value2 != null ? value2.getItemPurchased():null; List&lt;String&gt; purchasedItem = new ArrayList&lt;String&gt;(); if (purchaseName1 != null) &#123; purchasedItem.add(purchaseName1); &#125; if (purchaseName2 != null) &#123; purchasedItem.add(purchaseName2); &#125; Double price1 = value1 !=null ? value1.getPrice():0.0; Double price2 = value2 !=null ? value2.getPrice():0.0; return ActionUtil.getNewFace(date1, date2, purchasedItem, price1+price2); &#125;&#125; 实现连接1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class JoinStream &#123; private static final Logger LOG = LoggerFactory.getLogger(JoinStream.class); public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;SecondZmart-Kafka-Streams-App&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); // 配置当前时间 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); // 加载配置 StreamsConfig streamsConfig = new StreamsConfig(props); // 构建序列化器 // 默认的 Serde&lt;String&gt; stringSerde = Serdes.String(); // 自定义的(可优化) JsonSerializer&lt;PurchaseRecord&gt; ps = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;PurchaseRecord&gt; pds = new JsonDeserializer&lt;&gt;(PurchaseRecord.class); // 构建自定义序列化器 Serde&lt;PurchaseRecord&gt; PurchaseRecordSerde = Serdes.serdeFrom(ps, pds); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); //初次屏蔽处理器 KStream&lt;String, PurchaseRecord&gt; PurchaseRecordStream = streamsBuilder .stream(&quot;transactions&quot;, Consumed.with(stringSerde, PurchaseRecordSerde)) .mapValues(pr -&gt; ActionUtil.mask(pr)); //定义谓词,以及选择key键 Predicate&lt;String,PurchaseRecord&gt; isOne = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;钥匙套&quot;); Predicate&lt;String,PurchaseRecord&gt; isTwo = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;小五金&quot;); //获得分流的集合,并且在之前选择相同的key值 KStream&lt;String, PurchaseRecord&gt;[] branchesStream = PurchaseRecordStream.selectKey((k,v)-&gt; v.getFirstName()+v.getLastName()) .branch(isOne,isTwo); // 连接流 KStream&lt;String, PurchaseRecord&gt; stream1 = branchesStream[0]; KStream&lt;String, PurchaseRecord&gt; stream2 = branchesStream[1]; /** * 1.设置时间窗口 * 2.构建连接器 * 3.调用join产生连接.joined分别代表着key值序列化器,以及2个流value值的序列化器 */ JoinWindows f15sWindow = JoinWindows.of(60*1000); ValueJoiner&lt;PurchaseRecord, PurchaseRecord, CorrelatedPurchase&gt; joiner = new PurchaseJoiner(); KStream&lt;String, CorrelatedPurchase&gt; joinedKStream = stream1.join(stream2, joiner,f15sWindow,Joined.with(stringSerde, PurchaseRecordSerde, PurchaseRecordSerde)); joinedKStream.print(Printed.&lt;String, CorrelatedPurchase&gt;toSysOut().withLabel(&quot;joinedStream&quot;)); /** * 开起流 */ // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125; &#125; 代码测试 [joinedStream]: 王小十四, CorrelatedPurchase [firstDate=Mon Dec 30 11:18:12 CST 2019, seconDate=Mon Dec 30 11:18:21 CST 2019, purchaseListItem=[小小锅, 小小锅], totalAmount=40.0][joinedStream]: 王小十四, CorrelatedPurchase [firstDate=Mon Dec 30 11:18:45 CST 2019, seconDate=Mon Dec 30 11:18:21 CST 2019, purchaseListItem=[小小锅1, 小小锅], totalAmount=40.0][joinedStream]: 王小十四, CorrelatedPurchase [firstDate=Mon Dec 30 11:19:30 CST 2019, seconDate=Mon Dec 30 11:19:58 CST 2019, purchaseListItem=[榔头, 锤子], totalAmount=40.0][joinedStream]: 王小十四, CorrelatedPurchase [firstDate=Mon Dec 30 11:19:46 CST 2019, seconDate=Mon Dec 30 11:19:58 CST 2019, purchaseListItem=[打榔头, 锤子], totalAmount=40.0][joinedStream]: 王小十四, CorrelatedPurchase [firstDate=Mon Dec 30 11:21:12 CST 2019, seconDate=Mon Dec 30 11:20:57 CST 2019, purchaseListItem=[锤子1, 锤子], totalAmount=40.0][joinedStream]: 王小十四, CorrelatedPurchase [firstDate=Mon Dec 30 11:31:31 CST 2019, seconDate=Mon Dec 30 11:31:09 CST 2019, purchaseListItem=[锤子4, 锤子2], totalAmount=40.0][joinedStream]: 王小十四, CorrelatedPurchase [firstDate=Mon Dec 30 11:31:31 CST 2019, seconDate=Mon Dec 30 11:31:17 CST 2019, purchaseListItem=[锤子4, 锤子3], totalAmount=40.0] 只要符合交易时间,都会出发对应的链接操作.只要满足连接操作,可用foreachAction或者发送主题信息做对应的逻辑动作 连接的进阶记录的先后顺序从上面结果可以看到，数据的时间并没有关注先来后到,只要满足1分钟之内及产生逻辑 如何要指定顺序: 需要使用 JoinWindows.after 或者 JoinWindows.before 分别代表着 streamA.join(streamB) B的记录时间戳比A的记录时间滞后或者是提前. 连接的前提首要条件在Stream中执行连接操作,必要要保证数据具有相同数量的分区,按键分区且键的类型相同通过selectKey出发了重新分区的要求。这个是被自动处理的.这个动作我们归纳为协同分区 连接的动作 join 等同于 innerjoin outerJoin 等同于左右连接都满足 leftJoin 只需要左连接 kafkaStreams中时间戳时间戳的作用有3点: 连接流 更新变更日志 决定方法合适被触发 时间戳被kafkaStreams分为了三类 事件发生时间 特指事件发生时候的时间,通常设置在内置对象中,当然也可以考虑创建生产者的时间为事件时间 摄取时间 特指数据首次进入数据处理管道时设置的时间戳。可以考虑日志追加时间LogAppendTime作为摄取时间 处理时间 特指数据或者记录首次开始流经处理管道时设置的时间戳。 处理不同的时间语义 时间戳提取器 TimeStampExtractor接口 kafkaStreams自带一个处理时间语义WallclockTimestampExtractor本质是通过调用系统当前时间,以毫秒数返回当前时间 自定义时间戳 代码示例如下: 1234567891011public class TransactionTimestampExtractor implements TimestampExtractor&#123; @Override public long extract(ConsumerRecord&lt;Object, Object&gt; record, long previousTimestamp) &#123; // 获取发到kafka中的数据对象 PurchaseRecord ptRecord = (PurchaseRecord) record.value(); //返回数据本省所内置的时间 return ptRecord.getPurchaseDate().getTime(); &#125;&#125; 配置方式 一种是在流程序中统一添加 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, TransactionTimestampExtractor.class); 一种是在Consumed中配置 Consumed.with(Serdes.1,Serdes.2).withTimestampExtractor(new TransactionTimestampExtractor()); 梳理当前的DAG]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>数据状态</tag>
        <tag>连接形态</tag>
        <tag>洞察力</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams晋阶之路(数据状态)]]></title>
    <url>%2F2019%2F12%2F26%2F2019-12-26-kafkaStream%E6%99%8B%E9%98%B6%E4%B9%8B%E8%B7%AF(%E7%8A%B6%E6%80%81)%2F</url>
    <content type="text"><![CDATA[数据本来平淡无奇,一旦有了思想,数据变成为了有想法的一种境界状态 知识点 状态在流中的重要性 状态存储阅读历史,展望未来 分区一致.数据正确 状态存储的选择前置条件 使用状态存储 代码示例 状态在流中的重要性 什么是状态？ 状态是人赋予的主观意识判断。本身数据是无状态的。举个例子:股票的买卖交易，每天的交易买入卖出是一件很正常的事情。比如:9点30分买入1000只股票。10点买入1000只股票。 这个数据流现在无状态的。 但是如果在10点30分的时候如果该只股票出现了重大利好重组交易,数据从无变为了有状态。而这时候我们的主观意识已经在判断,是否前面这个买卖交易是否正常,这也可以说明这个是我们的价值观 流是否需要状态? 一个事件本身产生的流没有特别的特殊性,但是如果产生一些额外的上下文,那么可能会错过一些关键的机会，甚至于你可能会以全新的视角来看待这个事情. 很多时候流式处理意味着:彼此之间没有关联。源源不断的数据,当发生时就一定要加以时间处理。而状态的概念可能会产生静态的资源映像,比如对应到数据库中。 数据流的变化速度往往比数据表更新的更快更频繁。有些情况下,离散的数据已经携带了足够多的数据。但是通常情况下,数据流需要从某类存储的数据来加以丰富。 将状态操作应用到kafka_Stream中在前期的奖励节点中.对于每次客户的消费累计的奖励点数未做任何要求,如果假定现在用户的每一次消费达到一点奖励点数,我们会附上额外的动作,也是将本来不带状态的值，变为有状态的意义 12345public class RewardAccumulator &#123; private String customerId; private double purchaseTotal; &#125; 转变为 1234567891011public class RewardAccumulator &#123; private String customerId; private double purchaseTotal; //添加当前这笔消费的奖励点数 private int currentRewardPoints; //添加最后一次最后购买的时间 private int daysFromLastPurchase; //累计的奖励总点数 private long totalRewardPoints; &#125; 注意:设置奖励点的总数代码为: 123public void addRewardPoints(int previousTotalPoints) &#123; this.totalRewardPoints += previousTotalPoints;&#125; 状态存储阅读历史,展望未来如何进行存储 在kafkaStream中提供了一个基本的有状态的函数 transformvalues() 提供一个值转换器，转换器接口为ValueTransformer&lt;V,R&gt;,设置状态储存 构建一个值转换器代码示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class PurchaseRewardTransformer implements ValueTransformer&lt;PurchaseRecord, RewardAccumulator&gt;&#123; //声明一个状态存储变量 private KeyValueStore&lt;String, Integer&gt; stateStore; //声明一个状态存储的名字 private final String storeName; //声明上下文容器 private ProcessorContext context; public PurchaseRewardTransformer(String storeName) &#123; this.storeName = storeName; &#125; @Override public void init(ProcessorContext context) &#123; // TODO Auto-generated method stub this.context = context; stateStore = (KeyValueStore&lt;String, Integer&gt;) this.context.getStateStore(storeName); &#125; /** * 执行值转换时.会进入到transform方法中 */ @Override public RewardAccumulator transform(PurchaseRecord value) &#123; // TODO Auto-generated method stub //1. 执行和mapvalues一样的动作 RewardAccumulator reward = ActionUtil.getReward(value); System.out.println(reward.hashCode()); //2.使用状态存储总的奖励点数 Integer x = stateStore.get(reward.getCustomerId()); if (x !=null) &#123; System.out.println(&quot;进入条件判断&quot;); System.out.println(x); int total = x+reward.getCurrentRewardPoints(); System.out.println(total); stateStore.put(reward.getCustomerId(), total); &#125;else &#123; stateStore.put(reward.getCustomerId(), (int) reward.getCurrentRewardPoints()); &#125; System.out.println(&quot;当前用户&quot;+reward.getCustomerId()+&quot;的奖励点数为&quot;+stateStore.get(reward.getCustomerId())); System.out.println(&quot;执行相信的逻辑操作&quot;); return reward; &#125; @Override public RewardAccumulator punctuate(long timestamp) &#123; // TODO Auto-generated method stub return null; &#125; @Override public void close() &#123; // TODO Auto-generated method stub &#125;&#125; 分区一致,数据正确在kafkaStreams中在没有指定分区的时候,是按照轮询进行分区。而分区中有着对应的StreamTask.每个Task中有自己不同状态存储.对于上面我们使用存储,有可能客户的交易信息不会在同一个分区中.那么这个时候只有指定到相同的分区进行解决 使用流分区器解决 通过kafkaStream中的through可以创建一个中间主题,达到无缝分区 通过自定义分区器,解决数据分配到不同地方的问题 自定义流分区器如下: 123456789101112public class RewardsStreamPartitioner implements StreamPartitioner&lt;String, PurchaseRecord&gt;&#123; /** * 根据用户的姓氏进行匹配对应的分区 */ @Override public Integer partition(String key, PurchaseRecord value, int numPartitions) &#123; // TODO Auto-generated method stub return value.getFirstName().hashCode()%numPartitions; &#125;&#125; 状态存储的选择前置条件 数据本地化 故障恢复和容错 数据本地化 数据本地化对性能至关重要,通过一个流式程序处理百万级以上的数据,即使很小的网络延迟也会产生巨大的影响 流式程序尽管需要状态但是不是绝对的必要,但是应该设计在本地。应用程序的每个服务器和节点都应该有一个单独的数据存储 进程和线程之间不共享,即便一个进程失败,但不会影响其它的进程和线程 故障恢复和容错 在kafkaStreams中每个处理器都它的本地存储和一个用于备份状态存储的变更日志主题 使用状态存储 kafka添加状态存储使用stores类静态工厂创建storesupplier实例. 用于定制存储的附加类使用Meterialized(计量类)以及StoreBuilder类,高阶推荐用前者,低阶推荐后者。 除了本身这2个类之外,还分别提供了persistentKeyValueStore和lruMap,persistentWindowStore,persistentSeesionStore 状态存储容错以及改变日志主题 状态存储容错 所有的stateStoreSupplier默认都启用了日志,日志即是一个主题,该主题的作用是变更日志用来被封存储中的值,提供容错 配置变更日志主题 用于状态的变更日志采用压缩策略的主题.可以使用withLoggingEnabled进行配置 代码示例注意:重写奖励类的equals方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class StoreStream &#123; private static final Logger LOG = LoggerFactory.getLogger(StoreStream.class); public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;Store-Streams-App&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); // 配置当前时间 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); // 加载配置 StreamsConfig streamsConfig = new StreamsConfig(props); // 构建序列化器 // 默认的 Serde&lt;String&gt; stringSerde = Serdes.String(); // 自定义的(可优化) JsonSerializer&lt;PurchaseRecord&gt; ps = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;PurchaseRecord&gt; pds = new JsonDeserializer&lt;&gt;(PurchaseRecord.class); JsonSerializer&lt;RewardAccumulator&gt; rs = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;RewardAccumulator&gt; rds = new JsonDeserializer&lt;&gt;(RewardAccumulator.class); // 构建自定义序列化器 Serde&lt;PurchaseRecord&gt; PurchaseRecordSerde = Serdes.serdeFrom(ps, pds); Serde&lt;RewardAccumulator&gt; RewardAccumulatorSerde = Serdes.serdeFrom(rs, rds); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); // 流拓扑 /** * mapValues 原始的键不会发生变化 ，可获取到传递进来的Value值 */ KStream&lt;String, PurchaseRecord&gt; PurchaseRecordStream = streamsBuilder .stream(&quot;transactions&quot;, Consumed.with(stringSerde, PurchaseRecordSerde)) .mapValues(pr -&gt; ActionUtil.mask(pr)); /** * 加入状态处理器 */ //状态名字 String rewardsStateStoreName = &quot;rewardsPointsStore&quot;; //指定分区规则,集群环境下 RewardsStreamPartitioner streamPartitioner = new RewardsStreamPartitioner(); //选择存储状态的类型 KeyValueBytesStoreSupplier storeSupplier = Stores.inMemoryKeyValueStore(rewardsStateStoreName); StoreBuilder&lt;KeyValueStore&lt;String, Integer&gt;&gt; storeBuilder = Stores.keyValueStoreBuilder(storeSupplier, Serdes.String(), Serdes.Integer()); /** * storeBuilder.withLoggingEnabled(config) 可以使用该方法进行日志主题的配置 */ //添加到拓扑中 streamsBuilder.addStateStore(storeBuilder); /** * 将原本的流设计重新分区的方式,通过产生一个中间主题进行操作 * 因为现在只有一个分区。故不配置分区 */ //KStream&lt;String, PurchaseRecord&gt; transByCustomerStream = PurchaseRecordStream.through( &quot;customer_transactions&quot;, Produced.with(stringSerde, PurchaseRecordSerde, streamPartitioner)); KStream&lt;String, PurchaseRecord&gt; transByCustomerStream = PurchaseRecordStream.through( &quot;customer_transactions&quot;, Produced.with(stringSerde, PurchaseRecordSerde)); /** * 转换为有状态的流 */ KStream&lt;String, RewardAccumulator&gt; statefulRewardAccumulator = transByCustomerStream.transformValues(() -&gt; new PurchaseRewardTransformer(rewardsStateStoreName), rewardsStateStoreName); statefulRewardAccumulator.print(Printed.&lt;String, RewardAccumulator&gt;toSysOut().withLabel(&quot;rewards&quot;)); /** * 开起流 */ // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125; &#125; 代码测试观察结果 启动zookeeper 启动kafka 启动流 模拟数据 数据结果如下:（包含服务器断掉重连,依旧保持先前的记录）]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>数据状态</tag>
        <tag>主观意识形态</tag>
        <tag>数据形态</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams(3-4)]]></title>
    <url>%2F2019%2F12%2F16%2F2019-12-16-%E5%BC%80%E5%8F%91kafka_Stream(3-4)%2F</url>
    <content type="text"><![CDATA[kafka实时计算出版效果. springboot结合kafkaStream流推送消息Echart图形展示(3-4) 实现要求(学生名字,学生年龄,班级) (班级多少人,年龄分布人数,实时) 构建流式程序2个步骤(一个处理统计班级人数,一个统计年龄分布人数) 从studentMsg主题源获取数据,通过2个处理器处理输出到classCount和ageCount主题源中 Echarts采取使用南丁玫瑰图 存放数据采取使用ConcurrentSkipListMap&lt;&gt;(); 构建DAG图 构建一个普通的maven项目12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-streams --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-streams&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.8.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 数据模拟 在producer中随机录入数据 123456789101112131415161718192021222324252627&lt;script type=&quot;text/javascript&quot;&gt;function randomData()&#123; var x = 100; var y = 0; var z = 10; var studentAge = (parseInt(Math.random() * (x - y + 1) + y)).toString(); var studentClassNo = &quot;00&quot;+parseInt(Math.random() * (z - y + 1) + z); $.ajax(&#123; url:&apos;$&#123;pageContext.request.contextPath&#125;/mock&apos;, type:&apos;post&apos;, dataType:&apos;json&apos;, data:&#123; studentName:&apos;小小王&apos;, studentAge:studentAge, studentClassNo:studentClassNo &#125;, success:function(resp)&#123; &#125; &#125;)&#125;$(function()&#123; $(&quot;button&quot;).click(function()&#123; t = setInterval(&quot;randomData()&quot;, 1000); &#125;)&#125;) 构建一个模块编写流式程序 项目结构 构建必要的序列化器 创建流式程序选择必要的序列器 流式程序设置必要的序列器 项目结构 必要的序列化器代码 序列化器 12345678910111213141516171819202122public class StudentSer implements Closeable, AutoCloseable, Serializer&lt;Student&gt;&#123; private static final Charset CHARSET = Charset.forName(&quot;UTF-8&quot;); static private Gson gson = new Gson(); @Override public void configure(Map&lt;String, ?&gt; map, boolean b) &#123; &#125; @Override public byte[] serialize(String s, Student person) &#123; // Transform the Person object to String String line = gson.toJson(person); // Return the bytes from the String &apos;line&apos; return line.getBytes(CHARSET); &#125; @Override public void close() &#123; &#125;&#125; 反序列化器 123456789101112131415161718192021222324252627public class StudentDser implements Closeable, AutoCloseable, Deserializer&lt;Student&gt; &#123; private static final Charset CHARSET = Charset.forName(&quot;UTF-8&quot;); static private Gson gson = new Gson(); @Override public void configure(Map&lt;String, ?&gt; map, boolean b) &#123; &#125; @Override public Student deserialize(String topic, byte[] bytes) &#123; try &#123; // Transform the bytes to String String student = new String(bytes, CHARSET); // Return the Person object created from the String &apos;person&apos; return gson.fromJson(student, Student.class); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(&quot;Error reading bytes&quot;, e); &#125; &#125; @Override public void close() &#123; &#125;&#125; 序列化组合 123456789101112131415161718192021222324252627public class StudentSerde implements Serde&lt;Student&gt;&#123; private StudentSer serializer = new StudentSer(); private StudentDser deserializer = new StudentDser(); @Override public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123; serializer.configure(configs, isKey); deserializer.configure(configs, isKey); &#125; @Override public void close() &#123; serializer.close(); deserializer.close(); &#125; @Override public Serializer&lt;Student&gt; serializer() &#123; return serializer; &#125; @Override public Deserializer&lt;Student&gt; deserializer() &#123; return deserializer; &#125;&#125; 流式计算程序代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class ClassCountStream &#123; private static final Logger LOG = LoggerFactory.getLogger(ClassCountStream.class); public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;Count-Kafka-Streams-App&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, &quot;exactly_once&quot;); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()); // Here we set the Seder for the values that we are going to process. props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, StudentSerde.class); // 配置当前时间 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); // 加载配置 StreamsConfig streamsConfig = new StreamsConfig(props); // 构建序列化器 // 默认的 Serde&lt;String&gt; stringSerde = Serdes.String(); Serde&lt;Long&gt; longSerde = Serdes.Long(); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); /** * 统计班级人数 */ // 声明键值 // 声明keyValueMapper创建谓词匹配对应的key值 //根据班级进行人数归类 KeyValueMapper&lt;String, Student, String&gt; classKey0 = (key, student) -&gt; student.getStudentClassNo(); KStream&lt;String, Student&gt; ClassCountStream = streamsBuilder.stream(&quot;studentMsg&quot;); KTable&lt;String, Long&gt; ClassCounTable = ClassCountStream.selectKey(classKey0) .groupByKey() .count(); //根据年龄筛选20-25岁的人均分布 KeyValueMapper&lt;String, Student, String&gt; classKey1 = (key, student) -&gt; student.getStudentAge(); KStream&lt;String, Student&gt; AgeCountStream = ClassCountStream; KTable&lt;String, Long&gt; AgeCountTable = AgeCountStream.filter((key,student) -&gt; Integer.parseInt(student.getStudentAge()) &gt; 0) .selectKey(classKey1) .groupByKey() .count(); ClassCounTable.toStream().to(&quot;classCount&quot;, Produced.with(stringSerde, longSerde)); AgeCountTable.toStream().to(&quot;ageCount&quot;, Produced.with(stringSerde, longSerde)); // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125;&#125; 操作步骤 启动zookeeper 启动kafka 启动计算程序 启动消费者 (消费者序列化分别为String和Long) 启动生产者 通过websocket推送至前台 推送详见前期代码 消费监听数据源需要更改value值,以及去重判断 消费者代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Componentpublic class KafkaConsumer &#123; private static final Logger LOG = LogManager.getLogger(KafkaConsumer.class); private static ConcurrentSkipListMap&lt;String, Long&gt; rs2 = new ConcurrentSkipListMap&lt;&gt;(); private static ConcurrentSkipListMap&lt;String, Object&gt; rs3 = new ConcurrentSkipListMap&lt;&gt;(); private static List&lt;ClassMsg&gt; rs = new ArrayList&lt;&gt;(); private static ConcurrentSkipListMap&lt;String, Object&gt; rs6 = new ConcurrentSkipListMap&lt;&gt;(); private static ConcurrentSkipListMap&lt;String, Long&gt; rs4 = new ConcurrentSkipListMap&lt;&gt;(); private static List&lt;String&gt; rs001 =new ArrayList&lt;&gt;(); private static List&lt;Long&gt; rs002 = new ArrayList&lt;&gt;();// @KafkaListener(topics = &#123;&quot;studentMsg&quot;&#125;)// public void receiveDate(ConsumerRecord&lt;?, ?&gt; record) &#123;// System.out.printf(&quot;topic = %s, offset = %d, value = %s \n&quot;, record.topic(), record.offset(), record.value());// try &#123;// WebSocketServer.sendInfo(record.value().toString(),&quot;all&quot;);// &#125; catch (IOException e) &#123;// // TODO Auto-generated catch block// e.printStackTrace();// &#125;// &#125; @KafkaListener(topics = &#123; &quot;classCount&quot; &#125;) public void receiveClassCount(ConsumerRecord&lt;?, ?&gt; record) &#123; String classname = &quot;班级&quot; + record.key(); Long classCountLong = (Long) record.value(); rs2.put(classname, classCountLong); rs3.put(&quot;dataType&quot;, 1); rs3.put(&quot;data1&quot;, rs2.keySet()); Set&lt;Map.Entry&lt;String, Long&gt;&gt; entryseSet = rs2.entrySet(); for (Map.Entry&lt;String, Long&gt; entry : entryseSet) &#123; ClassMsg cms = new ClassMsg(); cms.setName(entry.getKey()); cms.setValue(entry.getValue()); if (!rs.contains(cms)) &#123; rs.add(cms); &#125; else &#123; rs.get(rs.indexOf(cms)).setValue(cms.getValue()); &#125; &#125; rs3.put(&quot;data2&quot;, rs); try &#123; WebSocketServer.sendInfo(JSON.toJSONString(rs3), &quot;all&quot;); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; @KafkaListener(topics = &#123; &quot;ageCount&quot; &#125;) public void receiveClassCount1(ConsumerRecord&lt;?, ?&gt; record) &#123; rs001.clear(); rs002.clear(); String agename = &quot;年龄&quot; + record.key(); Long classCountLong = (Long) record.value(); rs6.put(&quot;dataType&quot;, 2); rs4.put(agename,classCountLong); Set&lt;Map.Entry&lt;String, Long&gt;&gt; entryseSet = rs4.entrySet(); for (Map.Entry&lt;String, Long&gt; entry : entryseSet) &#123; rs001.add(entry.getKey()); rs002.add(entry.getValue());&#125; rs6.put(&quot;data1&quot;,rs001 ); rs6.put(&quot;data2&quot;, rs002); try &#123; WebSocketServer.sendInfo(JSON.toJSONString(rs6), &quot;all&quot;); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 最终结果如下：]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>webscoket推送</tag>
        <tag>群发消息</tag>
        <tag>图形实时展示</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams(3-3)]]></title>
    <url>%2F2019%2F12%2F06%2F2019-12-06-%E5%BC%80%E5%8F%91kafka_Stream(3-3)%2F</url>
    <content type="text"><![CDATA[推送是必不可少的一个环节。做好推送,即将进入实时计算的体系中。 springboot整合websocket推送数据消息 整合websocket 结合3-2进行消息的推送 springboot整合websocket 1.添加依赖文件 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt; &lt;/dependency&gt; 实例化websockt提供的对象 1234567@Configurationpublic class WebSocketConfig &#123; @Bean public ServerEndpointExporter serverEndpointExporter() &#123; return new ServerEndpointExporter(); &#125;&#125; 3.构建服务端对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126package com.wwj.consumer.websocket;import java.io.IOException;import java.util.concurrent.CopyOnWriteArraySet;import javax.websocket.OnClose;import javax.websocket.OnError;import javax.websocket.OnMessage;import javax.websocket.OnOpen;import javax.websocket.Session;import javax.websocket.server.PathParam;import javax.websocket.server.ServerEndpoint;import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;import org.springframework.stereotype.Component;import com.wwj.consumer.action.KafkaConsumer;@ServerEndpoint(&quot;/websocket/&#123;sid&#125;&quot;)@Componentpublic class WebSocketServer &#123; private static final Logger LOG = LogManager.getLogger(WebSocketServer.class); //静态变量，用来记录当前在线连接数。应该把它设计成线程安全的。 private static int onlineCount = 0; //concurrent包的线程安全Set，用来存放每个客户端对应的MyWebSocket对象。 private static CopyOnWriteArraySet&lt;WebSocketServer&gt; webSocketSet = new CopyOnWriteArraySet&lt;WebSocketServer&gt;(); //与某个客户端的连接会话，需要通过它来给客户端发送数据 private Session session; //接收sid private String sid=&quot;&quot;; /** * 连接建立成功调用的方法*/ @OnOpen public void onOpen(Session session,@PathParam(&quot;sid&quot;) String sid) &#123; this.session = session; webSocketSet.add(this); //加入set中 addOnlineCount(); //在线数加1 LOG.info(&quot;有新窗口开始监听:&quot;+sid+&quot;,当前在线人数为&quot; + getOnlineCount()); this.sid=sid; try &#123; sendMessage(&quot;连接成功&quot;); &#125; catch (IOException e) &#123; LOG.error(&quot;websocket IO异常&quot;); &#125; &#125; /** * 连接关闭调用的方法 */ @OnClose public void onClose() &#123; webSocketSet.remove(this); //从set中删除 subOnlineCount(); //在线数减1 LOG.info(&quot;有一连接关闭！当前在线人数为&quot; + getOnlineCount()); &#125; /** * 收到客户端消息后调用的方法 * * @param message 客户端发送过来的消息*/ @OnMessage public void onMessage(String message, Session session) &#123; LOG.info(&quot;收到来自窗口&quot;+sid+&quot;的信息:&quot;+message); //群发消息 for (WebSocketServer item : webSocketSet) &#123; try &#123; item.sendMessage(message); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * * @param session * @param error */ @OnError public void onError(Session session, Throwable error) &#123; LOG.error(&quot;发生错误&quot;); error.printStackTrace(); &#125; /** * 实现服务器主动推送 */ public void sendMessage(String message) throws IOException &#123; this.session.getBasicRemote().sendText(message); &#125; /** * 群发自定义消息 * */ public static void sendInfo(String message,@PathParam(&quot;sid&quot;) String sid) throws IOException &#123; LOG.info(&quot;推送消息到窗口&quot;+sid+&quot;，推送内容:&quot;+message); for (WebSocketServer item : webSocketSet) &#123; try &#123; //这里可以设定只推送给这个sid的，为null则全部推送 if(sid==null) &#123; item.sendMessage(message); &#125;else if(item.sid.equals(sid))&#123; item.sendMessage(message); &#125; &#125; catch (IOException e) &#123; continue; &#125; &#125; &#125; public static synchronized int getOnlineCount() &#123; return onlineCount; &#125; public static synchronized void addOnlineCount() &#123; WebSocketServer.onlineCount++; &#125; public static synchronized void subOnlineCount() &#123; WebSocketServer.onlineCount--; &#125;&#125; 加入jsp支持,构建controlle,先跳转到需要建立连接的页面 建立连接页面代码示例如下 123456789101112131415161718192021222324252627282930313233343536373839&lt;script type=&quot;text/javascript&quot; src=&quot;/easyui/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt;$(function()&#123; var socket; if(typeof(WebSocket) == &quot;undefined&quot;) &#123; console.log(&quot;您的浏览器不支持WebSocket&quot;); &#125;else&#123; console.log(&quot;您的浏览器支持WebSocket&quot;); //实现化WebSocket对象，指定要连接的服务器地址与端口 建立连接 //等同于socket = new WebSocket(&quot;ws://localhost:8083/checkcentersys/websocket/20&quot;); socket = new WebSocket(&quot;ws://localhost:10888/websocket/20&quot;); //打开事件 socket.onopen = function() &#123; console.log(&quot;Socket 已打开&quot;); //socket.send(&quot;这是来自客户端的消息&quot; + location.href + new Date()); &#125;; //获得消息事件 socket.onmessage = function(msg) &#123; console.log(msg.data); //发现消息进入 开始处理前端触发逻辑 &#125;; //关闭事件 socket.onclose = function() &#123; console.log(&quot;Socket已关闭&quot;); &#125;; //发生了错误事件 socket.onerror = function() &#123; alert(&quot;Socket发生了错误&quot;); //此时可以尝试刷新页面 &#125; &#125;&#125;)&lt;/script&gt;&lt;body&gt;我是首页&lt;/body&gt;&lt;/html&gt; 测试通过 结合3-2进行消息的推送 写一个api进行消息推送 实验kafka接收到消息后进行推送 写一个restController1234567891011121314@RestControllerpublic class PushController &#123; @RequestMapping(&quot;/socket/push/&#123;cid&#125;&quot;) public void pushToWeb(@PathVariable String cid,String message) &#123; try &#123; WebSocketServer.sendInfo(message,cid); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; *如图所示,统一接收到推送消息 消费者接收到消息后,调用发送消息123456789@KafkaListener(topics = &#123;&quot;studentMsg&quot;&#125;) public void receiveDate(ConsumerRecord&lt;?, ?&gt; record) &#123; System.out.printf(&quot;topic = %s, offset = %d, value = %s \n&quot;, record.topic(), record.offset(), record.value()); try &#123; WebSocketServer.sendInfo(record.value.toString(),&quot;all&quot;); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; 代码均已测试 单机单例未见zookeeper和kafka出现异常]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>webscoket推送</tag>
        <tag>群发消息</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams(3-2)]]></title>
    <url>%2F2019%2F12%2F05%2F2019-12-05-%E5%BC%80%E5%8F%91kafka_Stream(3-2)%2F</url>
    <content type="text"><![CDATA[第一步必不可少,理解熟练是必要! springboot整合kafka发送自定义消息序列 结合分层构建的springboot项目,分别构建生产者模块和消费者模块 构建自定的数据模型(使用jsonObject进行数据的转换)并配置kafka生产者和消费者 使用spring提供的kafka对象编写生产者和消费者代码 模拟数据测试代码 操作步骤 结合分层构建的springboot项目,分别构建生产者模块和消费者模块图示:如下 结合分层构建的springboot项目,分别构建生产者模块和消费者模块 父类引入新的依赖文件 123456789101112&lt;!--kafka依赖配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;version&gt;2.3.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--fastjson依赖配置--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;/dependency&gt; 在2个模块中构建启动文件以及设置不同的端口和log4j2 123456789101112131415161718192021//在pom.xml中指定启动文件 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 指定该Main Class为全局的唯一入口 --&gt; &lt;mainClass&gt;com.wwj.producer.WebApplication&lt;/mainClass&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt;&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 启动文件示例如下: 12345678@SpringBootApplication@ComponentScan(basePackages = &quot;com.wwj&quot;)public class WebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebApplication.class); &#125;&#125; 注意:appliacation.yml文件和log4j2文件请参照前面3-1中配置按需所取 构建自定的数据模型(使用jsonObject进行数据的转换)并配置kafka生产者和消费者前面提到过,kafka在发送消息的时候需要进行序列化操作,把对象转换字节的,在接收消息的时候需要将字节反序列化成对象,除此之外在kafka中需要按照2个接口进行序列化对象的实现 在pojo模块中构建序列化器以及数据模型 1.模型类 12345public class Student &#123; private String studentName; private String studentAge; private String studentClassNo; &#125; 2.序列化器 123456789public class JsonSerializer implements Serializer&lt;JSONObject&gt;&#123; @Override public byte[] serialize(String topic, JSONObject data) &#123; // TODO Auto-generated method stub return JSON.toJSONBytes(data); &#125;&#125; 123456789public class JsonDeserializer implements Deserializer&lt;JSONObject&gt;&#123; @Override public JSONObject deserialize(String topic, byte[] data) &#123; // TODO Auto-generated method stub return JSON.parseObject(data, JSONObject.class); &#125;&#125; 3.配置生产者和消费者并引入模型和序列化器(基本配置) 12345678#生产者 kafka: bootstrap-servers: 127.0.0.1:9092 producer: key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: com.wwj.util.JsonSerializer batch-size: 65536 buffer-memory: 524288 123456789#消费者 kafka: bootstrap-servers: 127.0.0.1:9092 consumer: group-id: 0 enable-auto-commit: true auto-commit-interval: 1000 key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: com.wwj.util.JsonDeserializer 使用spring提供的kafka对象编写生产者和消费者代码 生产者代码示例 1234567891011121314151617181920212223242526@Componentpublic class KfkaProducer &#123; private static final Logger LOG = LogManager.getLogger(KfkaProducer.class); @Autowired private KafkaTemplate&lt;String,JSONObject&gt; kafkaTemplate; public void sendMsg(String topic,JSONObject msg) &#123; ListenableFuture&lt;SendResult&lt;String, JSONObject&gt;&gt; future = kafkaTemplate.send(topic, msg); future.addCallback(new SuccessCallback&lt;Object&gt;() &#123; @Override public void onSuccess(Object result) &#123; // TODO Auto-generated method stub LOG.info(&quot;消息发送成功&quot;); &#125; &#125;,new FailureCallback() &#123; @Override public void onFailure(Throwable ex) &#123; LOG.info(&quot;消息发送失败&quot;); &#125; &#125;); &#125; 消费者代码示例 12345678910@Componentpublic class KafkaConsumer &#123; private static final Logger LOG = LogManager.getLogger(KafkaConsumer.class); @KafkaListener(topics = &#123;&quot;studentMsg&quot;&#125;) public void receiveDate(ConsumerRecord&lt;?, ?&gt; record) &#123; System.out.printf(&quot;topic = %s, offset = %d, value = %s \n&quot;, record.topic(), record.offset(), record.value()); &#125;&#125; 模拟数据测试代码12345678910111213141516@RestControllerpublic class MockController &#123; @Autowired private KfkaProducer producer; @RequestMapping(&quot;mock&quot;) public void sendMock() &#123; Student student = new Student(); student.setStudentName(&quot;小王&quot;); student.setStudentClassNo(&quot;001&quot;); student.setStudentAge(&quot;32&quot;); producer.sendMsg(&quot;studentMsg&quot;,(JSONObject)JSONObject.toJSON(student)); &#125;&#125; 操作步骤 启动zookeeper 启动kafka 创建主题(studentMsg) 启动消费者 启动生产者 1topic = studentMsg, offset = 0, value = &#123;&quot;studentAge&quot;:&quot;32&quot;,&quot;studentClassNo&quot;:&quot;001&quot;,&quot;studentName&quot;:&quot;小王&quot;&#125; Ok!代码通过测试]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>自定义数据序列化传输</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams(3-1)]]></title>
    <url>%2F2019%2F12%2F04%2F2019-12-04-%E5%BC%80%E5%8F%91Kafka_Stream(3-1)%2F</url>
    <content type="text"><![CDATA[前期先利用springboot整合热身,不是什么坏事情。 kafkaStream流式计算版本实现1.0 springboot分模块整合(3-1) springboot整合kafka发送自定义消息序列(3-2) springboot整合websocket推送数据消息(3-3) springboot结合kafkaStream流推送消息Echart图形展示(3-4) springboot分模块整合 先更新下eclipse 可在springboot插件下载进行对应版本的eclipse下载 构建springboot项目 目录结构如下: 搭建springboot并整合注意事项: 勾选需要的技术内容(mysql+web+mybatis) 分层结构 采用yml方式进行配置可能需要安装yml插件 使用easyui 注意事项: 配置jsp支持 添加静态资源文件 引入对应的所需文件 12345678910&lt;!-- 设置支持jsp页面 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; 直接引入static下的文件如下&lt;script type=&quot;text/javascript&quot; src=&quot;/easyui/jquery.min.js&quot;&gt;&lt;/script&gt; 使用druid数据源 123456&lt;!-- druid数据池 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt;&lt;/dependency&gt; yml展示请参照全文展示 通过访问ip+端口/druid——即可进入druid控制台 使用分页插件和mybatis 12345678910111213141516&lt;!-- mybatis分页插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; yml展示请参照全文展示 使用log4j2 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; 简单的lo4j2.xml配置文件如下 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;properties&gt; &lt;!-- 文件输出格式 --&gt; &lt;property name=&quot;PATTERN&quot;&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; |-%-5level [%thread] %c [%L] -| %msg%n&lt;/property&gt; &lt;Property name=&quot;instance&quot;&gt;spring-boot-log4j2-log&lt;/Property&gt; &lt;/properties&gt; &lt;appenders&gt; &lt;Console name=&quot;CONSOLE&quot; target=&quot;system_out&quot;&gt; &lt;PatternLayout pattern=&quot;$&#123;PATTERN&#125;&quot;/&gt; &lt;/Console&gt; &lt;/appenders&gt; &lt;loggers&gt; &lt;!-- root logger 配置 --&gt; &lt;root level=&quot;info&quot;&gt; &lt;appenderref ref=&quot;CONSOLE&quot;/&gt; &lt;/root&gt; &lt;/loggers&gt;&lt;/configuration&gt; 使用swagger2文档生成 12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt;&lt;/dependency&gt; 通过设置初始化信息 123456789101112131415161718192021222324@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select() .apis(RequestHandlerSelectors.basePackage(&quot;com.wwj.controller&quot;)) .paths(PathSelectors.any()).build(); &#125; /** * @Description: 构建 api文档的信息 */ private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() // 设置页面标题 .title(&quot;使用swagger2构建api接口文档&quot;) // 描述 .description(&quot;欢迎访问接口文档，这里是描述信息&quot;) // 定义版本号 .version(&quot;1.0&quot;).build(); &#125;&#125; 核心控制文件展示 根节点pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;KafkaFather&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;KafkaFather&lt;/name&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;description&gt;kafkaDemo2&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- log4j. --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; &lt;!-- druid数据池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis分页插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 设置支持jsp页面 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- swagger2 配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;web&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;modules&gt; &lt;module&gt;pojo&lt;/module&gt; &lt;module&gt;mapper&lt;/module&gt; &lt;module&gt;service&lt;/module&gt; &lt;module&gt;web&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; web节点pom.xml 123456789101112131415161718192021222324252627282930313233343536&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;KafkaFather&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;web&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 指定该Main Class为全局的唯一入口 --&gt; &lt;mainClass&gt;com.wwj.web.WebApplication&lt;/mainClass&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt;&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 其余节点之间相互依赖管理 关键文件（启动文件以及application.yml文件） 12345678910@SpringBootApplication@ComponentScan(basePackages = &quot;com.wwj&quot;)@MapperScan(basePackages = &quot;com.wwj.mapper&quot;)public class WebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebApplication.class); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#端口号server: port: 10086#配置druid数据源spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql://localhost:3306/crmpro?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false username: root password: root driver-class-name: com.mysql.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource druid: #初始化大小 initialSize: 5 #最小值 minIdle: 5 #最大值 maxActive: 20 #最大等待时间，配置获取连接等待超时，时间单位都是毫秒ms maxWait: 60000 #配置间隔多久才进行一次检测，检测需要关闭的空闲连接 timeBetweenEvictionRunsMillis: 60000 #配置一个连接在池中最小生存的时间 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true # 配置监控统计拦截的filters，去掉后监控界面sql无法统计， #&apos;wall&apos;用于防火墙，SpringBoot中没有log4j，我改成了log4j2 filters: stat,wall,log4j2 #最大PSCache连接 maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true # 通过connectProperties属性来打开mergeSql功能；慢SQL记录 connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 # 配置StatFilter web-stat-filter: #默认为false，设置为true启动 enabled: true url-pattern: &quot;/*&quot; exclusions: &quot;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*&quot; #配置StatViewServlet stat-view-servlet: url-pattern: &quot;/druid/*&quot; #允许那些ip allow: 127.0.0.1 login-username: admin login-password: 123456 #禁止那些ip deny: 192.168.1.102 #是否可以重置 reset-enable: true #启用 enabled: true#设置mybatismybatis: #mapper.xml所在位置 mapper-locations: classpath*:Mapper/*.xml configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl#设置pagehelperpagehelper: helperDialect: mysql reasonable: true supportMethodsArguments: true params: count=countSql]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>springboot分模块整合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams2]]></title>
    <url>%2F2019%2F12%2F02%2F2019-12-02-%E5%BC%80%E5%8F%91kafka_Streams2%2F</url>
    <content type="text"><![CDATA[熟知kafka提供的高级算子,以及熟练使用我们常用的算子是不可或缺的操作。 模拟数据进行流拓扑的设计 根据一个模拟的购物数据进行流的设计 设计规则以及如何将流切分为多个流(再分流) 根据一个模拟的购物数据进行流的设计 通过屏蔽处理器处理屏蔽卡号问题 提取购买的物品以及邮编,确定购买模式 获取会员号,以及金额.根据金额确定奖励 获取所有完成的数据,以备后续进行特定的分析 操作步骤 1.模拟数据对象 12345678910111213141516171819public class PurchaseRecord &#123; /** * 用户姓名 */ private String firstName; private String lastName; //用户信用卡编号 private String creditCardNumber; //用户购买物品 private String itemPurchased; //购物物品数量 private int quantity; //物品单价 private double price; //购买日期 private Date purchaseDate; //用户会员卡编号 private String zipCode; &#125; 12345678910111213public static void main(String[] args) &#123; PurchaseRecord record = new PurchaseRecord(); record.setFirstName(&quot;王&quot;); record.setLastName(&quot;伟杰&quot;); record.setCreditCardNumber(&quot;1000-5000-1987-0215&quot;); record.setItemPurchased(&quot;福特钥匙扣&quot;); record.setQuantity(1); record.setPrice(28.00); record.setPurchaseDate(new Date()); record.setZipCode(&quot;100187&quot;); Gson g = new Gson(); System.out.println(g.toJson(record)); &#125; 数据模拟效果如下:{&quot;firstName&quot;:&quot;王&quot;,&quot;lastName&quot;:&quot;伟杰&quot;,&quot;creditCardNumber&quot;:&quot;1000-5000-1987-0215&quot;,&quot;itemPurchased&quot;:&quot;福特钥匙扣&quot;,&quot;quantity&quot;:1,&quot;price&quot;:28.0,&quot;purchaseDate&quot;:&quot;Nov 19, 2019 4:55:58 PM&quot;,&quot;zipCode&quot;:&quot;100187&quot;} 2.构建通用的序列化器 说明:kafka以字节的方式传输数据,在传输数据的时候需要将对象转换为json,发送到对应的主题时候,需要转换成字节的数组,其次在消费的时候需要将主题中的字节数组转换成json,其次在转为对应的对象类型.当然上一节已经提到过.Kafka默认对一些类型进行了支持,比如String,Long,Integer等 123456789101112131415161718192021222324252627/** * 通用的序列化操作 * @author Yun * * @param &lt;T&gt; */public class JsonSerializer&lt;T&gt; implements Serializer&lt;T&gt;&#123; private Gson g = new Gson(); @Override public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123; // TODO Auto-generated method stub &#125; @Override public byte[] serialize(String topic, T data) &#123; // TODO Auto-generated method stub return g.toJson(data).getBytes(Charset.forName(&quot;UTF-8&quot;)); &#125; @Override public void close() &#123; // TODO Auto-generated method stub &#125;&#125; 123456789101112131415161718192021222324252627282930313233/** * 通用的反序列化操作 * @author Yun * * @param &lt;T&gt; */public class JsonDeserializer&lt;T&gt; implements Deserializer&lt;T&gt; &#123; private Gson g = new Gson(); private Class&lt;T&gt; deserializedClass; public JsonDeserializer(Class&lt;T&gt; deserializedClass) &#123; super(); this.deserializedClass = deserializedClass; &#125; @Override public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123; // TODO Auto-generated method stub &#125; @Override public T deserialize(String topic, byte[] data) &#123; // TODO Auto-generated method stub return g.fromJson(new String(data), deserializedClass); &#125; @Override public void close() &#123; // TODO Auto-generated method stub &#125; &#125; 3.编写对应的规则 1.处理信用卡的规则 2.提取购买的物品,以及邮编(购买模式的规则) 3.提取会员号以及话费的金额(奖励机制的规则) 构建一个工具类,以及规则所产出的对应的实体 123456public class PurchasePattern &#123; private String zipCode; private String item; private Date date; private double amount; &#125; 1234public class RewardAccumulator &#123; private String customerId; private double purchaseTotal; &#125; 工具类 12345678910111213141516171819202122232425262728293031323334353637public class ActionUtil &#123; private final static String MARK = &quot;xxxx-xxxx-xxxx&quot;; /** * 屏蔽信用卡号 * @param pr 需要被屏蔽的信息记录 * @return */ public static PurchaseRecord mask(PurchaseRecord pr)&#123; String[] parts = pr.getCreditCardNumber().split(&quot;-&quot;); pr.setCreditCardNumber(MARK+&quot;-&quot;+parts[3]); return pr; &#125; /** * 提取部分数据 * @param pr 需要提取的记录信息 * @return */ public static PurchasePattern getSomeOne(PurchaseRecord pr)&#123; PurchasePattern pp = new PurchasePattern(); pp.setZipCode(pr.getZipCode()); pp.setDate(pr.getPurchaseDate()); pp.setItem(pr.getItemPurchased()); pp.setAmount(pr.getPrice()*pr.getQuantity()); return pp; &#125; public static RewardAccumulator getReward(PurchaseRecord pr)&#123; RewardAccumulator ra = new RewardAccumulator(); ra.setCustomerId(pr.getFirstName()+pr.getLastName()); ra.setPurchaseTotal(pr.getPrice()*pr.getQuantity()); return ra; &#125; &#125; 测试结果数据如下: 123 &#123;&quot;firstName&quot;:&quot;王&quot;,&quot;lastName&quot;:&quot;伟杰&quot;,&quot;creditCardNumber&quot;:&quot;xxxx-xxxx-xxxx-0215&quot;,&quot;itemPurchased&quot;:&quot;福特钥匙扣&quot;,&quot;quantity&quot;:1,&quot;price&quot;:28.0,&quot;purchaseDate&quot;:&quot;Nov 20, 2019 5:07:13 PM&quot;,&quot;zipCode&quot;:&quot;100187&quot;&#125;&#123;&quot;zipCode&quot;:&quot;100187&quot;,&quot;item&quot;:&quot;福特钥匙扣&quot;,&quot;date&quot;:&quot;Nov 20, 2019 5:07:13 PM&quot;,&quot;amount&quot;:28.0&#125;&#123;&quot;customerId&quot;:&quot;王伟杰&quot;,&quot;purchaseTotal&quot;:28.0&#125; 根据拓扑创建一个流式应用程式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class FirstStream &#123; private static final Logger LOG = LoggerFactory.getLogger(FirstStream.class); public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;FirstZmart-Kafka-Streams-App&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); // 配置当前时间 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); // 加载配置 StreamsConfig streamsConfig = new StreamsConfig(props); // 构建序列化器 // 默认的 Serde&lt;String&gt; stringSerde = Serdes.String(); // 自定义的(可优化) JsonSerializer&lt;PurchaseRecord&gt; ps = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;PurchaseRecord&gt; pds = new JsonDeserializer&lt;&gt;(PurchaseRecord.class); JsonSerializer&lt;PurchasePattern&gt; pps = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;PurchasePattern&gt; ppds = new JsonDeserializer&lt;&gt;(PurchasePattern.class); JsonSerializer&lt;RewardAccumulator&gt; rs = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;RewardAccumulator&gt; rds = new JsonDeserializer&lt;&gt;(RewardAccumulator.class); // 构建自定义序列化器 Serde&lt;PurchaseRecord&gt; PurchaseRecordSerde = Serdes.serdeFrom(ps, pds); Serde&lt;PurchasePattern&gt; PurchasePatternSerde = Serdes.serdeFrom(pps, ppds); Serde&lt;RewardAccumulator&gt; RewardAccumulatorSerde = Serdes.serdeFrom(rs, rds); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); // 流拓扑 /** * mapValues 原始的键不会发生变化 ，可获取到传递进来的Value值 */ KStream&lt;String, PurchaseRecord&gt; PurchaseRecordStream = streamsBuilder .stream(&quot;transactions&quot;, Consumed.with(stringSerde, PurchaseRecordSerde)) .mapValues(pr -&gt; ActionUtil.mask(pr)); /** * 因为机器缘由，我们可以通过打印来替代 这一步等于处理完数据后发送给对应的主题,后续配置消费者消费即可 * PurchaseRecordStream.to(&quot;Purchase&quot;, Produced.with(stringSerde, * PurchaseRecordSerde)); */ PurchaseRecordStream.print(Printed.&lt;String, PurchaseRecord&gt;toSysOut().withLabel(&quot;PurchaseRecord&quot;)); // 同理如下 KStream&lt;String, PurchasePattern&gt; PurchasePatternStream = PurchaseRecordStream .mapValues(pr -&gt; ActionUtil.getSomeOne(pr)); PurchasePatternStream.print(Printed.&lt;String, PurchasePattern&gt;toSysOut().withLabel(&quot;PurchasePattern&quot;)); KStream&lt;String, RewardAccumulator&gt; RewardAccumulatorStream = PurchaseRecordStream .mapValues(pr -&gt; ActionUtil.getReward(pr)); RewardAccumulatorStream.print(Printed.&lt;String, RewardAccumulator&gt;toSysOut().withLabel(&quot;RewardAccumulator&quot;)); // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125;&#125; 5.配置生产者以及模拟数据 123456789101112131415161718192021222324public class TestProducer &#123; public static void main(String[] args) &#123; //模拟数据 PurchaseRecord record = new PurchaseRecord(); record.setFirstName(&quot;王&quot;); record.setLastName(&quot;伟杰&quot;); record.setCreditCardNumber(&quot;1000-5000-1987-0215&quot;); record.setItemPurchased(&quot;福特钥匙扣&quot;); record.setQuantity(1); record.setPrice(28.00); record.setPurchaseDate(new Date()); record.setZipCode(&quot;100187&quot;); //配置生产者 Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); properties.put(&quot;acks&quot;, &quot;1&quot;); properties.put(&quot;retries&quot;, &quot;3&quot;); properties.put(&quot;compression.type&quot;, &quot;snappy&quot;); KafkaProducer&lt;String, PurchaseRecord&gt; kp = new KafkaProducer&lt;String,PurchaseRecord&gt;(properties,new StringSerializer(),new JsonSerializer&lt;PurchaseRecord&gt;()); kp.send(new ProducerRecord&lt;String, PurchaseRecord&gt;(&quot;transactions&quot;, record)); kp.close(); &#125;&#125; 6.测试 启动zookeeper和kafka 创建一个transactions的主题 启动流程序 生产者发送消息 7.结果如下，对象要重写toString方法 123[PurchaseRecord]: null, PurchaseRecord [firstName=徐, lastName=小二, creditCardNumber=xxxx-xxxx-xxxx-0213, itemPurchased=福特钥匙扣, quantity=1, price=28.0, purchaseDate=Wed Nov 20 18:18:35 CST 2019, zipCode=100187][PurchasePattern]: null, PurchasePattern [zipCode=100187, item=福特钥匙扣, date=Wed Nov 20 18:18:35 CST 2019, amount=28.0][RewardAccumulator]: null, RewardAccumulator [customerId=徐小二, purchaseTotal=28.0] 如何将流切分为多个流(再分流)截止到现在,数据流的分配已经实现。接下我们需要细化一些规则 一定金额下面的信息我们需要进行过滤，小额交易可能对我们起不到任何帮助 在进入拓扑,默认没有对应的key值进行分类,这是需要我们为数据生成一个key值,以便做好新的归类 可能有一些的新的信息，接下来我们需要进行对应的分流到新的主题中 把一些需要的记录写入kafka之外 1.为模型添加一个Department字段 12//用户购买物品的种类 private String departMent; 2.过滤小额交易物品以及选择时间作为key值已方便归类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class SecondStream &#123; private static final Logger LOG = LoggerFactory.getLogger(SecondStream.class); public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;FirstZmart-Kafka-Streams-App&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); // 配置当前时间 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); // 加载配置 StreamsConfig streamsConfig = new StreamsConfig(props); // 构建序列化器 // 默认的 Serde&lt;String&gt; stringSerde = Serdes.String(); // 自定义的(可优化) JsonSerializer&lt;PurchaseRecord&gt; ps = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;PurchaseRecord&gt; pds = new JsonDeserializer&lt;&gt;(PurchaseRecord.class); // 构建自定义序列化器 Serde&lt;PurchaseRecord&gt; PurchaseRecordSerde = Serdes.serdeFrom(ps, pds); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); // 流拓扑 /** * mapValues 原始的键不会发生变化 ，可获取到传递进来的Value值 */ KStream&lt;String, PurchaseRecord&gt; PurchaseRecordStream = streamsBuilder .stream(&quot;transactions&quot;, Consumed.with(stringSerde, PurchaseRecordSerde)) .mapValues(pr -&gt; ActionUtil.mask(pr)); /** * 过滤小额操作以及选择特定的字段作为key */ //声明keyValueMapper创建谓词匹配对应的key值 KeyValueMapper&lt;String, PurchaseRecord, Long&gt; PurchaseRecordAsDateKey = (key,PurchaseRecord) -&gt; PurchaseRecord.getPurchaseDate().getTime(); //过滤小额交易的操作进入对应的流并选择特定的条件作为key值 使用filter可以进行条件进行过滤 KStream&lt;Long,PurchaseRecord&gt; filteredKStream = PurchaseRecordStream .filter((key,purchaseRecord) -&gt; purchaseRecord.getPrice()&gt;5.00) .selectKey(PurchaseRecordAsDateKey); filteredKStream.print(Printed.&lt;Long, PurchaseRecord&gt;toSysOut().withLabel(&quot;purchases&quot;)); &#125;&#125; 分流 1234567891011121314/** * 分流的操作 分流可以根据数据特定的条件进行分流 需要使用到特定的谓词条件 Predicate */Predicate&lt;String,PurchaseRecord&gt; isOne = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;钥匙套&quot;); Predicate&lt;String,PurchaseRecord&gt; isTwo = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;小五金&quot;); //返回分流的数组KStream&lt;String, PurchaseRecord&gt;[] kstreamByDepart = PurchaseRecordStream.branch(isOne,isTwo);kstreamByDepart[0].print(Printed.&lt;String, PurchaseRecord&gt;toSysOut().withLabel(&quot;钥匙类&quot;));kstreamByDepart[1].print(Printed.&lt;String, PurchaseRecord&gt;toSysOut().withLabel(&quot;小五金&quot;)); 使用foreach操作将记录写入kafka之外 假定会员编码为xxxx-xxxx-xxxx-0000为恶意会员码 123456//会员编码为恶意编码 ForeachAction&lt;String, PurchaseRecord&gt; purchaseRecordForeachAction = (key,purchaseRecord) -&gt; System.out.println(&quot;做额外的操作&quot;); PurchaseRecordStream .filter((key,purchaseRecord) -&gt;purchaseRecord.getZipCode().equals(&quot;xxxx-xxxx-xxxx-0000&quot;) ) .foreach(purchaseRecordForeachAction); 测试代码是否通过 启动zookeeper和kafka 启动流程序 生产者输送信息到transactions的主题 测试结果如下 1234567891011121314[purchases]: 1575279440000, PurchaseRecord [firstName=徐, lastName=小四, creditCardNumber=xxxx-xxxx-xxxx-0001, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:37:20 CST 2019, zipCode=100187][钥匙类]: null, PurchaseRecord [firstName=徐, lastName=小四, creditCardNumber=xxxx-xxxx-xxxx-0001, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:37:20 CST 2019, zipCode=100187][purchases]: 1575279951000, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:45:51 CST 2019, zipCode=100187][钥匙类]: null, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:45:51 CST 2019, zipCode=100187][purchases]: 1575280227000, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:50:27 CST 2019, zipCode=100187][钥匙类]: null, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:50:27 CST 2019, zipCode=100187][purchases]: 1575280293000, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:51:33 CST 2019, zipCode=000000][钥匙类]: null, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=福特钥匙扣, departMent=钥匙套, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:51:33 CST 2019, zipCode=000000]做额外的操作[purchases]: 1575280333000, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=汤勺, departMent=小五金, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:52:13 CST 2019, zipCode=100187][小五金]: null, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=汤勺, departMent=小五金, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:52:13 CST 2019, zipCode=100187][purchases]: 1575280351000, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=大锅, departMent=小五金, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:52:31 CST 2019, zipCode=100187][小五金]: null, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=大锅, departMent=小五金, quantity=1, price=28.0, purchaseDate=Mon Dec 02 17:52:31 CST 2019, zipCode=100187][小五金]: null, PurchaseRecord [firstName=徐, lastName=小五, creditCardNumber=xxxx-xxxx-xxxx-0002, itemPurchased=大锅, departMent=小五金, quantity=1, price=5.0, purchaseDate=Mon Dec 02 17:52:42 CST 2019, zipCode=100187] 完整代码示例如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111package com.wwj.streams;import java.util.Properties;import java.util.concurrent.CountDownLatch;import org.apache.kafka.common.serialization.Serde;import org.apache.kafka.common.serialization.Serdes;import org.apache.kafka.streams.Consumed;import org.apache.kafka.streams.KafkaStreams;import org.apache.kafka.streams.StreamsBuilder;import org.apache.kafka.streams.StreamsConfig;import org.apache.kafka.streams.kstream.ForeachAction;import org.apache.kafka.streams.kstream.KStream;import org.apache.kafka.streams.kstream.KeyValueMapper;import org.apache.kafka.streams.kstream.Predicate;import org.apache.kafka.streams.kstream.Printed;import org.apache.kafka.streams.processor.WallclockTimestampExtractor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.wwj.model.PurchaseRecord;import com.wwj.serde.JsonDeserializer;import com.wwj.serde.JsonSerializer;import com.wwj.util.ActionUtil;public class SecondStream &#123; private static final Logger LOG = LoggerFactory.getLogger(SecondStream.class); public static void main(String[] args) &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;SecondZmart-Kafka-Streams-App&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1); // 配置当前时间 props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class); // 加载配置 StreamsConfig streamsConfig = new StreamsConfig(props); // 构建序列化器 // 默认的 Serde&lt;String&gt; stringSerde = Serdes.String(); // 自定义的(可优化) JsonSerializer&lt;PurchaseRecord&gt; ps = new JsonSerializer&lt;&gt;(); JsonDeserializer&lt;PurchaseRecord&gt; pds = new JsonDeserializer&lt;&gt;(PurchaseRecord.class); // 构建自定义序列化器 Serde&lt;PurchaseRecord&gt; PurchaseRecordSerde = Serdes.serdeFrom(ps, pds); // 创建流的构造器 StreamsBuilder streamsBuilder = new StreamsBuilder(); // 流拓扑 /** * mapValues 原始的键不会发生变化 ，可获取到传递进来的Value值 */ KStream&lt;String, PurchaseRecord&gt; PurchaseRecordStream = streamsBuilder .stream(&quot;transactions&quot;, Consumed.with(stringSerde, PurchaseRecordSerde)) .mapValues(pr -&gt; ActionUtil.mask(pr)); /** * 过滤小额操作以及选择特定的字段作为key */ //声明keyValueMapper创建谓词匹配对应的key值 KeyValueMapper&lt;String, PurchaseRecord, Long&gt; PurchaseRecordAsDateKey = (key,PurchaseRecord) -&gt; PurchaseRecord.getPurchaseDate().getTime(); //过滤小额交易的操作进入对应的流并选择特定的条件作为key值 使用filter可以进行条件进行过滤 KStream&lt;Long,PurchaseRecord&gt; filteredKStream = PurchaseRecordStream .filter((key,purchaseRecord) -&gt; purchaseRecord.getPrice()&gt;5.00) .selectKey(PurchaseRecordAsDateKey); filteredKStream.print(Printed.&lt;Long, PurchaseRecord&gt;toSysOut().withLabel(&quot;purchases&quot;)); /** * 分流的操作 分流可以根据数据特定的条件进行分流 需要使用到特定的谓词条件 Predicate */ Predicate&lt;String,PurchaseRecord&gt; isOne = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;钥匙套&quot;); Predicate&lt;String,PurchaseRecord&gt; isTwo = (key,purchaseRecord) -&gt;purchaseRecord.getDepartMent().equalsIgnoreCase(&quot;小五金&quot;); //返回分流的数组 KStream&lt;String, PurchaseRecord&gt;[] kstreamByDepart = PurchaseRecordStream.branch(isOne,isTwo); kstreamByDepart[0].print(Printed.&lt;String, PurchaseRecord&gt;toSysOut().withLabel(&quot;钥匙类&quot;)); kstreamByDepart[1].print(Printed.&lt;String, PurchaseRecord&gt;toSysOut().withLabel(&quot;小五金&quot;)); //会员编码为恶意编码 ForeachAction&lt;String, PurchaseRecord&gt; purchaseRecordForeachAction = (key,purchaseRecord) -&gt; System.out.println(&quot;做额外的操作&quot;); PurchaseRecordStream .filter((key,purchaseRecord) -&gt;purchaseRecord.getZipCode().equals(&quot;xxxx-xxxx-xxxx-0000&quot;) ) .foreach(purchaseRecordForeachAction); // 开启流 final KafkaStreams streams = new KafkaStreams(streamsBuilder.build(), streamsConfig); final CountDownLatch latch = new CountDownLatch(1); Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-jvm-shutdown-hook&quot;) &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Exception e) &#123; System.exit(1); &#125; System.exit(0); &#125; &#125;]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>自定义序列器</tag>
        <tag>必要的算子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发Kafka_Streams1]]></title>
    <url>%2F2019%2F11%2F14%2F2019-11-14-%E5%BC%80%E5%8F%91kafka_Streams1%2F</url>
    <content type="text"><![CDATA[自定义数据类型,利用kafka进行数据传递,以及如何去定义流拓扑。什么是流,我们需要有一个初步认识 从零到有的kafka进阶 环境的准备 利用kafkaStreams实现helloworld-HELLOWORLD 利用kafka自定义序列化器以及构建生产者和消费者 环境的准备 jdk1.8 maven构建普通项目 引入关联的jar包 引入log4j 关于log4j的使用可参考 pom.xml如下 1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-streams --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-streams&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; lo4j配置 123456log4j.rootLogger=INFO, stdout# stdout Appenderlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target=System.outlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-5p %c&#123;1&#125;:%L - %m%n 利用kafkaStreams实现helloworld-HELLOWORLD流式处理API(DSL) 高级API的核心是KStream对象(该对象代表流/值记录) DSL方法都返回了一个KStream对象的引用 返回的KStream对象是一个新的实例。而不是最初的实例 构建一个简单的流向图 类似的步骤 定义配置项 创建自定义或预定义的Serde实例 创建处理器拓扑 创建和启动KStream 补充说明:kafka流在进行处理的时候,数据会进行序列化和反序列化操作。在kafka流中，默认提供了一个Serdes类来构建Serde对象。而默认提供以下类型作为支撑1.String 2.byte数组 3.Long 4.Integer 5.Double 关于序列化的原理和认知 代码示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.wwj.kafka;import java.util.Properties;import org.apache.kafka.common.serialization.Serde;import org.apache.kafka.common.serialization.Serdes;import org.apache.kafka.streams.Consumed;import org.apache.kafka.streams.KafkaStreams;import org.apache.kafka.streams.StreamsBuilder;import org.apache.kafka.streams.StreamsConfig;import org.apache.kafka.streams.kstream.KStream;import org.apache.kafka.streams.kstream.Produced;import org.apache.kafka.streams.kstream.ValueMapper;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class KafkaStreamsHelloWorld &#123; public final static Logger LOG = LoggerFactory.getLogger(KafkaStreamsHelloWorld.class); public static void main(String[] args) throws InterruptedException &#123; //配置基本属性 Properties props = new Properties(); //每个流式程序有特定的id和节点(必选) props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;helloworl_app_id&quot;); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;); StreamsConfig streamsConfig = new StreamsConfig(props); Serde&lt;String&gt; stringSerde = Serdes.String(); //1.构建流的创建者实例 StreamsBuilder builder = new StreamsBuilder(); // 1.1 接收源数据产生的处理器流 KStream&lt;String,String&gt; simpleFirstStream = builder.stream(&quot;src-topic&quot;, Consumed.with(stringSerde, stringSerde)); //1.2 将数据全部转化为大写 V代表接收值的类型,VR代表 KStream&lt;String, String&gt; upperCaseStream = simpleFirstStream.mapValues(new ValueMapper&lt;String, String&gt;() &#123; @Override public String apply(String value) &#123; return value.toUpperCase(); &#125; &#125;); //1.3 将处理后的值送到输出主题中 upperCaseStream.through(&quot;out-topic&quot;, Produced.with(stringSerde, stringSerde)); //2. 构建流容器 KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), streamsConfig); //3.启动流式程序 kafkaStreams.start(); Thread.sleep(60000); LOG.info(&quot;流式程序结束&quot;); kafkaStreams.close(); &#125;&#125; 操作步骤 启动zookeeper和kafka 创建2个主题，一个src-topic 和 out-topic 建立一个生产者和消费者 启动流式就计算程序 123456bin/zookeeper-server-start.sh config/zookeeper.propertiesbin/kafka-server-start.sh config/server.propertiesbin/kafka-topics.sh --create --topic src-topic --replication-factor 1 --partitions 1 --zookeeper localhost:2181bin/kafka-topics.sh --create --topic out-topic --replication-factor 1 --partitions 1 --zookeeper localhost:2181bin/kafka-console-producer.sh --topic src-topic --broker-list localhost:9092bin/kafka-console-consumer.sh --topic out-topic --bootstrap-server localhost:9092 --from-beginning 最终结果如下: 利用kafka自定义序列化器以及构建生产者和消费者创建数据对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 测试数据模型 * @author Yun * */public class OrderMsg &#123; //消费卡号 private String cardNumber; //消费人 private String personName; //消费金额 private Double money; public String getCardNumber() &#123; return cardNumber; &#125; public void setCardNumber(String cardNumber) &#123; this.cardNumber = cardNumber; &#125; public String getPersonName() &#123; return personName; &#125; public void setPersonName(String personName) &#123; this.personName = personName; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; public OrderMsg(String cardNumber, String personName, Double money) &#123; super(); this.cardNumber = cardNumber; this.personName = personName; this.money = money; &#125; public OrderMsg() &#123; super(); // TODO Auto-generated constructor stub &#125; @Override public String toString() &#123; return &quot;OrderMsg [cardNumber=&quot; + cardNumber + &quot;, personName=&quot; + personName + &quot;, money=&quot; + money + &quot;]&quot;; &#125; &#125; 创建序列化器1.使用序列化器（可选则用GSON） 12345&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.8.5&lt;/version&gt;&lt;/dependency&gt; 2.序列化器和反序列化器的代码如下(kafka在传递数据的时候,会将数据转换为字节,然后消费的时候将字节转换为具体的对象) 123456789101112131415161718192021222324//自定义序列化器public class JsonSer&lt;T&gt; implements Serializer&lt;T&gt; &#123; private Gson gson = new Gson(); @Override public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123; // TODO Auto-generated method stub &#125; @Override public byte[] serialize(String topic, T data) &#123; // TODO Auto-generated method stub return gson.toJson(data).getBytes(Charset.forName(&quot;UTF-8&quot;)); &#125; @Override public void close() &#123; // TODO Auto-generated method stub &#125;&#125; 1234567891011121314151617181920212223242526272829303132//自定义反序列化器public class JsonDser&lt;T&gt; implements Deserializer&lt;T&gt;&#123; private Gson gson = new Gson(); private Class&lt;T&gt; deserClass; public JsonDser(Class&lt;T&gt; deserClass)&#123; this.deserClass = deserClass; &#125; public JsonDser() &#123; // TODO Auto-generated constructor stub &#125; @Override public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123; // TODO Auto-generated method stub &#125; @Override public T deserialize(String topic, byte[] data) &#123; // TODO Auto-generated method stub return gson.fromJson(new String(data), deserClass); &#125; @Override public void close() &#123; // TODO Auto-generated method stub &#125;&#125; 创建生产者123456789101112131415public class TestProducer &#123; public static void main(String[] args) &#123; Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); properties.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.put(&quot;value.serializer&quot;, new JsonSer&lt;OrderMsg&gt;().getClass()); properties.put(&quot;acks&quot;, &quot;1&quot;); properties.put(&quot;retries&quot;, &quot;3&quot;); properties.put(&quot;compression.type&quot;, &quot;snappy&quot;); System.out.println(new JsonSer&lt;OrderMsg&gt;().getClass()); KafkaProducer&lt;String, OrderMsg&gt; kp = new KafkaProducer&lt;String,OrderMsg&gt;(properties); kp.send(new ProducerRecord&lt;String, OrderMsg&gt;(&quot;test-topic&quot;, new OrderMsg(&quot;005&quot;, &quot;zzz&quot;, 100.1))); kp.close(); &#125;&#125; 创建消费者1234567891011121314151617181920public class TestConsumer &#123; public static void main(String[] args) &#123; Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); properties.put(&quot;group.id&quot;, &quot;simple-consumer-example1&quot;); properties.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;); properties.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); properties.put(&quot;auto.commit.interval.ms&quot;, &quot;3000&quot;); KafkaConsumer&lt;String,OrderMsg&gt; ks = new KafkaConsumer&lt;String,OrderMsg&gt;(properties,new StringDeserializer(),new JsonDser&lt;&gt;(OrderMsg.class)); ks.subscribe(Collections.singletonList(&quot;test-topic&quot;)); while (true) &#123; ConsumerRecords&lt;String, OrderMsg&gt; records = ks.poll(1000); for (ConsumerRecord&lt;String, OrderMsg&gt; record : records) &#123; String message = String.format(&quot;Consumed: key = %s value = %s with offset = %d &quot;, record.key(), record.value().toString(), record.offset()); System.out.println(message); &#125; &#125; &#125;&#125; 所有代码均通过测试 后期参考springboot整合kafka并自定义序列化器]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>大数据分析</tag>
        <tag>解决方案</tag>
        <tag>自定义序列器</tag>
        <tag>构建生产和消费对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka快速上手]]></title>
    <url>%2F2019%2F11%2F06%2F2019-11-06-Kafka%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[kafkaStreams运行在kafka之上。没有kafka理论先行,很难始于足下。 kafka的上门之路 kafka架构 生产者和消费者 kafka的安装和运行 kafka架构 kafkaStreams是运行在kafka之上的一个库 示例 比如现在某个公司有3个系统。销售系统，营销系统，审计系统。系统之间数据可以相互共享获取 如果随着系统越来越多，数据相互之间都需要共享。这个时候可以使用kafka来做为数据中台。它满足几点要求 数据中心是无状态的 以一种方式接受交易数据并存储,消费程序可以根据自己的需要从数据中心提取信息。 数据中心只知道交易数据要保存多久。以及什么时候切分和删除这些数据 kafka介绍一个具有容错能力，健壮的发布/订阅系统,一个节点称为一个代理。多个代理组成一个集群。 kafka将生产者写入的消息存储在kafka的主题中,消费者订阅kafka主题。与kafka通信查看主体是否有可用的信息* kafka是一个消息代理 kafka是一个中介,将进行交换或交易但是不一定相互了解的两部分汇聚一起。 kafka将消息存储在主题中,从主题检索消息.本身不会和消费者和订阅者保持任何状态.仅作为一个消息中心 kafka底层技术用的是日志,不断追加输入记录文件。 主题的消息负载,kafka使用分区。 kafka是一个日志 日志用于记录应用程序正在做什么,如果程序出现问题。首先检查的是应用程序日志。 在kafka设计理念中，日志是一种只能追加的，完全按照时间顺序排列的记录序列 日志是具有强大含义的简单数据抽象.如果记录时间有序。解决冲突或者确定哪个数据更新到不同的机器就更加的明确 kafka的日志是按照主题名称分隔日志的,如果日志在一个集群中有多个副本。如果一台服务器宕机。从故障中回复是分布式提交日志具有的。 这也分布式应用程序和数据一致性的基本要求 kafka日志工作原理 kafka将每个主题映射到指定日志路径的下一个子目录。子目录数和主题对应的分区数相同。 每个目录里面存放都是追加传入消息的日志文件 一旦日志文件达到某个规模，日志文件就会被切分。消息会追加到一个新的日志文件中. 比如： /logs/topicA_0 logs是消息存储的根目录,目录下代表着主题的分区,下划线后面紧跟分区编号 kafka和分区 分区能够保证同一个键的数据按序发送给同一个消费者 kafka将每个传入的消息追加到日志末尾,消息都严格按照时间排列.不保证跨分区有序，但能保证每个分区消息有序 分区无键和有键的方式 键为空,生产者按照轮询的方式选择分区写入记录 键不为空,则按照 hascode.(key) % number of partitions 自定义分区12345678910111213public class PurchaseKeyPartitioner extends DefaultPartitioner &#123; @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123; Object newKey = null; if (key != null) &#123; PurchaseKey purchaseKey = (PurchaseKey) key; newKey = purchaseKey.getCustomerId(); keyBytes = ((String) newKey).getBytes(); &#125; return super.partition(topic, newKey, keyBytes, value, valueBytes, cluster); &#125;&#125; 可以在生产者配置上设置properties.put(&quot;partitioner.class&quot;, PurchaseKeyPartitioner.class.getName()); 分布式日志kafka提供了数据冗余,数据被写入到一个节点的时候,数据会被复制到一台或者多台机器上 其次选择zookeeper作为代理控制器目的在于: 集群成员 主题配置 访问控制 日志管理 传统的日志删除通过设置log.roll.ms会对日志进行切分 通过设置log.retention.ms会设置日志的保留时间 日志压缩通过这只log.cleanup.policy = compact可以设置日志压缩 注意:如果消息是独立的.就可以用日志删除.如果是需要对消息又更新最新点上面的操作，就可以使用日志压缩 生产者和消费者12345678910111213141516171819202122232425262728Properties properties = new Properties(); //服务器引导可以有多个逗号之间隔开 properties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); //转换为正确的字节数组需要提供正确的序列化器 properties.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); properties.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); //是否应答 all代表领导和追随者确认后应答 1代表只需要领导者应答 0无需做任何等待 properties.put(&quot;acks&quot;, &quot;1&quot;); //消息发送失败，尝试的次数 properties.put(&quot;retries&quot;, &quot;3&quot;); //日志压缩类型 properties.put(&quot;compression.type&quot;, &quot;snappy&quot;); //指定自定义的分区器 properties.put(&quot;partitioner.class&quot;, PurchaseKeyPartitioner.class.getName()); PurchaseKey key = new PurchaseKey(&quot;12334568&quot;, new Date()); try(Producer&lt;PurchaseKey, String&gt; producer = new KafkaProducer&lt;&gt;(properties)) &#123; ProducerRecord&lt;PurchaseKey, String&gt; record = new ProducerRecord&lt;&gt;(&quot;some-topic&quot;, key, &quot;对应的json数据&quot;); Callback callback = (metadata, exception) -&gt; &#123; if (exception != null) &#123; exception.printStackTrace(); &#125; &#125;; Future&lt;RecordMetadata&gt; sendFuture = producer.send(record, callback); &#125; 生产者可指定分区和时间戳以及指定分区 指定分区和时间戳 构造器重载有4个方法，可以指定分区和时间戳 分区位置平均可以考虑 AtomicInteger count = new AtomicInteger(0); AtomicInteger类的理解与使用 消费者首先生产者是无状态的,但是消费者需要周期性的提交从代理中消费过的消息的偏移量来管理一些状态。 消费者提交一个偏移量有以下含义 意味着消费者完全处理了消息 也表示发生故障或者重启时该消费者消费的起始位置 如果创建了消费者发生了某些故障，并且最后的提交的偏移量不可用。消费者从何处开始消费取决于具体的配置 earliest从最早可用的偏移量检索消息 latest本质从消费者加入集群的时间点开始消费消息 none代理将会向消费者抛出异常 同样消费者可以自动提交偏移量,以及手动提交偏移量 消费者代码示例 （引用书中代码） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class ThreadedConsumerExample &#123; private volatile boolean doneConsuming = false; private int numberPartitions; private ExecutorService executorService; public ThreadedConsumerExample(int numberPartitions) &#123; this.numberPartitions = numberPartitions; &#125; public void startConsuming() &#123; executorService = Executors.newFixedThreadPool(numberPartitions); Properties properties = getConsumerProps(); for (int i = 0; i &lt; numberPartitions; i++) &#123; Runnable consumerThread = getConsumerThread(properties); executorService.submit(consumerThread); &#125; &#125; private Runnable getConsumerThread(Properties properties) &#123; return () -&gt; &#123; Consumer&lt;String, String&gt; consumer = null; try &#123; consumer = new KafkaConsumer&lt;&gt;(properties); consumer.subscribe(Collections.singletonList(&quot;test-topic&quot;)); while (!doneConsuming) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(5000); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; String message = String.format(&quot;Consumed: key = %s value = %s with offset = %d partition = %d&quot;, record.key(), record.value(), record.offset(), record.partition()); System.out.println(message); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (consumer != null) &#123; consumer.close(); &#125; &#125; &#125;; &#125; public void stopConsuming() throws InterruptedException &#123; doneConsuming = true; executorService.awaitTermination(10000, TimeUnit.MILLISECONDS); executorService.shutdownNow(); &#125; private Properties getConsumerProps() &#123; Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); properties.put(&quot;group.id&quot;, &quot;simple-consumer-example&quot;); properties.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;); properties.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); properties.put(&quot;auto.commit.interval.ms&quot;, &quot;3000&quot;); properties.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); properties.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); return properties; &#125; /** * Change the constructor arg to match the actual number of partitions */ public static void main(String[] args) throws InterruptedException &#123; ThreadedConsumerExample consumerExample = new ThreadedConsumerExample(2); consumerExample.startConsuming(); Thread.sleep(60000); //Run for one minute consumerExample.stopConsuming(); &#125;&#125; Java ExecutorService四种线程池的例子与说明 深入理解volatile kafka的安装和运行 kafka选择版本 2.12-1.1.0 默认情况下kafka使用9092端口,zookeeper使用2181端口 kafka的配置在config的server.properties中-日志配置在log.dirs zookeeper在zookeeper.properties中-日志在dataDir中 操作步骤 1.先启动zookeeper kafka_2.12-1.1.0 % bin/zookeeper-server-start.sh config/zookeeper.properties 2.启动kafka bin/kafka-server-start.sh config/server.properties 3.创建一个主题供生产和消费进行操作 bin/kafka-topics.sh --create --topic first-topic --replication-factor 1 --partitions 1 --zookeeper localhost:2181 replication-factor 副本设置为1表示不复制。实际中副本因子为奇数以上以便发生故障时保证数据可用性 partitions 指定主题将用到的分区数。如果需要更高的负载，需要更多的分区。 4.通过生产者控制台发送消息 bin/kafka-console-producer.sh --topic first-topic --broker-list localhost：9092 5.通过消费者控制台接收消息 bin/kafka-console-consumer.sh --topic first-topic --bootstrap-server localhost:9092 --from-beginning from-beginning 消费者为从头接受消息,但没有提交偏移量]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>应用场景</tag>
        <tag>大数据分析</tag>
        <tag>消息队列</tag>
        <tag>生产者和消费者</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafkaStreams初识]]></title>
    <url>%2F2019%2F11%2F04%2F2019-11-04-KafkaStreams%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[如何使用好流式处理.流式处理从成本和人力该如何考虑,以及应用场景. 数据以及kafkaStreams的理念 数据的发展如何改变程序设计的 流式处理工作以及应用场景 kafkaStreams的简介以及解决问题 数据的发展如何改变程序设计的在现在的世界中,每天的数据越来越多。如何有有效的利用这些数据,就是我们当下需要考虑的点 现在有2种方式处理数据,一种是我们进行批量处理数据(批处理)这些数据都是离线的,第二种就是数据在到达的时候就需要进行处理。 kafkaStream是一个对记录的每个时间进行处理的库,基于每个时间就意味着数据一旦到达,就能够被及时处理.不需要将数据分成小批量的 MapReduce范式(补充)map会对每个记录产生一个键值对.而reduce基于每个键合并,处理中间结果 对于TB级别以上的数据有几个概念让我们更好的处理数据 一个集群中分发的数据达到易于处理的规模 使用键值对讲分布式的数据分组 利用副本备份机制容忍故障的产生，而不是避免故障 也就是通过计算机集群中的分散负载,就可以将数据转化为可管理的数量 其次如何将分布在不同机器上的数据进行汇总也就是分区 分区意味着分组.使用相同的散列码的键进行分组。 公式如下: partition = key.hashCode()% numberOfPartitions 补充:通过使用复制来接受故障。通过复制不同服务器上的数据块,不必担心磁盘故障导致停产.数据复制能够对于分布式的应用提供容错能力至关重要 离线计算的瓶颈 离线计算首先需要收集大量的数据，批处理的离线计算适合根据根据用户大量的习惯来决定未来可能会发生的事情 如果用户的习惯是偶然性，那就无法判断资源价值的有效利用 面对的问题 当前实时的趋势是什么？ 最近一个周期时间段的特征是什么？ 用户如何利用最新的发布的特性的？ 流式处理工作以及应用场景 定义:流式处理是利用连续计算处理无线数据流的能力,数据是流动的,所以无需收集以及存储数据。 流式数据的应用场景 信用卡诈骗:根据实时的消费记录,以及对比用户前期的消费习惯和地点,可能信用卡被盗刷.提醒信用卡的拥有者 入侵检测:实时监控异常行为. 大型自行车比赛:通过实时传输的数据,监测位置。以及比赛可能会遇到的问题。 金融业:根据实时买入卖出，提供决策能力 场景:数据到达时需要被立即报告处理,那么可以选择流式处理 如果需要对许菊进行深入分析.或者为了编制一个大的数据仓库以备后期分析,那么这个时候需要离线计算 kafkaStreams的简介以及解决问题假定有一个实时销售系统,我们要根据实时的数据对每个客户甚至于公司的团队制定决策 需求分解：有向无环图 购买记录 —-&gt; 屏蔽信息 屏蔽信息 —-&gt; 存储 ----&gt; 奖励 ----&gt; 模式 分析节点 源节点 —&gt; 每条销售信息记录 信用卡屏蔽节点 —-&gt; 将源节点的信息中卡号进行屏蔽 模式节点 —-&gt; 检索相关的物品，日期，邮政编码组装为一个新的对象 奖励节点 —-&gt; 抽取客户的ID和实时的消费金额 存储节点 —-&gt; 存储到相信的关系或者非关系数据中进行分析 注意:至始至终,这种有向无环图,我们都以深度优先的方式进行遍历以及处理数据。深度优先和广度优先可以参考 深度和广度优先 Java实现深度优先遍历和广度优先遍历 总结:数据交由了节点和处理器来进行共同的维护。节点即是需求规则，最终会将节点数据传输到对应的主题中,而处理器则存在在kafkaStream流上。处理器所处理的数据产生出来都是一个新的对象]]></content>
      <categories>
        <category>KafkaStreams</category>
      </categories>
      <tags>
        <tag>kafkaStreams</tag>
        <tag>流式计算</tag>
        <tag>应用场景</tag>
        <tag>大数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAli链路管理]]></title>
    <url>%2F2019%2F10%2F11%2F2019-10-11-SpringAli%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[链路追踪虽然是运维做的事情,但是我们作为开发的应该走一走 springAli链路追踪 什么是链路追踪 链路追踪解决方案 如何使用skywalking 什么是链路追踪微服务架构是通过业务来划分服务的，使用REST调用。对外暴露的一个接口，可能需要很多个服务协同才能完成这个接口功能，如果链路上任何一个服务出现问题或者网络超时，都会形成导致接口调用失败。随着业务的不断扩张，服务之间互相调用会越来越复杂 情况如下: 当然服务肯定不止这几个,或许会有上百个,有没有可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题，这就是所谓的 APM（应用性能管理）。 链路追踪解决方案 SkyWalking 多种监控手段，语言探针和服务网格(Service Mesh) 多语言自动探针，Java，.NET Core 和 Node.JS 轻量高效，不需要大数据 模块化，UI、存储、集群管理多种机制可选 支持告警 优秀的可视化方案 如何使用skywalking 1.安装docker,使用docker-compose执行编排文件 1234567891011version: &apos;3.3&apos;services: elasticsearch: image: wutang/elasticsearch-shanghai-zone:6.3.2 container_name: elasticsearch restart: always ports: - 9200:9200 - 9300:9300 environment: cluster.name: elasticsearch docker-compose up -d(启动并后台运行) docker-compose stop(停止) 访问localhost:9200 2.下载skywalking,修改配置文件config下application.yml 12345678910111213141516171819202122storage: elasticsearch: nameSpace: $&#123;SW_NAMESPACE:&quot;&quot;&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; user: $&#123;SW_ES_USER:&quot;&quot;&#125; password: $&#123;SW_ES_PASSWORD:&quot;&quot;&#125; indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:2000&#125; # Execute the bulk every 2000 requests bulkSize: $&#123;SW_STORAGE_ES_BULK_SIZE:20&#125; # flush the bulk every 20mb flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; # the number of concurrent requests metadataQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_SIZE:5000&#125; segmentQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200&#125;# h2:# driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125;# url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125;# user: $&#123;SW_STORAGE_H2_USER:sa&#125;# metadataQueryMaxSize: $&#123;SW_STORAGE_H2_QUERY_MAX_SIZE:5000&#125;# mysql:# metadataQueryMaxSize: $&#123;SW_STORAGE_H2_QUERY_MAX_SIZE:5000&#125; 3.切换并启动 cd /Users/Yun/apache-skywalking-apm-bin/bin 执行./startup.sh访问默认端口http://localhost:8080 4.在idea中部署探针 增加vm参数 123-javaagent:/Users/Yun/mycloud/clouddependencies/spring-cloud-external-skywalking/agent/skywalking-agent.jar-Dskywalking.agent.service_name=provider-Dskywalking.collector.backend_service=localhost:11800 5.启动项目 其余服务同理设置 Avg SLA： 服务可用性（主要是通过请求成功与失败次数来计算） CPM： 每分钟调用次数 Avg Response Time： 平均响应时间]]></content>
      <categories>
        <category>Spring微服务</category>
      </categories>
      <tags>
        <tag>Spring全家桶</tag>
        <tag>微服务</tag>
        <tag>高效开发</tag>
        <tag>链路追踪</tag>
        <tag>应用性能管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAli统一资源管理]]></title>
    <url>%2F2019%2F10%2F10%2F2019-10-10-SpringAli%E8%B5%84%E6%BA%90%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[如何做到资源的统一高效管理,nacos-config是一个不错的选择 springAli资源管理 统一资源管理的应用场景 实际操作(代码示例) 统一资源管理的应用场景 场景说明 在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。 也就是配置文件众多,你不可能每次更改后然后在打包为jar包运行,是否有一种方式可以通过读取远端的配置文件,随时可以更改端口或者服务名等一系列的动作 解决方案 解决方案:使用nacos config:使用 Spring Cloud Alibaba Nacos Config，可以在 Nacos Server 集中管理你 Spring Cloud 应用的外部属性配置 作用原理 作用:在特殊的 bootstrap 阶段，配置被加载到Spring环境中。当应用程序通过部署管道从开发到测试再到生产时，您可以管理这些环境之间的配置，并确保应用程序具有迁移时需要运行的所有内容。 实际操作(代码示例) 1.启动nacos服务(添加配置文件,不限于消费者或者服务者的配置文件) 1234567891011121314151617181920212223242526272829spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 sentinel: transport: dashboard: 127.0.0.1:8080 # 当前应用被sentinel监控的端口 port: 8720server: port: 8082management: endpoints: web: exposure: include: &quot;*&quot;#sentinelfeign: sentinel: enabled: true#cus attruser: uname: wwj age: 32 2.替换yml文件,新建读取属性文件bootstrap.properties 注意：Spring Boot 配置文件的加载顺序，依次为 bootstrap.properties -&gt; bootstrap.yml -&gt; application.properties -&gt; application.yml ，其中 bootstrap.properties 配置为最高优先级 3.新建一个controller用来作为数据可实时配置更新 12345678910111213141516@RestControllerpublic class Tcontroller &#123; /** * 注入配置文件上下文 */ @Autowired private ConfigurableApplicationContext applicationContext; /** * 从上下文中读取配置 */ @GetMapping(value = &quot;/hi&quot;) public String getNameFromNacosConfig() &#123; return &quot;Hello &quot; + applicationContext.getEnvironment().getProperty(&quot;user.uname&quot;); &#125;&#125; 4.pom.xml中添加nacos-config的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 5.启动服务 更改配置文件再次访问]]></content>
      <categories>
        <category>Spring微服务</category>
      </categories>
      <tags>
        <tag>Spring全家桶</tag>
        <tag>微服务</tag>
        <tag>高效开发</tag>
        <tag>统一注册配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAli统一网关]]></title>
    <url>%2F2019%2F10%2F09%2F2019-10-09-SpringAli%E7%BB%9F%E4%B8%80%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[统一路由网关,看得直接明白. springAlibaba路由网关 什么是spring网关 网关的功能特征 实际操作 网关全局过滤 什么是spring网关为微服务架构提供一种简单而有效的统一的 API 路由管理方式,不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 网关的功能特征 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流和路径重写 实际操作 新建项目pom.xml如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud-dependencies&lt;/artifactId&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;spring-cloud-alibaba-gateway&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Commons Begin --&gt; &lt;!--需要过滤器--&gt; &lt;dependency&gt;GatewayApplication &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Commons Begin --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.wwj.gateway.GatewayApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 注意:Spring Cloud Gateway 不使用 Web 作为服务器，而是 使用 WebFlux 作为服务器，Gateway 项目已经依赖了 starter-webflux，所以这里 千万不要依赖 starter-web,由于过滤器等功能依然需要 Servlet 支持，故这里还需要依赖 javax.servlet:javax.servlet-api 构建启动项目类 12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class, args); &#125;&#125; applcation.yml配置文件如下 12345678910111213141516171819202122232425262728293031323334353637383940414243spring: application: # 应用名称 name: spring-gateway cloud: # 使用 Naoos 作为服务注册发现 nacos: discovery: server-addr: 127.0.0.1:8848 # 使用 Sentinel 作为熔断器 sentinel: transport: port: 8721 dashboard: 127.0.0.1:8080 # 路由网关配置 gateway: # 设置与服务注册发现组件结合，这样可以采用服务名的路由策略 discovery: locator: enabled: true # 配置路由规则 routes: # 采用自定义路由 ID（有固定用法，不同的 id 有不同的功能，详见：https://cloud.spring.io/spring-cloud-gateway/2.0.x/single/spring-cloud-gateway.html#gateway-route-filters） - id: NACOS-CONSUMER # 采用 LoadBalanceClient 方式请求，以 lb:// 开头，后面的是注册在 Nacos 上的服务名 uri: lb://consumer # Predicate 翻译过来是“谓词”的意思，必须，主要作用是匹配用户的请求，有很多种用法 predicates: # Method 方法谓词，这里是匹配 GET 和 POST 请求 - Method=GET,POST - id: NACOS-CONSUMER-FEIGN uri: lb://consumer-feign predicates: - Method=GET,POSTserver: port: 9000# 配置日志级别，方别调试logging: level: org.springframework.cloud.gateway: debug 依次启动服务提供者,2个消费者,以及网关 网关全局过滤全局过滤器作用于所有的路由，不需要单独配置，我们可以用它来实现很多统一化处理的业务需求，比如权限认证，IP 访问限制等等. 构建一个filter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.wwj.gateway.filter;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.common.collect.Maps;import lombok.extern.slf4j.Slf4j;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.Ordered;import org.springframework.core.io.buffer.DataBuffer;import org.springframework.http.HttpStatus;import org.springframework.http.server.reactive.ServerHttpResponse;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import java.util.Map;@Slf4j@Componentpublic class AuthFilter implements GlobalFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; String token = exchange.getRequest().getQueryParams().getFirst(&quot;token&quot;); if (token == null || token.isEmpty()) &#123; ServerHttpResponse response = exchange.getResponse(); // 封装错误信息 Map&lt;String, Object&gt; responseData = Maps.newHashMap(); responseData.put(&quot;code&quot;, 401); responseData.put(&quot;message&quot;, &quot;非法请求&quot;); responseData.put(&quot;cause&quot;, &quot;Token is empty&quot;); try &#123; // 将信息转换为 JSON ObjectMapper objectMapper = new ObjectMapper(); byte[] data = objectMapper.writeValueAsBytes(responseData); // 输出错误信息到页面 DataBuffer buffer = response.bufferFactory().wrap(data); response.setStatusCode(HttpStatus.UNAUTHORIZED); response.getHeaders().add(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;); return response.writeWith(Mono.just(buffer)); &#125; catch (JsonProcessingException e) &#123; log.error(&quot;&#123;&#125;&quot;, e); &#125; &#125; return chain.filter(exchange); &#125; @Override public int getOrder() &#123; //顺序，多个filter的时候使用 return 0; &#125;&#125;]]></content>
      <categories>
        <category>Spring微服务</category>
      </categories>
      <tags>
        <tag>Spring全家桶</tag>
        <tag>微服务</tag>
        <tag>高效开发</tag>
        <tag>统一认证</tag>
        <tag>统一网关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAli服务容灾]]></title>
    <url>%2F2019%2F09%2F24%2F2019-09-24-SpringAli%E6%9C%8D%E5%8A%A1%E5%AE%B9%E7%81%BE%2F</url>
    <content type="text"><![CDATA[如何有效的监控服务,是我们要考量的问题。使用Sentinel提供解决方案.减少我们的人力成本和物力成本 springAlibaba服务熔断 为何出现服务熔断 使用Sentinel提供解决方案 Sentinel特征 Fegin使用Sentinel 使用熔断器表盘进行监控 为何出现服务熔断1.微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC 协议相互调用,在springcloud我们可以使用feign进行服务的调用。而为了保证服务的高可用,我们会把服务部署到集群上面,但是由于网络的原因或者自身出现的不可控的情况。会出现调用该服务出现阻塞 2.出现阻塞后,如果大量的请求涌入进来,而服务故障得不到及时处理,容器的西安城资源就会消耗完毕,导致服务瘫痪,因为服务之间在进行相互的调用,会产生对等依赖特性,也就会影响其它的服务.这就会造成我们所说的雪崩效应 3.如何解决:提出了熔断器模式.当到达一定的阈值的时候,进行一个特殊的处理。如同曾经证券市场推出来的熔断机制,虽然没有坚挺很久 使用Sentinel提供解决方案1.服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 2.Sentinel 组件，实现了熔断器模式，SpringCloud对这一组件进行了整合。在微服务架构中，一个请求需要调用多个服务是非常常见的，较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值熔断器将会被打开。熔断器打开后，为了避免连锁故障，通过 fallback 方法可以直接返回一个固定值。 Sentinel 的特征 丰富的应用场景：秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等 完备的实时监控： Sentinel同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况 Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与SpringCloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入Sentinel。 完善的 SPI 扩展点：Sentinel提供简单易用、完善的SPI扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等。 Fegin使用Sentinel使用feign项目中引用Sentinel pom.xml文件添加如下: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 在全局配置文件添加1234#sentinelfeign: sentinel: enabled: true 创建熔断类实现对应的service的接口12345678910package com.wwj.consumer.feign.fallback;import com.wwj.consumer.feign.service.ProviderService;@Componentpublic class ProviderServiceFallback implements ProviderService &#123; @Override public String echo(String message) &#123; return &quot;sentinel fallback&quot;; &#125;&#125; 在Feign中的Service中增加fallback指定类123456789101112/** * 1.通过@FeignClient伪造一个http客户端请求已经注册的服务 * 2.接口中的方法需要去匹配已经注册的服务方里面的请求 */@FeignClient(value = &quot;nacos-provider&quot;,fallback = ProviderServiceFallback.class)public interface ProviderService &#123; @GetMapping(value = &quot;/echo/&#123;message&#125;&quot;) String echo(@PathVariable String message);&#125; 测试结果正常启动消费者和提供者 关闭提供者(模拟服务提供方崩溃) 使用熔断器表盘进行监控表盘监控说明Sentinel 控制台提供一个轻量级的控制台，它提供机器发现、单机资源实时监控、集群资源汇总，以及规则管理的功能。您只需要对应用进行简单的配置，就可以使用这些功能。 注意: 集群资源汇总仅支持 500 台以下的应用集群，有大概 1 - 2 秒的延时。 下载切换到对等的目录并打包1234567# 下载源码git clone https://github.com/alibaba/Sentinel.git#切换目录cd /Users/Yun/Sentinel/sentinel-dashboard# 编译打包mvn clean package 或者 下载最新控制台jar包 切换到控制面板目录执行程序12java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 在Feign客户端的application.yml 和 pom.xml1234567891011121314151617181920212223242526spring: application: name: consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848 sentinel: transport: dashboard: 127.0.0.1:8080 # 当前应用被sentinel监控的端口 port: 8719#sentinelfeign: sentinel: enabled: trueserver: port: 9092management: endpoints: web: exposure: include: &quot;*&quot; 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 端口配置会在应用对应的机器上启动一个 Http Server，该 Server 会与 Sentinel 控制台做交互。比如 Sentinel 控制台添加了 1 个限流规则，会把规则数据 push 给这个 Http Server 接收，Http Server 再将规则注册到 Sentinel 中。 同理可以把监控添加给服务方或者消费方 可以看到利用哨兵对服务进行了监控,可设置QPS]]></content>
      <categories>
        <category>Spring微服务</category>
      </categories>
      <tags>
        <tag>Spring全家桶</tag>
        <tag>微服务</tag>
        <tag>高效开发</tag>
        <tag>哨兵</tag>
        <tag>服务容灾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAli服务消费]]></title>
    <url>%2F2019%2F09%2F18%2F2019-09-18-SpringAli%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%2F</url>
    <content type="text"><![CDATA[微服务改变着我们的项目结构,影响深远 Spring Cloud Alibaba 服务消费 服务消费(原始方式) 服务消费(使用Feign) 服务消费(原始方式) 显示的使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问。 创建新的moudle模块(消费者),pom.xml如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud-dependencies&lt;/artifactId&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;nacos-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.wwj.consumer.ConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 安装标准构建启动类12345678@SpringBootApplication@EnableDiscoveryClientpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class, args); &#125;&#125; 构建一个ConsumerConfiguration配置类,注入RestTemplate对象1234567@Configurationpublic class ConsumerConfiguration &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 编写controller123456789101112131415161718192021222324252627282930313233package com.wwj.consumer.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestControllerpublic class ConsumerController &#123; //注入启动客户端对象 @Autowired private LoadBalancerClient loadBalancerClient; //注入RestTemplate模板 @Autowired private RestTemplate restTemplate; //可以用来获取当前应用名称 @Value(&quot;$&#123;spring.application.name&#125;&quot;) private String appName; @GetMapping(value = &quot;/echo/app/name&quot;) public String echo() &#123; //使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 //选择服务名字 ServiceInstance serviceInstance = loadBalancerClient.choose(&quot;provider&quot;); //拼接restful请求 String url = String.format(&quot;http://%s:%s/echo/%s&quot;, serviceInstance.getHost(), serviceInstance.getPort(), appName); return restTemplate.getForObject(url, String.class); &#125;&#125; 构建应用程序启动文件 application.yml12345678910111213141516spring: application: name: consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9091management: endpoints: web: exposure: include: &quot;*&quot; 结果如下 端点检查 http://localhost:9091/actuator/nacos-discovery 服务消费(使用Feign) 概论 Feign 是一个声明式的伪 Http 客户端，它使得写 Http 客户端变得更简单。使用 Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用 Feign 注解和 JAX-RS 注解。Feign 支持可插拔的编码器和解码器。Feign 默认集成了 Ribbon，Nacos 也很好的兼容了 Feign，默认实现了负载均衡的效果 使用接口很容易抽象理解 集成Ribbon达到负载均衡 构建新的moudle,pom.xml内容如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud-dependencies&lt;/artifactId&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;nacos-consumer-feign&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.wwj.consumer.feign.ConsumerFeignApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 构建启动类12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ConsumerFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerFeignApplication.class, args); &#125;&#125; 通过feign调用远程服务1234567891011/** * 1.通过@FeignClient伪造一个http客户端请求已经注册的服务 * 2.接口中的方法需要去匹配已经注册的服务方里面的请求 */@FeignClient(value = &quot;nacos-provider&quot;)public interface ProviderService &#123; @GetMapping(value = &quot;/echo/&#123;message&#125;&quot;) String echo(@PathVariable String message);&#125; controller注入对应的服务1234567891011@RestControllerpublic class ProviderController &#123; @Autowired private ProviderService providerService; @GetMapping(&quot;echo&quot;) public String echo() &#123; return providerService.echo(&quot;Feign Client&quot;); &#125;&#125; 全局配置文件声明如下12345678910111213141516spring: application: name: consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9092management: endpoints: web: exposure: include: &quot;*&quot; 结果如下 测试负载均衡 服务端启动多个示例 多次访问localhost:9092/echo]]></content>
      <categories>
        <category>Spring微服务</category>
      </categories>
      <tags>
        <tag>Spring全家桶</tag>
        <tag>微服务</tag>
        <tag>高效开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAli服务注册]]></title>
    <url>%2F2019%2F09%2F16%2F2019-09-16-SpringAli%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%2F</url>
    <content type="text"><![CDATA[微服务改变着我们的项目结构,影响深远 Spring Cloud Alibaba 服务注册与发现 Nacos简介 Nacos安装 测试Nacos 整合Nacos(含服务提供者和消费者) 重温nacos概念和常用配置项 Nacos简介Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 官网链接 Nacos安装 1.下载源码 git clone https://github.com/alibaba/nacos.git 2.安装 mvn -Prelease-nacos clean install -U 测试Nacos1234#切换至nacos下的bin目录/Users/Yun/nacos/distribution/target/nacos-server-1.1.3/nacos/bin# Linux./startup.sh -m standalone 注意:访问端口为8848/nacos,用户名和密码都为nacos 整合Nacos 1.新建maven项目,pom.xml如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;!-- 项目信息--&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;nacos-provider&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt;&lt;!-- 项目继承--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;/parent&gt;&lt;!-- 项目版本--&gt; &lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;/properties&gt;&lt;!-- 项目管理--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;!-- 构建环境--&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- Java Document Generate --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- YUI Compressor (CSS/JS压缩) --&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compress&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;jswarn&gt;false&lt;/jswarn&gt; &lt;nosuffix&gt;true&lt;/nosuffix&gt; &lt;linebreakpos&gt;30000&lt;/linebreakpos&gt; &lt;force&gt;true&lt;/force&gt; &lt;includes&gt; &lt;include&gt;**/*.js&lt;/include&gt; &lt;include&gt;**/*.css&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.min.js&lt;/exclude&gt; &lt;exclude&gt;**/*.min.css&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 2.在该项目上新增moudle（nacos-provider） pom.xml文件如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud-dependencies&lt;/artifactId&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;nacos-provider&lt;/artifactId&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.wwj.provider.ProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.启动类如下 1234567@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderApplication.class, args); &#125;&#125; 3.控制层代码以及yml配置文件 1234567891011121314@RestControllerpublic class Pcontroller &#123; @Value(&quot;$&#123;server.port&#125;&quot;) private String port; @GetMapping(value = &quot;/echo/&#123;message&#125;&quot;) public String echo(@PathVariable String message) &#123; return &quot;Hello Nacos Discovery &quot; + message + &quot; , From port :&quot; + port; &#125;&#125; 12345678910111213141516spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 8081management: endpoints: web: exposure: include: &quot;*&quot; 分别启动服务端和程序端 同时我们也可以通过服务端点进行检查 http://ip:port/actuator/nacos-discovery 1、subscribe: 显示了当前有哪些服务订阅者2、NacosDiscoveryProperties: 显示了当前服务实例关于 Nacos 的基础配置 nacos常用的配置项 重温nacos的概念 服务 (Service)服务是指一个或一组软件功能（例如特定信息的检索或一组操作的执行），其目的是不同的客户端可以为不同的目的重用（例如通过跨进程的网络调用）。Nacos 支持主流的服务生态，如 Kubernetes Service、gRPC|Dubbo RPC Service 或者 Spring Cloud RESTful Service. 服务注册中心 (Service Registry)服务注册中心，它是服务，其实例及元数据的数据库。服务实例在启动时注册到服务注册表，并在关闭时注销。服务和路由器的客户端查询服务注册表以查找服务的可用实例。服务注册中心可能会调用服务实例的健康检查 API 来验证它是否能够处理请求。 服务元数据 (Service Metadata)服务元数据是指包括服务端点(endpoints)、服务标签、服务版本号、服务实例权重、路由规则、安全策略等描述服务的数据 服务提供方 (Service Provider)是指提供可复用和可调用服务的应用方 服务消费方 (Service Consumer)是指会发起对某个服务调用的应用方 配置 (Configuration)在系统开发过程中通常会将一些需要变更的参数、变量等从代码中分离出来独立管理，以独立的配置文件的形式存在。目的是让静态的系统工件或者交付物（如 WAR，JAR 包等）更好地和实际的物理运行环境进行适配。配置管理一般包含在系统部署的过程中，由系统管理员或者运维人员完成这个步骤。配置变更是调整系统运行时的行为的有效手段之一。 配置管理 (Configuration Management)在数据中心中，系统中所有配置的编辑、存储、分发、变更管理、历史版本管理、变更审计等所有与配置相关的活动统称为配置管理。 名字服务 (Naming Service)提供分布式系统中所有对象(Object)、实体(Entity)的“名字”到关联的元数据之间的映射管理服务，例如 ServiceName -&gt; Endpoints Info, Distributed Lock Name -&gt; Lock Owner/Status Info, DNS Domain Name -&gt; IP List, 服务发现和 DNS 就是名字服务的2大场景。 配置服务 (Configuration Service)在服务或者应用运行过程中，提供动态配置或者元数据以及配置管理的服务提供者。]]></content>
      <categories>
        <category>Spring微服务</category>
      </categories>
      <tags>
        <tag>Spring全家桶</tag>
        <tag>微服务</tag>
        <tag>高效开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAli准备工作]]></title>
    <url>%2F2019%2F09%2F16%2F2019-09-16-SpringAli%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[微服务改变着我们的项目结构,影响深远 Spring Cloud Alibaba(准备) springCloud-alibaba(组件简介) 使用idea创建分模块创建统一的依赖管理 springCloud-alibaba(组件简介) 1.服务限流降级 默认支持 Servlet、Feign、RestTemplate、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 2.服务注册与发现 适配 SpringCloud 服务注册与发现标准，默认集成了 Ribbon的支持 3.分布式配置管理 支持分布式系统中的外部化配置，配置更改时自动刷新。 其余的功能请参照官方文档阿里官方文档 使用idea创建分模块创建统一的依赖管理 1.构建目录结构 2.添加对应的pom.xml文件加入到maven管理中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;!-- 项目信息--&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt;&lt;!-- 项目继承--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt; &lt;/parent&gt;&lt;!-- 项目版本--&gt; &lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;2.1.0.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;/properties&gt;&lt;!-- 项目管理--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt;]]></content>
      <categories>
        <category>Spring微服务</category>
      </categories>
      <tags>
        <tag>Spring全家桶</tag>
        <tag>微服务</tag>
        <tag>高效开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis1]]></title>
    <url>%2F2019%2F09%2F10%2F2019-09-10-Mybatis(%E7%BC%98)%2F</url>
    <content type="text"><![CDATA[mybatis是一个优秀的开源框架,半自动ORM映射,能够适配各种业务需求 mybatis的路线图(上) mybatis简介 mybatis框架执行原理 mybatis初次的入门案例 mybatis配置文件详解 mybatis 方法多参数的处理 mybatis返回主键值 sql代码段 自定义结果类型ResultMap mybatis简介mybatis本身是一个轻量级的持久化层框架(1.何为持久化。2.何为序列化操作),本身也是基于JDBC的封装(JDBC的链接步骤).开发者本身更多的关注SQL语句的执行效率,除此之外mybatis也是一个半自动的ORM映射框架(支持一对一,一对多的实现,多对多采用两个一对多进行实现) 注意:实际的开发过程中,因为大量的关系相互映射的存在,在查询数据这一块不便于后期项目本身的项目维护扩展。所以更多的方向是思考数据库中的设计和利用本身mybatis提供的数据自定义封装和其它的类似缓存机制的特点,解决开发中的数据设计结构 mybatis的优势 比起jdbc的操作,减少了一些重复的代码量工作，也方便能够集成到后期的管理框架中 mybatis提供在XML中编写sql语句,不直接入侵在代码中(方便分类修改） 分别提供的xml标签和mapper标签(xml标签可实现动态SQL语句,也就是嵌入条件判断和循环,比较类似存储函数),mapper标签支持对象正确的解析至数据库中 mybatis框架执行原理 sqlConfigXMl配置文件(一个全局的配置文件)(可配置映射文件和连接数据源和事务等) 通过配置文件构建出可构建操作数据会话的会话工厂,也就是我们常说的sqlSessionFactory(涉及工厂模式代码设计) 通过sqlSessionFactory生产出相互独立的sqlsession,为什么是独立的会话，既然是独立的会话，那也有全局的会话(简单提及缓存)进行数据库层面上面的操作 sqlsession之所以能够操作,依赖一个叫Executor的执行器,通过该执行器进行数据库的CRUD操作 Executor的执行器需要操作CRUD的动作由谁而来，就是由mapperstatement对象读取mapper映射文件 我们可以看到在配置xml文件的时候,可以支持多种对象级数据参数 mybatis初次的入门案例 配置一个log4j.properties(可选)方便我们监听到mybatis进行的动作 1234567\# set levellog4j.rootLogger=DEBUG, stdout\# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n 构建一个普通的web项目,jar包结构如下: src目录下构建mybatis的全局配置文件mybatisCfg.xml,配置文件如下: 123456789101112131415161718192021222324252627&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;!-- 数据库连接环境配置 --&gt; &lt;environments default=&quot;development&quot;&gt; &lt;!-- 标明mybaitis环境 id唯一 --&gt; &lt;environment id=&quot;development&quot;&gt; &lt;!-- JDBC – 这个配置直接简单使用了 JDBC 的提交和回滚设置。 它依赖于从数据源得 到的连接来管理事务范围。JDBC默认是自动提交 --&gt; &lt;transactionManager type=&quot;JDBC&quot; /&gt; &lt;!-- 采用数据库连接池 --&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;!-- 避免环境的不统一，造成数据操作乱码 --&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot; /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 添加需要被映射的文件 --&gt; &lt;mappers&gt; &lt;mapper resource=&quot;com/wwj/dao/PersonMapper.xml&quot; /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 构建模型类 com.wwj.model 和 数据库表 12345678910111213141516171819import java.io.Serializable;import java.util.Date;/** * 基本的模型类 * @author wwj *对象序列化是一个用于将对象状态转换为字节流的过程，可以将其保存到磁盘文件中或通过网络发送到任何其他程序；从字节流创建对象的相反的过程称为反序列化。而创建的字节流是与平台无关的，在一个平台上序列化的对象可以在不同的平台上反序列化。 *无需序列化的变量使用transient */public class Person implements Serializable &#123; //Java的序列化机制是通过在运行时判断类的serialVersionUID来验证版本一致性的 //这里是用来表明版本的一致性 private static final long serialVersionUID = 2680875170108959939L; private Integer id; private String name; private Date bir; private String address; //自行get和set &#125; 创建数据层的操作也就是mapper的操作接口 123456789101112131415161718192021222324252627282930313233343536/** * person层的操作 * * @author Yun * */public interface PersonDao &#123; /** * 新增用户 * * @param p * 传入需要新增的对象 * @return 0,1代表结果 */ int savePerson(Person p); /** * 更新用户对象 * @param p 需要被更新的对象 * @return 0,1代表结果 */ int updatePerson(Person p); /** * 根据用户id进行删除 * @param id 唯一用户id * @return 0，1代表结果 */ int deletePersonById(int id); /** * 获取所有的信息 * @return 所有的人员信息 */ List&lt;Person&gt; getPersonInfos();&#125; 构建对应的mapper映射文件 12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapperPUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.wwj.dao.PersonDao&quot;&gt; &lt;insert id=&quot;savePerson&quot; parameterType=&quot;com.wwj.model.Person&quot;&gt; insert into person(name,address,bir) values(#&#123;name&#125;,#&#123;address&#125;,#&#123;bir&#125;); &lt;/insert&gt; &lt;update id=&quot;updatePerson&quot; parameterType=&quot;com.wwj.model.Person&quot;&gt; update person set name=#&#123;p.name&#125;,address=#&#123;address&#125;,bir=#&#123;bir&#125; where id=#&#123;id&#125; &lt;/update&gt; &lt;delete id=&quot;deletePersonById&quot; parameterType=&quot;int&quot;&gt; delete from person where id=#&#123;id&#125; &lt;/delete&gt; &lt;select id=&quot;getPersonInfos&quot; resultType=&quot;com.wwj.model.Person&quot;&gt; select * from person &lt;/select&gt;&lt;/mapper&gt; 编码测试 1234567891011121314151617181920212223242526272829303132/** * 测试mybatis的CRUD操作 * * @author wwj * */public class TestMybatis &#123; public static void main(String[] args) throws IOException, ParseException &#123; /* * 日期上面的处理 */ SimpleDateFormat sf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); String format = sf.format(new Date()); Date parse = sf.parse(format); InputStream is = Resources.getResourceAsStream(&quot;mybatisCfg.xml&quot;); SqlSessionFactory build = new SqlSessionFactoryBuilder().build(is); // 生成 session SqlSession session = build.openSession(); Person per = new Person(); per.setName(&quot; 小王 &quot;); per.setAddress(&quot; 重庆 &quot;); per.setBir(parse); // 操作数据 int insert = session.insert(&quot;savePerson&quot;,per); // 提交事务 session.commit(); // 关闭 session session.close(); &#125;&#125; 注意:mysql中设置为date支持的格式为yyyy-mm-dd,java中的date是格林威治时间 结果图示 同理依次测试更新和删除,以及查询 更新的调用操作 1234567Person per = new Person();per.setId(1);per.setName(&quot; 小张 &quot;);per.setAddress(&quot; 重庆 &quot;);per.setBir(parse);// 操作数据int update = session.update(&quot;updatePerson&quot;, per); 查询的调用操作 List&lt;Person&gt; pers = session.selectList(&quot;getPersonInfos&quot;); 删除的调用操作 int de = session.delete(&quot;deletePersonById&quot;, 1); mybatis配置文件详解全局配置文件详解 environments环境配置,可以配置多种环境 default指定使用某种环境. transactionManager事务管理器有两种取值JDBC,managed.我们选择jdbc即可 dataSource配置数据源,采用默认的连接池选择项POOLED mappers里面填入需要进行数据操作xml标签用于执行的动作 映射的数据操作文件需要和接口保持同个路径(可以把mapper当成接口的实现类) 映射文件详解 namespace表明需要对应动作的空间即是接口所在的全路径名称 id与接口中的方法保持一致 parameterType填写自定义对象的全路径名称 接收参数采用 #{objAttrName} mybatis方法多参数接收(代码示例）索引接收(了解即可)1234 List&lt;Person&gt; getPersonInfosByNameAndID(String name ,int id);&lt;select id=&quot;getPersonInfosByNameAndID&quot; &gt; select * from person where name = #&#123;0&#125; and id = #&#123;1&#125; &lt;/select&gt; map接收(重点)1234567891011121314151617 /** * 根据map进行查询 * @param attrs * key1 id key2 name * @return */ List&lt;Person&gt; getPersonInfosByMap(Map attrs); //------------------动作实现 &lt;select id=&quot;getPersonInfosByMap&quot; parameterType=&quot;java.util.Map&quot; resultType=&quot;com.wwj.model.Person&quot;&gt; select * from person where id = #&#123;id&#125; and name = #&#123;name&#125;&lt;/select&gt; //----------------调用测试 Map&lt;String,Object&gt; attrs = new HashMap&lt;&gt;(); attrs.put(&quot;id&quot;, 2); attrs.put(&quot;name&quot;, &quot;小王&quot;); session.selectList(&quot;getPersonInfosByMap&quot;, attrs); 注解@Param接收(重点)1234567891011121314 /** * 根据用户唯一id查询信息 * @param id * @return */ Person getPersonInfo(@Param(&quot;pid&quot;) int id); //---------------动作实现&lt;select id=&quot;getPersonInfo&quot; resultType=&quot;com.wwj.model.Person&quot;&gt; select * from person where id = #&#123;pid&#125;&lt;/select&gt;//---------调用测试session.selectOne(&quot;getPersonInfo&quot;, 2); mybatis立即返回主键值应用场景:当我们需要在当前事务插入数据后立即获取数据的主键id，做下一步额外操作，并且不因为并发高的情况下取错值而考虑 修改代码如下 123456789101112131415 &lt;insert id=&quot;savePerson&quot; parameterType=&quot;com.wwj.model.Person&quot;&gt; &lt;selectKey keyProperty=&quot;id&quot; resultType=&quot;int&quot; order=&quot;AFTER&quot;&gt; select last_insert_id() &lt;/selectKey&gt; insert into person(name,address,bir) values(#&#123;name&#125;,#&#123;address&#125;,#&#123;bir&#125;);&lt;/insert&gt;//------------------------------------------------------------ // 操作数据 Person p = new Person(); p.setName(&quot;小小王&quot;); p.setBir(parse); int result = session.insert(&quot;savePerson&quot;, p); System.out.println(result); System.out.println(p.getId()); keyProperty=”返回主键的id的属性名” resultType=”主键类型” order=””什么时候执行，在SQL执行前还是执行后执行，两个取值：BEFORE和AFTER select last_insert_id()取到最后生成的主键，只在当前事务中取 sql代码段如果场景中有大量的重复的公共sql语句,那么可以考虑使用&lt;sql&gt;声明公共的部分 示例如下: 123456789101112131415161718 /** * sql片段 * @param id 根据用户的id查询姓名 * @return */ String getPersonName(@Param(&quot;pid&quot;) int id); //--------动作实现 &lt;sql id=&quot;nameCol&quot;&gt; name&lt;/sql&gt;&lt;select id=&quot;getPersonName&quot; resultType=&quot;java.lang.String&quot;&gt; select &lt;include refid=&quot;nameCol&quot;&gt;&lt;/include&gt; from person where id = #&#123;pid&#125;&lt;/select&gt;//--------测试调用 String name = session.selectOne(&quot;getPersonName&quot;,2); System.out.println(name); 自定义结果类型ResultMap(开发中长期使用)应用场景:假设我们的实际开发过程中,数据表组合字段多,又不想关心配置映射关系,只想关心sql语句,以及结果,并且也关心sql语句的效率 假设2张表 person和card 1:m关系 连接查询需要person中的人名和card表中的卡号名字 操作步骤如下: 在任意自定对象上添加属性 12345678910111213141516171819202122232425262728293031323334//----- 实体类public class Card &#123; private String cname; &#125;public class Person implements Serializable &#123; private Integer id; private String name; private Date bir; private String address; private List&lt;Card&gt; cards; &#125;//----构建自定义的resultmap封装 注意 collection(集合)association(联系) &lt;resultMap type=&quot;com.wwj.model.Person&quot; id=&quot;personRS&quot;&gt; &lt;!--column指向数据库列名 property指向pojo对象中字段名 --&gt; &lt;result column=&quot;name&quot; property=&quot;name&quot; /&gt; &lt;!-- property指的是在bean中字段名 ofType类的全定向名 --&gt; &lt;collection property=&quot;cards&quot; ofType=&quot;com.wwj.model.Card&quot;&gt; &lt;result column=&quot;cname&quot; property=&quot;cname&quot; /&gt; &lt;/collection&gt; &lt;/resultMap&gt;//--------映射的动作实现 &lt;select id=&quot;getPersonsOfCard&quot; resultMap=&quot;personRS&quot;&gt; select person.name,card.cname from person INNER JOIN card on person.id = card.pid &lt;/select&gt;//--------代码操作 List&lt;Person&gt; persons = session.selectList(&quot;getPersonsOfCard&quot;); for (Person person : persons) &#123; System.out.println(person.getCards().get(0).getCname()); System.out.println(person.getCards().get(1).getCname()); &#125; 注意1:po代表和数据库一一对照的数据模型.vo代表业务逻辑和表现层之间需要的数据 注意2:如果需要暴露一部分数据出去的,可能还是会单独做接口和设计VO]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>数据持久化</tag>
        <tag>orm</tag>
        <tag>半自动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx使用]]></title>
    <url>%2F2019%2F08%2F23%2F2019-09-10-Nginx%2F</url>
    <content type="text"><![CDATA[Nginx是一个非常优秀的服务器,它的魅力不仅是负载均衡,动静分离等等. Nginx使用 Nginx 简介 Nginx 安装与配置 部署 Nginx+Tomcat集群负载均衡 Nginx+Tomcat 动静分离 Nginx 负载均衡策略 Nginx 简介Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务 正向代理:客户端是清楚目标服务器的地址的，而目标服务器是不清楚来自客户端，它只知道来自哪个代理服务器，所以正向代理可以屏蔽或隐藏客户端的信息. 反向代理:客户端发来请求，先由反向代理服务器，然后按一定的规则分发到明确的服务器，而客户端不知道是哪台服务器。常常用nginx来作反向代理 Nginx安装和配置 1.安装需要的依赖 yum install gcc-c++ yum -y install pcre* yum -y install openssl* 2.下载nginx与解压到指定目录 wget http://nginx.org/download/nginx-1.9.9.tar.gz tar -zxvf nginx-1.9.9.tar.gz -C /root/nginx 3.进入nginx目录设置安装目录 ./configure --prefix=/root/nginx 执行make 执行make install 4.启动nginx服务(在安装目录下的Sbin目录下) 执行./nginx 执行 ps -ef | grep nginx 查看工作进程 常见的命令./nginx -s stop/reload/quit 注意:如果访问报403错误.更改nginx.conf文件设置用户保持与当前一致 最终结果: 部署 Nginx+Tomcat集群与负载均衡 1.安装2个tomcat并修改端口号 (10088和10089) 2.在2个tomcat的root文件下放入index.jsp 123456789101112&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;%@ page isELIgnored =&quot;false&quot; %&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Tomcat 10089&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 3.配置下nginx 1234567891011upstream wwj &#123; server 144.202.3.120:10088 weight=1; server 144.202.3.120:10089 weight=2; &#125; location / &#123; # root html; # index index.html index.htm; proxy_pass http://wwj; proxy_redirect default; &#125; 4.依次启动tomcat以及nginx进行操作 Nginx+Tomcat 动静分离将一些常用的静态资源存放到nginx服务中,减轻tomcat本身的压力 1.先将一张图片1.jpg传入到ngnix的static目录下(/root/nginx/static） scp /Users/Yun/Desktop/1.jpg root@144.202.3.120:/root/nginx/static 配置nginx配置文件拦截静态资源 123location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|js|css)$ &#123; root /root/nginx/static; &#125; 在tomcat的jsp中加入&lt;img src=&quot;1.jpg&quot; alt=&quot;wwj&quot;/&gt; 结果如下: Nginx 负载均衡策略1.weight轮询（默认）：接收到的请求按照顺序逐一分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值（weight），用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。 2.ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。 3.least_conn: 把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同;但是有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，least_conn这种方式就可以达到更好的负载均衡效。 4.fair：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是Nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块。 5.url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装nginx的hash软件包。 配置在上游服务器设置中]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>服务器</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis2]]></title>
    <url>%2F2019%2F08%2F20%2F2019-09-10-Redis(%E4%BB%BD)%2F</url>
    <content type="text"><![CDATA[Redis是一个很棒的产品,单线程,高读写是它的核心 spring整合redis Spring使用原生redisTemplate(数据一致性要求不高) Spring基于注解整合Redis实现内容缓存(要求一致性高) 统一配置项目pom.xml文件(在整合项目dao层) 1.添加redis依赖版本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;small&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;small-dao&lt;/artifactId&gt; &lt;properties&gt; &lt;!--jar包版本 --&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;mybatis-spring.version&gt;1.3.1&lt;/mybatis-spring.version&gt; &lt;pagehelper.version&gt;4.1.4&lt;/pagehelper.version&gt; &lt;mysql-connector.version&gt;5.1.41&lt;/mysql-connector.version&gt; &lt;c3p0&gt;0.9.5.3&lt;/c3p0&gt; &lt;spring-redis&gt;1.6.0.RELEASE&lt;/spring-redis&gt; &lt;jredis-version&gt;2.7.3&lt;/jredis-version&gt; &lt;!--编译级别 --&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- mybatis核心包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis集成spring包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mysql数据库链接jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql-connector.version&#125;&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- mybatis分页插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;$&#123;pagehelper.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- c3p0 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;$&#123;c3p0&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--Spring redis 缓存 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-redis&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--redis 客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;$&#123;jredis-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.添加redis配置文件 1234567891011# Redis settings redis.host=144.202.3.120redis.port=6379 redis.pass=redisredis.dbIndex=0 redis.expiration=3000 redis.maxIdle=300 redis.maxActive=600 redis.maxWait=1000# check data 有效性redis.testOnBorrow=true 3.在web层添加utils 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.wwj.utils;import java.lang.reflect.Method;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.cache.annotation.EnableCaching;import org.springframework.cache.interceptor.KeyGenerator;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;/** * 重写的generate（）方法为数据存入缓存的无参的方法指定存入缓存中的数据的key * @author Yun * */@Configuration@EnableCachingpublic class RedisCacheConfig extends CachingConfigurerSupport &#123; private volatile JedisConnectionFactory jedisConnectionFactory; private volatile RedisTemplate&lt;String, String&gt; redisTemplate; private volatile RedisCacheManager redisCacheManager; public RedisCacheConfig() &#123; super(); &#125; /** * 带参数的构造方法 初始化所有的成员变量 * * @param jedisConnectionFactory * @param redisTemplate * @param redisCacheManager */ public RedisCacheConfig(JedisConnectionFactory jedisConnectionFactory, RedisTemplate&lt;String, String&gt; redisTemplate, RedisCacheManager redisCacheManager) &#123; this.jedisConnectionFactory = jedisConnectionFactory; this.redisTemplate = redisTemplate; this.redisCacheManager = redisCacheManager; &#125; public JedisConnectionFactory getJedisConnecionFactory() &#123; return jedisConnectionFactory; &#125; public RedisTemplate&lt;String, String&gt; getRedisTemplate() &#123; return redisTemplate; &#125; public RedisCacheManager getRedisCacheManager() &#123; return redisCacheManager; &#125; @Bean public KeyGenerator keyGenerator() &#123; return new KeyGenerator() &#123; @Override public Object generate(Object target, Method method, Object... objects) &#123; StringBuilder sb = new StringBuilder(); //sb.append(target.getClass().getName()); sb.append(method.getName()); if(objects.length != 0)&#123; sb.append(&quot;_&quot;); for (Object obj : objects) &#123; sb.append(obj.toString()); &#125; &#125; return sb.toString(); &#125; &#125;; &#125;&#125; 4.在容器中配置redis实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!-- 自动扫描 --&gt; &lt;context:component-scan base-package=&quot;com.wwj&quot;/&gt; &lt;!-- 引入配置文件 --&gt; &lt;bean id=&quot;propertyConfigurer&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:jdbc.properties&lt;/value&gt; &lt;value&gt;classpath:redis.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置c3p0数据源 --&gt; &lt;bean class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot; id=&quot;dataSource&quot;&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- spring和MyBatis整合 --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!--mybatis分页插件--&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:spring/mybatis-config.xml&quot;&gt;&lt;/property&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:Mapper/*.xml&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.wwj.mapper&quot;/&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;!--支持事务注解的（@Transactional）--&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; &lt;!-- redis config start --&gt; &lt;!-- 配置JedisPoolConfig实例 --&gt; &lt;bean id=&quot;poolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;$&#123;redis.maxIdle&#125;&quot; /&gt; &lt;property name=&quot;maxTotal&quot; value=&quot;$&#123;redis.maxActive&#125;&quot; /&gt; &lt;property name=&quot;maxWaitMillis&quot; value=&quot;$&#123;redis.maxWait&#125;&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;redis.testOnBorrow&#125;&quot; /&gt; &lt;/bean&gt; &lt;!-- 配置JedisConnectionFactory --&gt; &lt;bean id=&quot;jedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt; &lt;property name=&quot;hostName&quot; value=&quot;$&#123;redis.host&#125;&quot; /&gt; &lt;property name=&quot;port&quot; value=&quot;$&#123;redis.port&#125;&quot; /&gt; &lt;!-- &lt;property name=&quot;password&quot; value=&quot;$&#123;redis.pass&#125;&quot; /&gt; --&gt; &lt;property name=&quot;database&quot; value=&quot;$&#123;redis.dbIndex&#125;&quot; /&gt; &lt;property name=&quot;poolConfig&quot; ref=&quot;poolConfig&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;stringRedisSerializer&quot; class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot;/&gt; &lt;!-- 配置RedisTemplate --&gt; &lt;bean id=&quot;redisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot; /&gt; &lt;property name=&quot;hashKeySerializer&quot; ref=&quot;stringRedisSerializer&quot;/&gt; &lt;property name=&quot;keySerializer&quot; ref=&quot;stringRedisSerializer&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置RedisCacheManager --&gt; &lt;bean id=&quot;redisCacheManager&quot; class=&quot;org.springframework.data.redis.cache.RedisCacheManager&quot;&gt; &lt;constructor-arg name=&quot;redisOperations&quot; ref=&quot;redisTemplate&quot; /&gt; &lt;property name=&quot;defaultExpiration&quot; value=&quot;$&#123;redis.expiration&#125;&quot; /&gt; &lt;!-- 可选配置缓存区间 &lt;property name=&quot;cacheNames&quot;&gt; &lt;list&gt; &lt;value&gt;xxx&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; --&gt; &lt;/bean&gt; &lt;!-- 配置RedisCacheConfig --&gt;&lt;bean id=&quot;redisCacheConfig&quot; class=&quot;com.wwj.utils.RedisCacheConfig&quot;&gt; &lt;constructor-arg ref=&quot;jedisConnectionFactory&quot;/&gt; &lt;constructor-arg ref=&quot;redisTemplate&quot;/&gt; &lt;constructor-arg ref=&quot;redisCacheManager&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 注解含义 @Cacheable：表明在进入方法之前，Spring会先去缓存服务器中查找对应key的缓存值，如果找到缓存值，那么Spring将不会再调用方法，而是将缓存值独处，返回给调用者；如果没有找到缓存值，那么Spring就会执行你的方法，将最后的结果通过key保存到缓存服务器中。 @CachePut：表明Spring会将该方法返回的值缓存到缓存服务器中，这里需要注意的是，Spring不会事先去缓存服务器中查找，而是直接执行方法，然后缓存。换句话说，该方法始终会被Spring所调用。 @CacheEvict：表示执行方法后从缓存服务器移除对应key的值； 加深理解123456789@Cacheable(value=&quot;xxx&quot; key=&quot;zzz&quot;)注解：标注该方法查询的结果进入缓存，再次访问时直接读取缓存中的数据1.对于有参数的方法，指定value(缓存区间)和key(缓存的key)；对于无参数的方法，只需指定value,存到数据库中数据的key通过重写的generate()方法生成。2.调用该注解标识的方法时，会根据value和key去redis缓存中查找数据，如果查找不到，则去数据库中查找，然后将查找到的数据存放入redis缓存中；3.向redis中填充的数据分为两部分： 1).用来记录xxx缓存区间中的缓存数据的key的xxx~keys(zset类型) 2).缓存的数据，key：数据的key；value：序列化后的从数据库中得到的数据4.第一次执行@Cacheable注解标识的方法，会在redis中新增上面两条数据5.非第一次执行@Cacheable注解标识的方法，若未从redis中查找到数据，则执行从数据库中查询 1234* @CacheEvict()注解:移除指定缓存区间的一个或者多个缓存对象 * @param value + key 或者 value + allEntries=true * 1.value + key 移除value缓存区间内的键为key的数据 * 2.value + allEntries=true 移除value缓存区间内的所有数据 代码操作示例(数据一致性不高) 1.建一张用户表模拟数据以及封装的resultmap对应的vo对象(需要被序列化) 2.构建服务层以及dao层和controller层 1234567891011121314151617181920212223242526272829303132333435363738394041package com.wwj.controller;import java.util.concurrent.TimeUnit;import javax.annotation.Resource;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import com.wwj.service.RedisService;@Controllerpublic class RedisController &#123; @Autowired private RedisService redisService; @Resource private RedisTemplate redisTemplate; @RequestMapping(&quot;/selectRedis1&quot;) @ResponseBody public String selectRedis1()&#123; String personCount = null; personCount= (String) redisTemplate.opsForValue().get(&quot;person_count&quot;); if(personCount == null)&#123; //redis缓存中无数据，从数据库中查询，并放入redis缓存中，设置生存时间为1小时 personCount = Integer.toString(redisService.getPersonCount()); redisTemplate.opsForValue().set(&quot;person_count&quot;, personCount, 1, TimeUnit.HOURS); &#125; else &#123; System.out.println(&quot;从redis拿取数据&quot;); personCount= (String) redisTemplate.opsForValue().get(&quot;person_count&quot;); &#125; return personCount; &#125;&#125; 代码操作示例(数据一致性高)以及增加或者删除修改数据后清空缓存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.wwj.service.impl;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cache.annotation.CacheEvict;import org.springframework.cache.annotation.Cacheable;import org.springframework.stereotype.Service;import com.wwj.mapper.PersonMapper;import com.wwj.model.Person;import com.wwj.service.RedisService;@Service(&quot;redisService&quot;)public class RedisServiceImpl implements RedisService&#123; @Autowired private PersonMapper personMapper; @Override public Integer getPersonCount() &#123; // TODO Auto-generated method stub return personMapper.selectCountOfPerson(); &#125; @Cacheable(value=&quot;getPersons&quot;) @Override public List&lt;Person&gt; getPersons() &#123; // TODO Auto-generated method stub return personMapper.selectPersons(); &#125; @Cacheable(value=&quot;getPersonById&quot;,key=&quot;&apos;getPersonById_&apos;+#id&quot;) @Override public Person getPersonById(Integer id) &#123; // TODO Auto-generated method stub return personMapper.selectPersonById(id); &#125; @CacheEvict(value=&quot;getPersons&quot;,allEntries=true) @Override public int savePerson(String name) &#123; // TODO Auto-generated method stub return personMapper.insertPerson(name); &#125;&#125; 代码地址详见 SSM整合]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据持久化</tag>
        <tag>分关系型数据库</tag>
        <tag>内存型数据库</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis1]]></title>
    <url>%2F2019%2F08%2F17%2F2019-09-10-Redis(%E7%BC%98)%2F</url>
    <content type="text"><![CDATA[Redis是一个很棒的产品,单线程,高读写是它的核心 redis数据库初识 Redis 简介 Redis 的安装配置 Redis 的常见操作 Redis 的数据类型 Redis 的事务控制 Java 操作 Redis 数据库 Redis简介redis的作用Redis:REmote DIctionary Server( 远程字典服务器 ) 是完全开源免费的，用 C 语言编写的，遵守 BSD协议，是一个高性能的 (key/value) 分布式内存数据库，基于内存运行并支持持久化的 NoSQL 数据库，是当前最热门的 NoSql 数据库之一 , 也被人们称为数据结构服务器 BSD协议简单的说就是开源自由最大化,不以商业为中心 redis的优缺点优点 性能极高 – Redis能支持超过 100K+ 每秒的读写频率。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 缺点 是数据库容量受到物理内存的限制,不能用作海量数据的高性能读写,因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis 的安装(Linux下) 1.下载wget -P /root/softdev http://download.redis.io/releases/redis-5.0.5.tar.gz 2.解压tar zxvf redis-5.0.5.tar.gz -C /root/redis 3.安装C语言环境yum install gcc-c++ 4.切换到redis安装目录下.执行make命令 5.配置目录下的redis.conf文件.主要的目的 允许其他地址访问 关闭保护模式 设置密码 6.切换到目录下进行启动src/redis-server redis.conf 可检查是否存在ps -ef |grep redis 可视化工具下载 Redis 的常见操作 Keys *：指令 查看当前这个库中所有的key值 exists key 名字 : 判断某个 key 值是否存在 0 表示不存在 1 表示存在 move key 名字 数据库的索引下标： 将某个值移除到指定的库中 Redis 默认有 16 个库，我们可以通过修改 redis 配置文件 redis.conf 来改变库的数量 select 下标可以切换不同的数据库： select 下标 1234567(了解)flushdb : 删除当前库中所有的 keyflushall : 删除所有库的信息Info：查看数据库的信息expire key 名字 秒：设定指定的 key 的存活时间ttl key 名字 : 查看当前的 key 还有多少存活时间 -1 表示永不过期，-2 表示已经过期type key 名字 : 查看当前 key 的类型（key String,Object） Redis的数据类型String类型1234567891011121314151617SET key 名字 value 值： 设置单一键值对 (key 值相同会覆盖原来的值 , 类似于map 集合 )GET key 名字：获取指定 key 的值DEL key 名字：删除指定名称 keyAPPEND key 名字 新值：在原有的值的基础上添加新的值STRLEN key 名字 : 获取字符串的长度(value 值必须是数字 )INCR(value 值自动加 1) ： incr key名字；DECR(value 值自动减 1) ：decr key名字；INCRBY 递增值： incrby key名字 数字；DECRBY 递减值：decrby key名字 数字 ;GETRANGE : GETRANGE key start end： 获取 value 值的一部分SETRANGE ：SETRANGE key 起始位置 值： 从起始位置开始替换值SETEX: SETEX key 名字 存活时间 值： 设定一组值同时设定存活时间；SETNX: SETNX key 名字 值： 设置永久存活的一组值。 (key 值冲突无法存入值 -- 返回值为 0)MSET: mset key 值 key 值 .... 一次设定多组值，如果 key 值存在也会覆盖MGET: mget key key 一次获取多个 key 的值MSETNX: 一次设定多组 key 值，如果有 key 值存在无法添加完成 List类型12345678LPUSH: 向集合中添加内容 lpush 集合的名字 值 显示的顺序和添加的顺序相反。RPUSH: 向集合中添加内容 rpush 集合的名字 值 添加顺序就是显示顺序LRANGE: 集合的名字 起始位置 结束位置 (-1 代表到集合的末尾 )LLEN: llen 集合的名字 查看集合的长度LPOP: lpop 集合的名称 移除集合中的第一个元素RPOP: rop 集合的名称移除集合中的最后一个元素LINDEX : 获取制定索引的值 lindex 集合的名称 索引数值LREM : 删除指定数量的值： lrem 集合的名称 个数 值 ( 集合中有重复值 )； hash类型(hash表的基本操作与string一样.特别适合存储对象数据)12345678910111213HSET: 存放一组键值对 hset key 值的名称 具体的值；（重复添加会覆盖原来的值）HGET：获取一个值： hget key 值的名称HMSET： 设定多组键值对 HMSET customer id 1 name zs address beijingHMGET： 获取过个键对应的值 hmget customer id name addressHGETALL： 获取所有的数据 hgetall key 值；HDEL: 删除某个指定的 key 的一组 value hdel customer idHLEN: 当前的 key 有几组对应的键值对HEXISTS: 判断当前 key 中是否有指定名称的键值对： hexists customer id;HKEYS：获取所有的 keyHVALS: 获取所有的值HINCRBY: 增加指定步长的数据 hincrby customer age 2;HINCRBYFLOAT: 在原有的基础上增加指定的小数。 hincrbyfloat customer course 0.5HSETNX： 如果 value 中的 key 重复不能添加到集合中。 set类型(无序不重复)123456789SADD：添加值 sadd 集合名称 值 ....SMEMBERS：查看值 smembers 集合名称SCARD : 集合中元素个数 scard 集合名称SREM : 删除集合中的某个值 srem 集合名称 值；SPOP： 随机从集合中移除一个数据 spop 集合名称SMOVE: 将集合中的某个值赋给另外一个集合： SMOVE 集合 1 集合 2 值；SDIFF: 差集SINTER: 交集SUNION: 并集 Zset类型(是 string 类型的有序集合，也不可重复)1234567891011sorted set 中的每个元素都需要指定一个分数，根据分数对元素进行升序排序，如果多个元素有相同的分数，则以字典序进行升序排序Zadd：创建集合并设定标准 zadd zset01 60 v1 70 v2 80 v3 90 v4 100 v5（等级划分的数据）ZRANGE: 查询所有的标准 ZRANGE zset01 0 -1 , ZRANGE zset01 0 -1 withscoresZRANGEBYSCORE : 根据分数查询内容ZRANGEBYSCORE zset01 60 90 ( 注意如果前面添加”(” 表示不包含节点的意思 )withscores limit 起始位置 数量 .ZREM : 删除元素 zrem 集合 某 score 下对应的 value 值。ZREM zset01 v5ZCARD: 统计有几个键值对 zcard 集合ZCOUNT: zcount 集合 数值 1 数值 2 统计区间的值ZRANK : 统计对应的下标 zrank 集合名 valuesZSCORE : zscore 集合名 values 获取对应的分数 1234567891011redis 127.0.0.1:6379&gt; ZADD runoobkey 1 redis(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 2 mongodb(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 3 mysql(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 3 mysql(integer) 0redis 127.0.0.1:6379&gt; ZADD runoobkey 4 mysql(integer) 0redis 127.0.0.1:6379&gt; ZRANGE runoobkey 0 10 WITHSCORES 5.redis的事务规则 批量操作在发送 EXEC 命令前被放入队列缓存。 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。 123456789redis 127.0.0.1:7000&gt; multiOKredis 127.0.0.1:7000&gt; set a aaaQUEUEDredis 127.0.0.1:7000&gt; set b bbbQUEUEDredis 127.0.0.1:7000&gt; set c cccQUEUEDredis 127.0.0.1:7000&gt; exec maven项目下使用java操作redis数据库1.创建一个简单的maven项目pom.xml如下 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.使用jredis模板 123456789101112131415161718192021222324252627282930313233343536package com.wwj.test;import org.junit.Test;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;public class TestRedis &#123; @Test public void testJedis() &#123; // 创建一个 Jedis 的连接 Jedis jedis = new Jedis(&quot;144.202.3.120&quot;, 6379); // 密码认证 如果设置了密码，就需要进行认证 jedis.auth(&quot;redis&quot;); // 执行 redis 命令 jedis.set(&quot;mytest&quot;, &quot;hello world, this is jedis client!&quot;);&#125; @Test public void testJedisPool() &#123; // 创建一连接池对象 JedisPool jedisPool = new JedisPool(&quot;144.202.3.120&quot;, 6379); // 从连接池中获得连接 Jedis jedis = jedisPool.getResource(); // 密码认证 如果设置了密码，就需要进行认证 jedis.auth(&quot;redis&quot;); String result = jedis.get(&quot;mytest&quot;); System.out.println(result); // 关闭连接 jedis.close(); // 关闭连接池 jedisPool.close(); &#125; &#125; redis练习操作分布式锁参考文章]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据持久化</tag>
        <tag>分关系型数据库</tag>
        <tag>内存型数据库</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统使用]]></title>
    <url>%2F2019%2F08%2F09%2F2019-09-10-Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Linux操作系统是一个开源的命令行系统,没有消息就是一个好的消息 Linux操作系统 Linux 操作系统简介 VM 虚拟机和 linux 操作系统安装 Linux 的目录结构解析 Linux 的常用指令 Vim 文本编辑器使用 Linux 用户和组的管理 Linux 中的文件权限 Linux 操作系统安装 Jdk Linux 操作系统下 Tomcat 的安装 Linux 操作系统安装 Mysql Linux 系统下 Shell 脚本的编写和运行 Linux操作系统 开源,安全,使用的时候,最好全部使用命令的方式进行操作 VM 虚拟机和 linux 操作系统安装 安装可在虚拟机或者开一个远程服务器 Linux目录结构解析(服务器系统centos6-64位) 目录是一个树形结构,会有一个根(/) 切换到根目录。 /bin存放的二进制可执行文件(ls,cat,mkdir等)，常用命令一般都在这里 /etc存放系统管理和配置文件 （比较重要） /home 存放所有用户文件的根目录 (不含root) /root单独的root,可以看到里面root用户下的文件 /usr 用于存放系统应用程序，比较重要的目录/usr/local 本地系统管理员软件安装目录（安装系统级的应用） /tmp 用于存放各种临时文件，是公用的临时文件存储点。 /var 各种服务的日志文件(当然,一般项目中,我们都是自己有一个固定的地方存放日志文件) 最终形成的目录结构如下: Linux常用命令一些常用的命令 pwd 查看当前所在的目录 cd (change dic)更换目录 ls 查看目录 -f(查看当前目录下的文件,含隐藏文件) -l(查看文件和目录详细) cat 查看文件 cat 文件名(全路径) mkdir 创建文件目录 rm -rf 目录名字 touch创建一个文件或者使用vim直接进行创建 注意:未安装vim可以使用yum install vim echo代表输入命令(echo ‘内容’ &gt; 文件名),如不想覆盖则用&gt;&gt; 删除文件rm -f 文件名 (Mv 文件名 新文件名)可以给文件重命名(Mv 文件名 一个有效的文件目录)可以将某个文件移动到指定目录中 cp复制命令 cp dir/* . 复制一个目录下的所有文件到当前工作目录 cp -a /tmp/dir1 路径 复制一个目录到当前工作目录 cp -a file1 file2 # 连同文件的所有特性把文件 file1 复制成文件 file2 cp file1 file2 file3 dir # 把文件 file1、file2、file3 复制到目录 dir 中 find命令查找命令 find 指令 基本格式：语法： find [ 查找文件的路径 ] [ 查找条件 ] [ 处理动作 ] grep 文件内容查找(了解) 关机重启(shutdown 和 reboot) su -root 指令切换到管理员 注意引号内为正则表达式即可 zip解压缩 压缩zip -r archive_name.zip filename 解压在当前 unzip archive_name.zip 解压到指定 unzip archive_name.zip -d new_dir tar打包 打包一个目录(含文件)tar -cvf archive_name.tar directory_to_compress 解包tar -zxvf archive_name.tar.gz 解包到指定目录tar -xvf archive_name.tar -C new_dir tar.gz格式压缩 压缩tar -zcvf archive_name.tar.gz filename 解压缩 tar -zxvf archive_name.tar.gz 解压缩到指定 tar -zxvf archive_name.tar.gz -C new_dir 使用vim编辑器 注意 进入之后按i或者a即可根据光标位置进行操作 按esc切换到命令模式:可以设置行号 :set nu 也可以用/需要查找的内容 是n或者N查看下一个或者上一个 :wq或者:w 强制写入或者写入 :q 或者 :q! 退出或者强制退出 Linux 用户和组的管理 Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。每个用户账号都拥有一个唯一的用户名和各自的口令。 通过cat /etc/passwd 分别代表用户名,密码,用户ID,组ID,用户全称,用户目录,用户使用的shell 1.添加用户 和 删除用户 删除用户userdel -r -f wangweijie userdel -r 用户名 删除用户以及下面所有的目录 2.用户组添加管理 需要移除用户的话 gpasswd -d 用户账户 用户组名 Linux中文件权限 10个字符 第一个文件类型 后面每3个一组 (r=4， w=2， x=1) 然后是用户,用户组,大小 每一组权限分别对应当前用户,用户组,非该用户组 更改abc.txt 当前用户为可读 linux安装jdk 1.现在root下构建一个专门存放jdk和tomcat的等一系列的软件目录 softdev 2.上传安装包到softdev中 scp /path/local_filename username@servername:/path 3.如果是从服务器下载则scp username@servername:/path/filename /tmp/local_destinationr 4.也可以考虑使用 yum install -y lrzsz （使用rz上传或则sz下载） 5.执行解压的命令 tar -zxvf jdk-8u162-linux-x64.tar.gz -C /root/java8/ 6.配置在全局环境变量中（执行 source /etc/profile） 123export JAVA_HOME=/root/java8/jdk1.8.0_162export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar linux下安装tomcat 1.分别新建2个文件夹存放tomcat （tomcat1和tomcat2） 2.tar -zxvf apache-tomcat-8.5.43.tar.gz -C /root/tomcat1 3.修改2个tomcat的端口号 10088和10089(文件位于/root/tomcat1/apache-tomcat-8.5.43/conf) 4.开启：service iptables start 关闭：service iptables stop(防火墙)service iptables status 5.在bin目录下启动tomact(./startup.sh) linux下安装 Mysql 1.yum list installed | grep mysql查看是否安装mysql 2.yum -y remove mysql (删除已安装的mysql) 3.下载小容量mysql(wget http://repo.mysql.com/mysql-community-release-el6-5.noarch.rpm) 4.rpm -ivh mysql-community-release-el6-5.noarch.rpm(类似解压出安装文件可通过yum repolist all | grep mysql) 5.yum install mysql-community-server 安装 6.service mysqld start 启动 关闭service mysqld stop 12345# mysql -u root# use mysql;# update user set password=PASSWORD(&quot;这里输入root用户密码&quot;) where User=&apos;root&apos;;# GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION; # flush privileges; linux下的 Shell 脚本的编写和运行 1.touch HelloWorld.sh 123#!/bin/bashecho Hello World! 1.1 #!/bin/bash #!是代表这是一个解释程序 /bin/bash是bash的绝对路径。 2.bash HelloWrold.sh]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>命令行操作系统</tag>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle2]]></title>
    <url>%2F2019%2F08%2F02%2F2019-09-10-Oracle(%E4%BB%BD)%2F</url>
    <content type="text"><![CDATA[Oracle数据库也是一个数据库的中间力量 oracle数据库操作 Oracle 常用数据类型 Oracle 中常用的操作符 Oracle 常用函数 Oracle 中的序列 和 Oracle 中的查询 Oracle 中的视图 Oracle 中的触发器 Oracle 中的存储过程 oracle常用的数据类型分为字符型,数字类型,日期,blob 字符类型VARCHAR2 (n)：可变长度的字符,最大长度4000bytes,即1&lt;=n&lt;=4000,VARCHAR2(10)，表示占10个字节的字符串，当长度小于10字节时,不会自动补空格,占实际大小,大于则报错 数字类型NUMBER(P,S):P为整数位+S小数位数.例如NUMBER(5,3),表示整数位数为2,小数位数为3的数字,如25.112 日期类型data缺省格式为DD-MON-YY,timestamp同样,精确到纳秒 LOB类型BLOB：二进制数据,最大长度4G. CLOB:字符数据,最大长度4G，一般音视频类就BLOB,文献就CLOB oracle常用的操作符比较操作符 =、!=、&lt;、&gt;、&lt;=、&gt;=、BETWEEN AND （检查是否在两个值之间） [NOT] IN（与列表中的值匹配） [NOT] LIKE（匹配字符模式， * _ 通配符） [NOT] IS NULL（检查是否为空） 逻辑操作符 and or not 如果and和or混用,and的优先级高于or,所以尽量的使用括号来表明优先级 集合操作符 UNION（联合） 返回两个查询选定不重复的行。( 删除重复的行 ) UNION ALL（联合所有） 合并两个查询选定的所有行，包括重复的行。 INTERSECT（交集） 只返回两个查询都有的行。 MINUS（减集） 在第一个查询结果中排除第二个查询结果中出现的行。 （第一 – 第二） 注意:使用集合操作符的时候列的数量和数据类型,都要保持一致 连接操作符 使用||进行连接,返回字符串 SELECT (&#39;wwj&#39; || &#39;hello&#39;) as str1 FROM dual oracle常用的函数字符串函数 (subsrt 和 replace 和 decode) SELECT SUBSTR(ch, pos, length) as str1 FROM dual pos代表等于0或1时,都是从第一位开始截取 length代表要截取的字符串的长度 如果pos填写为负数,为倒着截取 SELECT REPLACE(&#39;wwj&#39;,&#39;j&#39;,&#39;q&#39;) as str1 FROM dual 将字符串中包含j的替换成q decode(条件,值1,返回值1,值2,返回值2) 等同于 if elseif 数学函数 (round 和 trunc ) SELECT ROUND(n, int) as num1 FROM dual int位置代表保留几位小数,并且四舍五入 SELECT TRUNC(n1, n2) as num1 FROM dual n2代表保留几位小数,并不四舍五入 转换函数(tochar 和 todate) SELECT to_char(SYSDATE,&#39;Day, HH12:MI:SS&#39;) FROM dual; SELECT TO_CHAR(99,&#39;$99.9999&#39;) FROM dual; SELECT to_date(&#39;2089-5-7 17:09:37&#39;,&#39;yyyy-mm-dd HH24:MI:SS&#39;) from dual 其它函数 nal(expr1,expr2)代表 oracle第一个参数为空那么显示第二个参数的值，如果第一个参数的值不为空，则显示第一个参数本来的值。 比如:select ename,NVL(comm, -1) from emp; 如何comm没值,则取-1 Oracle 中的序列 和 Oracle 中的查询 mysql数据中提供了数据库自增的选项,但是oracle中没有提供,只有利用序列实现主键自增的功能 sequence 就是序号,也可以说是序列 序列创建的语法创建1234567891011CREATE SEQUENCE seq1INCREMENT BY 1 -- 每次加几个START WITH 1 -- 从1开始计数NOMAXvalue -- 不设置最大值NOCYCLE -- 一直累加,不循环CACHE 10; --设置缓存cache个序列，如果系统down掉了或者其它情况将会导致序列不连续，也可以设置为---------NOCACHE 查看与操作序列信息 select * from user_sequences; Select * from all_sequences; 使用序列名.CurrVal：返回 sequence的当前值 使用序列名.NextVal：增加sequence的值，然后返回 增加后sequence值 select seq1.currval from dual 重新初始化seq的序号(可以使用修改) alter sequence seq1 increment by 1 删除seq drop sequence seq1 数据模拟 emp 员工表（empno 员工号/ename 员工姓名/job 工作/mgr 上级编号/hiredate 受雇日期/sal 薪金/comm 佣金/deptno 部门编号） dept 部门表（deptno 部门编号/dname 部门名称/loc 地点） 创建部门表12345create table dept( deptno number(10) primary key, dname varchar2(30), loc varchar2(30)) 创建员工表1234567891011create table emp( empno number(10) primary key, ename varchar2(30), job varchar2(30), mgr varchar2(30), hiredate number(10), sal number(10), comm number(10), deptno number(10), foreign key(deptno) references dept(deptno)) 模拟数据12345678910111213insert into dept values(seq1.nextval, &apos;技术部&apos; ,&apos;南泥湾&apos;);insert into dept values(seq1.nextval, &apos;SALES&apos; ,&apos;深圳市&apos;);insert into dept values(seq1.nextval, &apos;事业部&apos; ,&apos;北京市&apos;);insert into dept values(seq1.nextval, &apos;服务部&apos; ,&apos;延安&apos;);insert into dept values(seq1.nextval, &apos;生产部&apos; ,&apos;南京市&apos;);insert into dept values(seq1.nextval, &apos;宣传部&apos; ,&apos;上海市&apos;);insert into dept values(seq1.nextval, &apos;打杂部&apos; ,&apos;广州市&apos;);insert into dept values(seq1.nextval, &apos;司令部&apos; ,&apos;重庆市&apos;);insert into dept values(seq1.nextval, &apos;卫生部&apos; ,&apos;长沙市&apos;);insert into dept values(seq1.nextval, &apos;文化部&apos; ,&apos;武冈市&apos;);insert into dept values(seq1.nextval, &apos;娱乐部&apos; ,&apos;纽约&apos;);insert into dept values(seq1.nextval, &apos;管理部&apos; ,&apos;伦敦&apos;);insert into dept values(seq1.nextval, &apos;行政部&apos; ,&apos;天津市&apos;); 123456789INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;1&apos;, &apos;关羽羽&apos;, &apos;CLERK&apos;, &apos;刘备备&apos;, &apos;20011109&apos;, &apos;2000&apos;, &apos;1000&apos;, &apos;3&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;2&apos;, &apos;SMITH&apos;, &apos;CLERK&apos;, &apos;刘备备&apos;, &apos;20120101&apos;, &apos;2000&apos;, &apos;800&apos;, &apos;6&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;3&apos;, &apos;刘备备&apos;, &apos;MANAGER&apos;, &apos;宋祖英&apos;, &apos;20080808&apos;, &apos;9000&apos;, &apos;4000&apos;, &apos;3&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;4&apos;, &apos;TOM&apos;, &apos;ENGINEER&apos;, &apos;Steve&apos;, &apos;20050612&apos;, &apos;3000&apos;, &apos;1000&apos;, &apos;4&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;5&apos;, &apos;Steve&apos;, &apos;MANAGER&apos;, &apos;宋祖英&apos;, &apos;20110323&apos;, &apos;80000&apos;, &apos;9000&apos;, &apos;4&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;6&apos;, &apos;张飞飞&apos;, &apos;CLERK&apos;, &apos;刘备备&apos;, &apos;20101010&apos;, &apos;2000&apos;, &apos;1000&apos;, &apos;3&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;7&apos;, &apos;SCOTT&apos;, &apos;CLERK&apos;, &apos;刘备备&apos;, &apos;20071204&apos;, &apos;2000&apos;, &apos;1000&apos;, &apos;3&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;8&apos;, &apos;宋祖英&apos;, &apos;Boss&apos;, &apos;无&apos;, &apos;20060603&apos;, &apos;2000&apos;, &apos;1000&apos;, &apos;8&apos;);INSERT INTO &quot;EMP&quot;(&quot;EMPNO&quot;, &quot;ENAME&quot;, &quot;JOB&quot;, &quot;MGR&quot;, &quot;HIREDATE&quot;, &quot;SAL&quot;, &quot;COMM&quot;, &quot;DEPTNO&quot;) VALUES (&apos;9&apos;, &apos;曹仁人&apos;, &apos;SALESMAN&apos;, &apos;曹操操&apos;, &apos;20120130&apos;, &apos;2000&apos;, &apos;1000&apos;, &apos;5&apos;); rownum分页SELECT ROWNUM , dept.* FROM dept 123456SELECT * FROM (SELECT ROWNUM , dept.* FROM dept WHERE ROWNUM &lt; endNum)WHERE ROWNUM &gt; startNum 计算起始位置和结束位置startNum = (pageNo - 1) * pageSizeendNum = (pageNo * pageSize) + 1 查询 分组查询使用group by 和 having 进行过滤条件筛选 子查询也就是条件中加入查询语句 连接查询,内连接（利用where或者inner join）,左和右连接(left join 和 right join),自连接(树菜单结构) 数据操作 1.列出至少有一个员工的所有部门。select deptno,dname,loc from dept where deptno in (select deptno from emp); 2.列出薪金比“SMITH”多的所有员工。（大于最大薪水SMITH员工）select empno,ename,sal from emp where emp.sal&gt;(select sal from emp emp1 where emp1.ename = &#39;SMITH&#39;) 3.列出所有员工的姓名及其直接上级的姓名。select a.ename,b.ename from emp a,emp b where a.mgr=b.ename; 4.列出受雇日期早于其直接上级的所有员工。select a.empno, a.ename from emp a, emp b where a.mgr=b.ename and a.hiredate&lt;b.hiredate; 5.列出部门名称和这些部门的员工信息，包括那些没有员工的部门。select dept.dname,emp.* from dept left join emp on dept.deptno = emp.deptno; 6.列出所有job为“CLERK”（办事员）的姓名及其部门名称。select emp.ename,emp.job,dept.dname from emp,dept where emp.job = &#39;CLERK&#39; and emp.deptno = dept.deptno; 7.列出最低薪金大于1500的各种工作。select job from emp group by job having min(sal)&gt;1500; 8.列出在部门“SALES”（销售部）工作的员工的姓名，假定不知道销售部的部门编号。select emp.ename from emp where emp.deptno = (select deptno from dept where dept.dname = &#39;SALES&#39;); 9.列出薪金高于公司平均薪金的所有员工。select * from emp where emp.sal &gt; (select avg(sal) from emp) 10.列出与“SCOTT”从事相同工作的所有员工。select * from emp where emp.job = (select job from emp e where e.ename = &#39;SCOTT&#39;); 11.列出薪金等于部门3中员工的薪金的所有员工的姓名和薪金。select ename,sal from emp where sal in (select sal from emp where deptno=3); 12.列出薪金高于在部门3工作的所有员工的薪金的员工姓名和薪金。select ename,sal from emp where sal &gt; (select max(sal) from emp where deptno=3); 13.列出在每个部门工作的员工数量、平均工资。select deptno,count(empno),avg(sal) from emp group by deptno 14.列出所有员工的姓名、部门名称和工资。select emp.ename as 姓名, dept.dname as 部门, emp.sal+emp.comm as 工资 from emp,dept where dept.deptno = emp.deptno; 15.列出从事同一种工作但属于不同部门的员工的一种组合。select a.ename, b.ename, a.job, b.job, a.deptno, b.deptno from emp a,emp b where a.job=b.job and a.deptno$amp; 16.列出所有部门的详细信息和部门人数。select dept.*,(select count(*) from emp where dept.deptno = emp.deptno) as pop from dept; 17.列出各种工作的最低工资。select job,min((nvl(comm,0)+sal)) from emp group by job 18.列出各个部门的MANAGER（经理）的最低薪金（job为MANAGER）。select emp.deptno, min(sal) from emp,dept where job = &#39;MANAGER&#39; group by emp.deptno 19.列出所有员工的年工资，按年薪从低到高排序。select ename,(nvl(comm,0)+sal)*12 年薪 from emp oracle视图 当某个业务需要多个数据融合在一起展现的时候,可以利用视图 视图只查不改 其实就是一张虚拟表 语法(切换到sys grant CREATE any view to WANGWEIJIE) 123create or replace view v1 (maxsal,minsal,avgsal) As select max(sal),min(sal),avg(sal)from emp oracle触发器订单表和仓库表12345create table sorder( orderNo number(10) primary key, proDuctNo number(10), orderNum number(30)) 1234create table sproduct( pNo number(10) primary key, pNum number(10)) 场景一:新增一个订单的时候,库存表数量减少 :new代表新行 和 :old代表删除和更新 123456CREATE OR REPLACE TRIGGER abc1AFTER INSERT ON SORDERFOR EACH ROWBEGIN UPDATE SPRODUCT SET SPRODUCT.PNUM = SPRODUCT.PNUM-:NEW.ORDERNUM WHERE SPRODUCT.PNO = :NEW.PRODUCTNO;END; 场景二: 删除一个订单 场景三: 修改一个订单 Oracle 中的存储过程 无参数存储过程 123456create or replace procedure p1isbegindbms_output.put_line(&apos; 执行了 &apos;);end p1;call p1() 有参数的存储 12345create or replace procedure p2(newname in varchar2)isbegindbms_output.put_line(&apos; 执行了 &apos;||newname);end p2; 输出参数 123456789101112create or replace procedure p3(newname out varchar2)isbeginselect 5 into newname from dual;end p3;declarenewname number;beginp3(newname);dbms_output.put_line(&apos; 数据库中一共有 &apos;||newname||&apos; 条数据 &apos;);end;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据持久化</tag>
        <tag>关系型数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM]]></title>
    <url>%2F2019%2F07%2F31%2F2019-09-10-SSM%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[整合是一门学问,在于你想用什么技术改变生活 maven分模块搭建SSM框架 前期的准备 步骤分解整合SSM以及注意事项 整合mybatis分页插件 （详见核心代码） 整合mybatis事务 (详见注意事项) 前期的准备说明:一个项目分为前台:如考勤,审批.而后台数据库交互模块（dao).通用业务模块（service） 接口模块（api）通用工具（util）,dao、service、util你可能想要一些经验丰富的人来维护,模块化开发的另一个好处是如果dao的代码被修改，只需要重新build我们的dao模块就可以了。web模块可以build成war，dao、service、util等可以build成jar，只需要配置好依赖关系，就可以实现模块间的解耦合。这样的设计才是遵循“高内聚，低耦合”设计原则. 步骤分解整合SSM(配置方式很多,活学活用)构建父级项目方式为(构建方式为pom) 名字为small 父级项目右键构建3个moudle,分别small-web small-service small-dao 其中web打包方式为war 其余的均为jar small-web: small-service: small-dao:同理 pom.xml详见github链接 配置文件结构（配置文件主要在small-web中） 整合mybatis分页插件(详见核心代码) 通过mybatis分页插件可以不用在mapper映射中使用limit语句,使用插件提供的PageHelper和PageInfo对象 12345678@RequestMapping(&quot;/select1&quot;)@ResponseBodypublic List&lt;Student&gt; a11()&#123; PageHelper.startPage(2, 3); List&lt;Student&gt; students = studentService.getAllStudent(); PageInfo&lt;Student&gt; pi = new PageInfo&lt;&gt;(students); return students;&#125; 整合mybatis事务 (详见注意事项) 使用 @Transactional 注解在服务的实现类中 其余操作详见github链接代码 整合swaager文档生成 相关依赖 (在small-web中) 123456789101112131415161718192021&lt;springfox-swagger2&gt;2.7.0&lt;/springfox-swagger2&gt;&lt;springfox-swagger-ui&gt;2.7.0&lt;/springfox-swagger-ui&gt;&lt;jackson-databind&gt;2.9.0&lt;/jackson-databind&gt;//分隔线注意&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;springfox-swagger2&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--springfox-ui的jar包(里面包含了swagger的界面静态文件) --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;springfox-swagger-ui&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--springfox依赖的jar包；如果你的项目中已经集成了无需重复 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson-databind&#125;&lt;/version&gt;&lt;/dependency&gt; 构建swagger初始化配置 构建一个新报 com.wwj.swagger 1234567891011121314151617181920212223242526272829303132333435363738package com.wwj.swagger;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;@Configuration@EnableSwagger2@EnableWebMvc@ComponentScan(basePackages = &quot;com.wwj.controller&quot;)public class SwaggerConfig &#123; @Bean public Docket api() &#123; return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.any()) .build() .apiInfo(apiInfo()); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(&quot;small接口文档&quot;) .description(&quot;small接口测试&quot;) .version(&quot;1.0.0&quot;) .termsOfServiceUrl(&quot;&quot;) .license(&quot;&quot;) .licenseUrl(&quot;&quot;) .build(); &#125;&#125; 在spring-mvc中注入对象和过滤对象 12345&lt;!--启用该标签代表 spring mvc 不拦截css、js、jpg等相关的静态资源--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;bean class=&quot;com.wwj.swagger.SwaggerConfig&quot;/&gt; &lt;mvc:resources location=&quot;classpath:/META-INF/resources/&quot; mapping=&quot;swagger-ui.html&quot;/&gt; &lt;mvc:resources location=&quot;classpath:/META-INF/resources/webjars/&quot; mapping=&quot;/webjars/**&quot;/&gt; 下载swaggerUI界面 讲dist文件摆放到项目中api文件夹下 更改index.html中地址为自己的项目名+api+api-docs url: &quot;http://localhost:8080/small-web/api/api-docs&quot; 方法和参数上使用 12@ApiOperation(value=&quot;删除学生信息&quot;,httpMethod=&quot;POST&quot;) public Map&lt;String,String&gt; a4(@ApiParam(name = &quot;sid&quot;, value = &quot;学生编号&quot;, required = true)int sid) 图示如下:]]></content>
      <categories>
        <category>框架整合</category>
      </categories>
      <tags>
        <tag>项目整合</tag>
        <tag>MVC模式</tag>
        <tag>业务分层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven项目管理工具使用]]></title>
    <url>%2F2019%2F07%2F30%2F2019-09-10-Maven%2F</url>
    <content type="text"><![CDATA[一个项目管理工具,能够帮助你的项目构建以及部署加快. maven的上下一体 Maven 简介 Maven 的安装和配置 Maven 仓库 Maven 入门 Maven 核心概念解析 Maven 的依赖管理 Eclipse 中创建 Maven JAVEWEB 项目 Maven 的继承 Maven 的聚合 maven简单的说是一个项目集管理工具 一个项目里面包含什么内容,无非是java代码,资源,甚至是相关的一些jar包,如何摆放 多个项目之间是否存在关系,是否需要相互照应,是否能够将项目直接放置在tomcat中,那么这些都需要靠maven来进行操作 maven的简介说明 一个普通的web项目需要在lib中引入大量的jar包,maven可以帮助我们添加需要的jar包 一个工具包可能需要依赖其它的jar包作为支撑,比如使用log4j的时候需要依靠通用的common-io包,maven可以帮助的项目做依赖jar包 一些jar包有着不同的版本,每个项目可能需要的jar包不一样，从哪里来。maven提供了一个中央仓库供大家下载 多模块拆分,以前常见使用package的方式进行分层能够解决基本的问题,但随着项目越来越大,那么我们要进行细化,直接使用package分并不够。那么通过我们可以通过maven进行拆分，并且统一进行管理 关于构建 （结构化的建立）(也就是有一种标准式的建立方式) 主要有几个动作: clean 清理:删除编译的内容,做好重新编译的准备 complie 编译:也就是将代码编译为class文件 test 测试:对项目中的某个模块业务进行测试,以确保的结果的准确性 report 报告:有测试完毕的情况下,有对应的报告生成 package 打包:将一个文件或者多个进行jar或者war包打包 install 安装:将jar包或者war包安装到本地仓库中 deploy 部署:将war包部署到服务器容器中 自动构建 (CI) 持续集成 上面的动作是非常繁琐的。是否可以通过一个命令一个脚本帮助你做这件事情。这个我们称作为自动构建或者叫做持续集成 maven的安装与配置 官网地址下载 windows配置环境变量（注意:可能需要设置JAVA_HOME变量） mac中加入 bash_profile (可执行的配置文件) 12345cat ~/.bash_profile#add maven_homeMAVEN_HOME=/Users/Yun/Documents/maven/apache-maven-3.3.9PATH=$PATH:$MAVEN_HOME/binexport MAVEN_HOME 使用mvn -v 命令查看maven版本 (验证是否安装成功) 修改使用maven下载jar包存放仓库的位置(路径自行选择) 在config-setting.xml中 更改&lt;localRepository&gt;/Users/Yun/Documents/maven/repo&lt;/localRepository&gt; 设置镜像仓库（maven默认仓库假设在美国,国内有锁,下载十分缓慢） 123456&lt;mirror&gt;&lt;id&gt;nexus-aliyun&lt;/id&gt;&lt;mirrorOf&gt;*&lt;/mirrorOf&gt;&lt;name&gt;Nexus aliyun&lt;/name&gt;&lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;&lt;/mirror&gt; 后期为了保证项目统一的jdk版本在中加入(JDK更改即可) 123456789101112&lt;profile&gt; &lt;id&gt;jdk18&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; maven仓库的概念 本地仓库 (本地maven存放的文件) 远程仓库 (来自五湖四海汇集到一起) 私服 (开发中,都有自己搭建的私服,其实就是私有仓库) 中央仓库和镜像 中央仓库只有一个，镜像是中央仓库的克隆，用于分担中央仓库的压力 maven入门 eclipse中配置maven路径(默认是自动识别) 加载maven配置文件 构建一个mavenproject（勾选创建一个简单的maven项目） 目录结构如下: 观察一下pom.xml（自行加入junit） 123456789101112131415&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;maven001&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.0&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 在src/main/java 以及 src/test/java中 12345public class HelloMaven &#123; public String sayHello(String name)&#123; return &quot;Hello &quot;+name+&quot;!&quot;; &#125;&#125; 12345678910111213import static org.junit.Assert.*;import org.junit.Test;import com.wwj.hell.HelloMaven;public class HelloMavenTest &#123; @Test public void testHello()&#123; HelloMaven hello = new HelloMaven(); String results = hello.sayHello(&quot;wwj&quot;); //用于判别内容是否一致 assertEquals(&quot;Hello wwj!&quot;,results); &#125;&#125; 切换到项目根目录下执行 mvn compile (注意观察info) mvn clean （注意观察info） mvn test (注意观察info) 会新增一个测试报告 mvn package (注意观察info) （compile-&gt;test-&gt;package） Maven 核心概念解析（pom,目录结构,坐标） pom.xml文件对整体项目文件的管理。认知maven就是认知pom.xml文件 src/main/java 为项目的逻辑代码存放地 src/main/resource 为项目资源配置文件,同理测试目录为测试文件与资源的存放地 target为compile存放文件的位置 坐标主要的目的一个项目能从maven仓库中找到需要的内容,而这个内容需要有一个标识 123&lt;groupId&gt;com.wwj&lt;/groupId&gt;&lt;artifactId&gt;maven001&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; 执行 mvn install (观察info) 相当于打包jar包放置与本地仓库中 路径: Maven 的依赖管理 依赖管理 中有一个标签叫 , scope有3个选项compile,test,provided compile 编译 主要为项目主业务代码 从前到后使用 test 测试 主要提供给测试业务代码 仅仅只在test使用 provided 可提供的 也就是从编译到测试使用,可以理解为仅仅只在项目中使用,部署后由容易本身提供 依赖传递概念 (1). 假如有Maven项目A，项目B依赖A，项目C依赖B。那么我们可以说 C依赖A。也就是说，依赖的关系为：C—&gt;B—&gt;A。 那么我们执行项目C时，会自动把B、A都下载导入到C项目的jar包文件夹中。这就是依赖的传递性。并且C对B的支撑要达到complie级别,A才能够可见到C. 其余级别不支持 (2). 如果C现在不要A （使用exclusion） 12345678&lt;exclusions&gt; &lt;exclusion&gt; &lt;!--被排除的依赖包坐标--&gt; &lt;groupId&gt;A&lt;/groupId&gt; &lt;artifactId&gt;A&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/exclusion&gt;&lt;/exclusions&gt; (3). 依赖冲突:一个项目A，通过不同依赖传递路径依赖于X，若在不同路径下传递过来的X版本不同 短路优先 (会选择version2) A -&gt; B -&gt; C -&gt; X(VERSION=1) 和 A -&gt; D -&gt; X(VERSION=2) 声明优先(会选择version2) 在A的声明中 D如果写在E前则D优先 A -&gt; D -&gt; X(VERSION=2) 和 A -&gt; E -&gt; X(VERSION=1) 统一版本管理 1234567891011&lt;properties&gt; &lt;wwj.junit&gt;4.0&lt;/wwj.junit&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;wwj.junit&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Eclipse 中创建 Maven JAVEWEB 项目 （勾选简单的maven项目） 项目右键勾选属性: OK~ 一个web项目构建完成 maven的继承 (多个子项目都需要某些依赖, 就可以把子项目共同的依赖抽取到父项目中,子项目通过继承得到这些依赖) 构建父项目(打包方式为pom) 父项目使用 dependencyManagement 标签来管理,optional表示子 pom 无论如何都不能继承(已经失效) 12345678910111213141516171819202122&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;maven003&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 子 pom 可以继承 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;/project&gt; 子项目使用父项目的依赖 12345678910111213141516171819202122&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;maven004&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;!-- 父项目坐标 --&gt; &lt;groupId&gt;com.wwj&lt;/groupId&gt; &lt;artifactId&gt;maven003&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 父项目 pom 文件路径 --&gt; &lt;relativePath&gt;../maven003/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- 不需要版本, 会从父项目继承, 如果指定版本就是代表不是来自父 pom 而是子 pom 自己的. --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 9.maven聚合 (将功能模块拆分,最常见的我们整合ssm的时候会将service和dao进行拆分,当然也可以以项目的方式) maven-parent (Maven Project) |- maven-son1 (Maven Module)|- maven-son2 (Maven Module)|- … 创建父模块(父模块一般承担聚合模块和统一管理依赖的作用，没有实际代码和资源文件) （打包方式为pom.xml） 右键父项目创建子模块module 分别观察到父亲管理那些模块,儿子的父亲是谁 父模块做统一管理 12345678910111213&lt;properties&gt; &lt;wwj.json&gt;1.2.47&lt;/wwj.json&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 子 pom 可以继承 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;$&#123;wwj.json&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 子模块直接进行依赖 1234567&lt;dependencies&gt; &lt;!-- 子 pom 可以继承 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 切换到maven父项目执行mvn install (观察info)]]></content>
      <categories>
        <category>项目管理工具</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle1]]></title>
    <url>%2F2019%2F07%2F30%2F2019-09-10-Oracle(%E7%BC%98)%2F</url>
    <content type="text"><![CDATA[Oracle数据库也是一个数据库的中间力量 服务器的配置 512M内存 500GB的带宽 10G的SSD 系统采用centos6 64位 3.5刀一个月 XE是免费可授权版.只允许在一个机器上面跑实例。但是用来测试单库是性价比最高的 XE的下载地址 (现在oracle需要采取登录才能授权下载,故采用scp的方式上传到服务器中)http://download.oracle.com/otn/linux/oracle11g/xe/oracle-xe-11.2.0-1.0.x86_64.rpm.zip 上传至root下的自定义文件下 scp /Users/Yun/Downloads/oracle-xe-11.2.0-1.0.x86_64.rpm.zip root@144.202.3.120:/root/wwj/ 安装固定依赖 yum install libaio libaio-devel bc -y 添加虚拟内存(针对小型服务器)(命令请依次执行) su - root dd if=/dev/zero of=/swapfile bs=1024 count=1048576 mkswap /swapfile swapon /swapfile cp /etc/fstab /etc/fstab.backup_$(date +%N) echo ‘/swapfile swap swap defaults 0 0’ /etc/fstab chown root:root /swapfile chmod 0600 /swapfile swapon -a swapon -s 注意:需要删除虚拟内存分区即可swapoff /swapfile和rm -rf /swapfile 安装解压命令并解压 yum install -y unzip zip unzip oracle-xe-11.2.0-1.0.x86_64.rpm.zip 文件安装在disk01中,安装切换到disk01中 安装oracelXE(切换到Disk01) rpm -ivh oracle-xe-11.2.0-1.0.x86_64.rpm 执行初始化文件 /etc/init.d/oracle-xe configure命令 默认端口为8080 可改:8888 监听端口为1521 sys与system密码设置为xxxx 配置为开机启动 等待中…… 可选操作(需要在命令窗口中进行数据库的访问) cd /u01/app/oracle/product/11.2.0/xe/bin/ (u01在系统的根目录下) source ./oracle_env.sh 可选图形连接界面 /sbin/iptables -I INPUT -p tcp –dport 1521 -j ACCEPT (加入端口开放) /etc/rc.d/init.d/iptables save （保存端口） /etc/init.d/iptables status （查看开放的端口） 可选关闭防火墙 service iptables start service iptables stop 特别注意 创建一个新的表空间(类似创建一个新的数据库) 新建一个用户给与connect与resource权限 更改连接 美美的操作oracle数据库]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据持久化</tag>
        <tag>关系型数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC2]]></title>
    <url>%2F2019%2F07%2F29%2F2019-09-10-SpringMVC(%E4%BB%BD)%2F</url>
    <content type="text"><![CDATA[SpringMVC让你的C层更加高效 springMVC(下集) SpringMVC 的常用注解 SpringMVC 静态资源的处理 SpringMVC 的文件上传和下载 SpringMVC 的统一异常处理 SpringMVC 的拦截器 SpringMVC 的自动校验 springmvc常用注解使用cookie获取页面设置的cookie值,代码示例: 构建页面进行cookie的值的设置 12345678910&lt;head&gt; &lt;script type=&quot;text/javascript&quot;&gt; //(path)必须要填写，因为JS的默认路径是当前页，如果不填，此cookie只在当前页面生效！~ document.cookie=&quot;name=wwj;path=/&quot; document.cookie=&quot;age=32;path=/&quot; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;a href=&quot;testCookie&quot;&gt;查看Cookie&lt;/a&gt;&lt;/body&gt; 后台业务代码 123456789@Controllerpublic class CookieController &#123; @RequestMapping(&quot;/testCookie&quot;) public String testCookie(@CookieValue(value = &quot;name&quot;, required = false) String name, @CookieValue(value = &quot;age&quot;, required = false) Integer age) &#123; System.out.println(name + &quot;,&quot; + age); return &quot;hello&quot;; &#125;&#125; 操作访问，先访问jsp页面进行cookie值的设置。在进行请求的访问 使用@SessionAttributes将数据放入session作用域中需要注意的是@SessionAttributes只能用在类上 常用的设置@SessionAttributes(value={“user1”, “user2”}) 会将model中属性名为user1和user2的属性添加到会话中 12345678910@SessionAttributes(value=&#123;&quot;user&quot;&#125;)@Controllerpublic class SessionController &#123; @RequestMapping(&quot;/testSessionAttributes&quot;) public String testSessionAttributes(Model model)&#123; model.addAttribute(&quot;user&quot;, &quot;wwj&quot;); return &quot;success&quot;; &#125;&#125; 访问连接,分别在不用的页面进行取值 使用@ModelAttribute 注释在一个普通方法(初始化数据) 12345//构建一个模型public class Girl &#123; private String name; private int age;&#125; 123456789101112131415@Controllerpublic class ModelController &#123; @ModelAttribute(&quot;girl&quot;) public Girl init(Model model)&#123; Girl g = new Girl(); g.setAge(28); g.setName(&quot;菲菲&quot;); return g; &#125; @RequestMapping(&quot;/m1&quot;) public String m1(Model model) &#123; System.out.println(model.containsAttribute(&quot;girl&quot;)); return &quot;msg&quot;; &#125;&#125; 直接接收restful格式并进行封装 路径请求 &lt;a href=&quot;m2/wwj/32&quot;&gt;restful操作&lt;/a&gt; 接收restful 12345@RequestMapping(&quot;/m2/&#123;name&#125;/&#123;age&#125;&quot;)public String m1(@ModelAttribute Girl girl) &#123; System.out.println(girl.getName()+girl.getAge()); return &quot;msg&quot;;&#125; 注意数据:数据被封装到modelattr中，同时也是在model中的 设置请求方式 (了解)@RequestMapping(value=”m3”,method=RequestMethod.POST) 通过method来设置http的请求方式 总结:其实不在乎注解的与多少，毕竟是属于对servlet的包装，可以假定不管使用什么方式,接收到前台所传递的参数 springMVC对于静态资源的处理 使用 &lt;mvc:resources&gt; 掌握 http://localhost:8080/springmvc001/usrjs.jsp 静态资源在加载的时候,被拦截了。这个时候需要我们在springmvc中标注哪些为静态资源，不受springmvc进行拦截 &lt;mvc:resources location=&quot;/js/&quot; mapping=&quot;/js/**&quot;/&gt; location代表着webcontext容器下路径。映射所有js下面的资源为静态资源 观察浏览器资源加载列表 使用&lt;mvc:default-servlet-handler/&gt;（掌握） SpringMVC的文件上传和下载文件上传 构建form表单 需要设置enctype(编码格式) 为 multipart/form-data 不仅包含文本数据,还包含文件数据 12345&lt;!-- 多文件上传 --&gt;&lt;form action=&quot;uploadUrl&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;filename&quot; /&gt; &lt;input type=&quot;file&quot; name=&quot;filename&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;文件上传&quot; /&gt;&lt;/form&gt; 引入对应的jar包 Commons-fileupload.jar和commons-io.jar 2个包属于依赖关系翻译过来就是通用的上传与通用的读写操作 设置对应的上传数据要求在springmvc.xml中 123456&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!-- 设置请求编码格式，必须与JSP中的pageEncoding属性一致 --&gt; &lt;property name=&quot;defaultEncoding&quot; value=&quot;UTF-8&quot; /&gt; &lt;!-- 设置允许上传文件的最大值（2MB），单位为字节 --&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;2097152&quot; /&gt;&lt;/bean&gt; 处理对应上传的处理类 123456789101112131415161718192021222324252627282930313233@Controllerpublic class UploadController &#123; @RequestMapping(&quot;/uploadUrl&quot;) public String handleFormUpload(@RequestParam(&quot;filename&quot;) MultipartFile[] files,HttpServletRequest req)&#123; //判断文件是否存在 if(files.length&gt;0)&#123; for (MultipartFile multipartFile : files) &#123; //获取上传文件的原始名字 String originalFilename = multipartFile.getOriginalFilename(); //一般决定于项目设计的时候所规范的路径 String dirPath = req.getServletContext().getRealPath(&quot;/upload/&quot;); File filePath = new File(dirPath); //如果保存文件的地址不存在，就先创建目录 if(!filePath.exists()) &#123; filePath.mkdirs(); &#125; String newFilename = UUID.randomUUID()+&quot;_&quot;+originalFilename; try &#123; multipartFile.transferTo(new File(dirPath + newFilename)); &#125; catch (IllegalStateException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; return null; &#125;&#125; 注意:UUID 是 通用唯一识别码（Universally Unique Identifier），是一种软件建构的标准 使用ajax进行文件的上传 注意事项: 需要使用到js中一个叫做formData对象 尽量使用goole或者火狐浏览器 123456789101112131415161718function testup()&#123; var form = new FormData(document.getElementById(&quot;tf&quot;)); $.ajax(&#123; url:&quot;uploadUrl1&quot;, type:&quot;post&quot;, data:form, processData:false, contentType:false, success:function(data)&#123; console.log(data) if(data==&quot;ok&quot;)&#123; alert(&quot;上传成功&quot;) &#125;else &#123; alert(&quot;上传失败&quot;) &#125; &#125; &#125;);&#125; 注意:contentType 和 processData 设置为false 使其能够正确的对formdata进行处理 文件的下载 构建请求 12&lt;a href=&quot;downloadone&quot;&gt;下载单文件&lt;/a&gt;&lt;a href=&quot;downloadmore&quot;&gt;下载多文件&lt;/a&gt; 构建处理类: 单文件下载 123456789101112131415161718@Controllerpublic class DownloadController &#123;@RequestMapping(&quot;/downloadone&quot;) public ResponseEntity&lt;byte[]&gt; download(HttpServletRequest req) throws IOException &#123; // 这个路径由数据库中取出 String resourceName = &quot;计划.txt&quot;; // 指定全路径位置 File file = new File(req.getServletContext().getRealPath(&quot;/upload/&quot;)+resourceName); HttpHeaders headers = new HttpHeaders(); // 避免出现文件名乱码 String filename = new String(resourceName.getBytes(&quot;iso-8859-1&quot;),&quot;utf-8&quot;); //设置响应的内容 attachment 附件 headers.setContentDispositionFormData(&quot;attachment&quot;, filename); // 设置响应的内容为流的方式 headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); return new ResponseEntity&lt;byte[]&gt;(FileUtils.readFileToByteArray(file),headers,HttpStatus.CREATED); &#125; 多文件需要考虑进行打包 1234567891011121314151617181920212223242526272829303132333435@RequestMapping(&quot;/downloadmore&quot;) public ResponseEntity&lt;byte[]&gt; download1s(HttpServletRequest req) throws IOException &#123; //数据库中提取 List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;计划.txt&quot;); list.add(&quot;进度.txt&quot;); //压缩后的文件名 String resourcesName = &quot;test.zip&quot;; //压缩后的全路径 String pathName = req.getServletContext().getRealPath(&quot;/upload/&quot;); File zipFile = new File(pathName+resourcesName); ZipOutputStream zipOut = new ZipOutputStream(new FileOutputStream(zipFile)); //读取并写入到压缩包里面 InputStream input = null; for (String str : list) &#123; String name = pathName+str; input = new FileInputStream(new File(name)); zipOut.putNextEntry(new ZipEntry(str)); int temp = 0; while((temp = input.read()) != -1)&#123; zipOut.write(temp); &#125; input.close(); &#125; zipOut.close(); File file = new File(pathName+resourcesName); HttpHeaders headers = new HttpHeaders(); String filename = new String(resourcesName.getBytes(&quot;iso-8859-1&quot;),&quot;utf-8&quot;); headers.setContentDispositionFormData(&quot;attachment&quot;, filename); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); return new ResponseEntity&lt;byte[]&gt;(FileUtils.readFileToByteArray(file),headers,HttpStatus.CREATED); &#125; SpringMVC 的统一异常处理(掌握) (避免在controller中进行冗余的try catch操作) 先自定义异常 123456789101112/** * 自定义异常 * @author Yun * */public class ServiceException extends RuntimeException &#123; public ServiceException(String msg)&#123; super(msg); &#125;&#125; 定义全局异常处理类 （需要用到@ControllerAdvice以及@ExceptionHandler(ServiceException.class)） 123456789101112131415161718@ControllerAdvicepublic class GlobalExceptionResolver &#123; /** * 处理所有业务异常 * * @param e 业务异常 * @return json结果 */ @ExceptionHandler(ServiceException.class) @ResponseBody public Girl handleOpdRuntimeException(ServiceException e) &#123; Girl g = new Girl(); g.setAge(18); g.setName(&quot;wwj&quot;); return g; &#125;&#125; controller业务处理 123456789101112131415@Controllerpublic class Econtroller &#123; /** * 测试返回异常信息 * @return */ @RequestMapping(&quot;/exception&quot;) public void returnExceptionInfo() &#123; if (1 != 2) &#123; // 用户民错误或不存在异常 throw new ServiceException(&quot;错误&quot;); &#125; &#125;&#125; 注意:开发中,我们在设计业务功能模块，都需要配置对应的exception处理 SpringMVC 拦截器 (掌握) 拦截 Interceptor拦截器是对过滤器操作的一种升华。拦截器本身的机制也是aop进行实现 操作方式 123456789101112131415161718192021222324public class MyInterceptor implements HandlerInterceptor&#123; @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &#123; // TODO Auto-generated method stub System.out.println(&quot;afterCompletion&quot;); &#125; @Override public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) throws Exception &#123; // TODO Auto-generated method stub System.out.println(&quot;postHandle&quot;); &#125; @Override public boolean preHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2) throws Exception &#123; // TODO Auto-generated method stub System.out.println(&quot;preHandle&quot;); return true; &#125;&#125; 配置文件 123456789&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!-- 拦截所有的请求，这个必须写在前面，也就是写在【不拦截】的上面 --&gt; &lt;mvc:mapping path=&quot;/**&quot; /&gt; &lt;!-- 但是排除下面这些，也就是不拦截请求 --&gt; &lt;mvc:exclude-mapping path=&quot;/login.html&quot; /&gt; &lt;bean class=&quot;com.wwj.interceptor.MyInterceptor&quot; /&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 执行的顺序为 preHandle 在业务处理器处理请求之前被调用(如果preHandle返回false) postHandle 在业务处理器处理请求执行完成后,生成视图之前执行 afterCompletion 完全处理完请求后被调用,可用于清理资源等 SpringMVC 的自动校验(了解) 引入相关的jar包 构建实体类 （有一些注解可以对对象的某个字段进行检验） 12345678910import javax.validation.constraints.NotBlank;import javax.validation.constraints.NotNull;public class User &#123; @NotNull(message=&quot;id不能为空!&quot;) private int uid; @NotBlank(message=&quot;用户名不能为空!&quot;) private String uname; &#125; (将配置文件中拦截器代码剔除) 12345&lt;form action=&quot;user1&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;uid&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;uname&quot;/&gt; &lt;button&gt;提交&lt;/button&gt;&lt;/form&gt; 控制代码中通过提供的errorObj来获取验证的信息 1234567891011121314@Controllerpublic class Vcontroller &#123; @RequestMapping(&quot;/user1&quot;) @ResponseBody public User test(@Validated User user, BindingResult result) &#123; if (result.hasErrors()) &#123; List&lt;ObjectError&gt; errors = result.getAllErrors(); for (ObjectError error : errors) &#123; System.out.println(error.getDefaultMessage()); &#125; &#125; return user; &#125;&#125;]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
      <tags>
        <tag>MVC模式</tag>
        <tag>Spring产品</tag>
        <tag>替代servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC1]]></title>
    <url>%2F2019%2F07%2F26%2F2019-09-10-SpringMVC(%E7%BC%98)%2F</url>
    <content type="text"><![CDATA[SpringMVC让你的C层更加高效. springMVC初次 SpringMVC简介 SpringMVC的执行流程 SpringMVC的入门案例 SpringMVC相关配置文件解析 SpringMVC的参数绑定 SpringMVC自定义类型转换器 SpringMVC控制器方法的返回值处理 SpringMVC的跳转以及重定向传值 springMVC简介 springMVC本身也是基于对servlet进行了封装，也是轻量级的web开发框架之一 从使用角度来说,就是依赖大量的注解，达到传统意思上面MVC的Controller的功效 springMVC的执行流程 一个请求匹配前端控制器 DispatcherServlet的请求映射路径(在web.xml中指定),WEB容器将该请求转交给DispatcherServlet * 处理DispatcherServlet 接收到请求后, 将根据请求信息交给处理器映射器(HandlerMapping) HandlerMapping 根据用户的url请求 查找匹配该url的 Handler，并返回一个执行链 DispatcherServlet 再请求 处理器适配器(HandlerAdapter)调用相应的Handler进行处理并返回ModelAndView给DispatcherServlet DispatcherServlet 将 ModelAndView 请求 ViewReslover（视图解析器）解析，返回具体 View DispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中） DispatcherServlet 将页面响应给用户 用港剧的方式来说明下(港剧最喜欢的就是走私贩毒什么的 贩毒是暴利，需要周密的计划和设计,才能有获利) 现在有一批毒品进行货运 (梁朝伟负责) （梁朝伟不可能直接就联络到接收人） （用户发起一个http请求） 梁朝伟打电话问周润发,因为周润发那里有一个接收人联络官(黎明)(HandlerMapping),(这里周润发就等同于DispatcherServlet) 周润发告诉接收人联络官((黎明))之后，接收联络官那里有一个联络表，肯定不是明文显示，找到了对应的接收人（刘德华）(handler) 每个人都有自己接收的方式(刘德华也不例外)（也就是执行链）, 但是你想，虽然无非就是梁朝伟去找刘德华，但是我们说的，一旦被抓就可能全盘完蛋，黎明和周润发都不可能直接和梁朝伟说，你去找谁。 所以刘德华（handler）会给(快递员HandlerAdapter)说我是接收人，然后周润发也来问我接收人是谁.我不知道那个是不是毒品。我只知道谁给我，我给谁.按照他们要求的方式进行打包(毒品伪装)（HttpMessageConveter数据转换） 1 我送达之后，会有一个回执单（上面是暗号)(modelandview),我会给周润发（DispatcherServlet） 周润发根据这个暗号，然后用心里默默记住的（ViewReslover）类似解码表进行解码 将所有的交易的信息，时间点（渲染+解析）交给了什么（梁朝伟吗？不是)交给了历史。(everybody都可以阅历历史） 设计代码，就是所谓的高内聚，低耦合 SpringMVC入门 新建项目,并且导入对应的jar包 页面中发起一个同步的请求 hello (梁朝伟) 在web.xml中 (周润发) 注意解决乱码可以配置/,但是可能会出现不生效的情况,所以建议填写(/*) 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot; &quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot; &gt;&lt;web-app&gt; &lt;!-- 处理POST提交乱码问题 --&gt; &lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;!-- 前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 不使用 默认找 /WEB-INF/[servlet的名称(springmvc)]-servlet.xml --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 3.1 完善联络关系表 springmvc.xml 在src下 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.1.xsd&quot;&gt; &lt;!-- 扫描包以其子包下所有类的注解 @Controler @Service等 --&gt;&lt;context:component-scan base-package=&quot;com.wwj&quot;/&gt;&lt;!-- 注解驱动 --&gt;&lt;mvc:annotation-driven/&gt;&lt;!-- 视图解释器 使用前后缀拼接跳转页面路径 --&gt;&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;&lt;/bean&gt; &lt;/beans&gt; 编写controller 刘德华 1234567891011@Controllerpublic class HelloController &#123; @RequestMapping(&quot;/hello&quot;) public ModelAndView login()&#123; //处理业务逻辑 ModelAndView mv = new ModelAndView(); mv.addObject(&quot;pOne&quot;,&quot;wwj&quot;); mv.setViewName(&quot;main&quot;); return mv; &#125;&#125; 注意:如果在jsp页面使用el表达式，无法取值的话,可以在jsp抬头上面添加&lt;%@ page isELIgnored =”false” %&gt; SpringMVC 相关配置文件解析(了解) web.xml中添加了init-param 主要是调整我们的配置文件位置加载在src目录下 关于url-pattern常用规则 使用url-pattern配置为 / 拦截所有的请求 使用(*.action或者*.do) 也就是加一个动作标签 如果使用/* 而我们访问的是一个/xxx.html 或者是 /xxx.jsp 的静态资源。那么拦截了之后，返回对应的设置的value=”/WEB-INF/jsp/“ 是无法找到的。 /并不是真正意义上的拦截所有请求，它不会拦截jsp的页面请求，其他的请求则会拦截 /*才是真正意义上的拦截所有请求 SpringMVC 的参数绑定的多种方式 分类 接收多个独立的参数 接收简单的对象类型(包含时间处理) 接收复杂的对象类型 (了解) 接收restful形式的参数 （理解） 接收json数据或者是json字符串 接收多个独立的参数 12345678910&lt;form action=&quot;a1&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;a&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;b&quot;/&gt; &lt;button&gt;提交&lt;/button&gt;&lt;/form&gt;//接收多值的参数 @RequestMapping(&quot;/a1&quot;) public void login(@RequestParam(value=&quot;a&quot;) String a,@RequestParam(value=&quot;b&quot;) String b)&#123; System.out.println(a+b); &#125; 接收简单的对象类型(处理时间类型) 123456public class Person implements Serializable&#123; private int pid; private String name; @DateTimeFormat(pattern=&quot;yyyy-MM-dd&quot;) private Date bir; &#125; 123456&lt;form action=&quot;a2&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;pid&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;bir&quot;/&gt; &lt;button&gt;提交&lt;/button&gt;&lt;/form&gt; 123456@RequestMapping(&quot;/a2&quot;)public void login(Person p)&#123; System.out.println(p.getPid()); System.out.println(p.getName()); System.out.println(p.getBir().toString());&#125; 注意:如果就只传递类似时间格式的字符串而又不包含的在对象中,可以考虑使用java库处理时间字符串,也可以使用全局的自定义转换器(了解)后续会讲到 接收复杂的对象类型 (了解) 对象中多添加List属性private List&lt;String&gt; dognames; 123456789&lt;form action=&quot;a3&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;pid&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;bir&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;dognames[0]&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;dognames[1]&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;dognames[2]&quot;/&gt; &lt;button&gt;提交&lt;/button&gt;&lt;/form&gt; 1234567@RequestMapping(&quot;/a3&quot;)public void login2(Person p)&#123; System.out.println(p.getPid()); System.out.println(p.getName()); System.out.println(p.getBir().toString()); System.out.println(p.getDognames().size());&#125; 接收restful形式的参数 (理解) 何为restful /a4/pname/wwj/ 设计请求的api 1&lt;a href=&quot;a4/pname/wwj&quot;&gt;hellrestful&lt;/a&gt; 1234@RequestMapping(value=&quot;/a4/&#123;pnameattr&#125;/&#123;name&#125;&quot;)public void login3(@PathVariable(value=&quot;pnameattr&quot;) String pnameattr,@PathVariable(value=&quot;name&quot;) String name)&#123; System.out.println(pnameattr+name);&#125; 5.接收json数据或者是json字符串(需要先用到jquery ajax,暂时不设置返回,因为还需额外的jar包进行转换) 暂时先引入:&lt;script src=&quot;http://libs.baidu.com/jquery/1.9.1/jquery.min.js&quot;&gt;&lt;/script&gt; 123456789101112131415161718192021$(function()&#123; var user = &#123; uname : &apos;wwj&apos;, uage : 18 &#125; $.ajax(&#123; url: &quot;a5&quot;, type: &quot;post&quot;, dataType:&apos;json&apos;, data: user, success: function (json) &#123; &#125;&#125;)&#125;)//后台接收 @RequestMapping(&quot;/a5&quot;) public void login4(@RequestParam(&quot;uname&quot;) String uname,@RequestParam(&quot;uage&quot;) String uage)&#123; System.out.println(uname+uage); &#125; 注意:这种方式不推荐,也就是ajax传递json的字符串,而不是对象,那么需要在ajax中设置 contentType : ‘application/json;charset=utf-8’ 赋值参数绑定 直接使用原生的servlet对象以及model(等同于设置到request作用域中) 123@RequestMapping(&quot;/a6&quot;)public void login5(HttpServletRequest req ,HttpServletResponse resp,Model model)&#123;&#125; modelView和modelMap不推荐 自定义转换类型(处理时间类型)1.定义转换器 123456789101112131415161718192021import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;import org.springframework.core.convert.converter.Converter;public class StringToDate implements Converter&lt;String,Date&gt;&#123; @Override public Date convert(String arg0) &#123; // TODO Auto-generated method stub try &#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date date = simpleDateFormat.parse(arg0); return date; &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 注解驱动添加 123456789 &lt;!-- 注解驱动 --&gt;&lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot;/&gt; &lt;bean id=&quot;conversionService&quot; class=&quot;org.springframework.context.support.ConversionServiceFactoryBean&quot;&gt; &lt;property name=&quot;converters&quot;&gt; &lt;set&gt; &lt;bean class=&quot;com.wwj.convert.StringToDate&quot;&gt;&lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 将前面对象属性中提供的注解去掉即可 SpringMVC 控制器方法的返回值处理 SpringMVC 的跳转 (了解) 如果使用void 采用原生servletAPI中进行请求转发和重定向即可 使用springMVC提供的快捷方式 return “redirect: 资源路径 “; return “forward: 资源路径 “; 12345@RequestMapping(&quot;/a6&quot;)public String login5(HttpServletRequest req ,HttpServletResponse resp,Model model)&#123; System.out.println(111); return &quot;redirect: main.jsp&quot;;&#125; 重定向传值(了解,需要借助RedirectAttributes属性) 12345@RequestMapping(&quot;/a6&quot;)public String login5(RedirectAttributes rs)&#123; rs.addAttribute(&quot;pname&quot;,&quot;wwj&quot;); return &quot;redirect: index.jsp&quot;;&#125; 注意观察地址栏的变化 不想参数暴露 123456@RequestMapping(&quot;/a6&quot;)public String login5(RedirectAttributes rs)&#123; //rs.addAttribute(&quot;pname&quot;,&quot;wwj&quot;); rs.addFlashAttribute(&quot;pname&quot;, &quot;wwj&quot;); return &quot;redirect: index.jsp&quot;;&#125; 然后新的请求接收值的时候 一定使用@ModelAttribute String pname]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
      <tags>
        <tag>MVC模式</tag>
        <tag>Spring产品</tag>
        <tag>替代servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAOP]]></title>
    <url>%2F2019%2F07%2F25%2F2019-09-10-SpringAOP%2F</url>
    <content type="text"><![CDATA[Spring的核心思想就是IOC和AOP spring的AOP(面向切面) SpringAOP 详解(aop思想,aop利用代理的想法,代理模式.以及Java提供的动态代理和CGLIB库提供的继承性代理） SpringAOP 的事务管理(如何使用spring管理事务。事务的传播性) SpringAop详解 Aop的核⼼思想叫做⾯向切⾯编程,它是⼀种⾯对横向业务流提出的⼀种解耦⽅案(何为aop,就好⽐法式⾯包.你想加点葡萄,花⽣仁什么的,你不可能因为你想吃什么,⽽重新做.你可以⽤到刀切成⼏块,在每块当中镶嵌进去) 可能会有⼈说,这已经改变的物理结构本⾝发⽣的变化,现实当中不好实现,但是软件开发中,我们作为上帝,那可以随时的组装和实现 如何实现?从这个例⼦来说,我们可以看到想⾃⼰想加什么就加什么,不想加的时候,又能随时⽅便的去掉.又不承担任何风险.现实当中,我们就要不断的去克隆和复制同⼀块物体,以保证风控程度是接近于0.所以在软件的设计开发当中,就是需要我们考虑的⼀个问题(如何解耦) 所以我们需要使⽤⼀种称作为代理的机制. 代理顾名思义便是帮XXX去相关的事,好比彩票你自己买不了,你需要要彩票的代理点帮你买 回过来,我们用专业的计算术语来解释,功能之间是否能够相互独立,能否保证代码不入侵,能达到同样的效果 代码当中体现,能不能尽量在不改动代码的情况下,只以添加类和删减类的插播方式,达到随用随取 代理模式的实现: 一共有3个人称出现.代理角色,真实角色,代理角色和抽象角色共同的行为方式。 代理角色有真实角色的行为引用 代码示例 12345678/** * 代理角色和真实角色共同的行为 * @author Yun * */public interface BuyCaiPiao &#123; void buy500w();&#125; 123456789101112/** * 真实角色 * @author Yun * */public class RealRole implements BuyCaiPiao&#123; @Override public void buy500w() &#123; // TODO Auto-generated method stub System.out.println(&quot;自己买彩票&quot;); &#125;&#125; 123456789101112131415161718/** * 代理角色，代理角色需要有真实角色的引用 * @author Yun * */public class ProxyRole implements BuyCaiPiao &#123; private BuyCaiPiao bcp; public ProxyRole(BuyCaiPiao bcp) &#123; // TODO Auto-generated constructor stub this.bcp = bcp; &#125; @Override public void buy500w() &#123; // TODO Auto-generated method stub bcp.buy500w(); &#125;&#125; 123456789101112public class TestProxy &#123; public static void main(String[] args) &#123; //构建真实角色 RealRole r = new RealRole(); //构建代理角色（传入需要被代理的角色） ProxyRole p = new ProxyRole(r); //代理角色执行 （这件事是发生在代理身上的，也就意味着风险的承担方是代理角色） //从侧方面也可以看到(我们可以额外的在附加其它的动作,而这些都是发生在代理角色身上) //从代码方面看来,是否是我们尽量做类的代码增或者减，尽量的去避免源对象的改变 p.buy500w(); &#125;&#125; 代理模式的深入思考 从上面的代码看,可以发现,如果我们想代理其它的真实角色,那么不说我们需要不断的去扩充接口,扩充真实的代理角色 是否有一种方式,可以动态的实现真实的角色想要实现的动作（其实就是利用我们的反射机制） jdk支持的动态代理方式(实现步骤) 同样的构造接口和真实的角色 123456789/** * 行为接口 * @author Yun * */public interface InterPerson &#123; void sayA(); void sayB(String s);&#125; 1234567891011121314151617181920/** * 真实的角色 * @author Yun * */public class RealPerson implements InterPerson&#123; @Override public void sayA() &#123; // TODO Auto-generated method stub System.out.println(&quot;sayA&quot;); &#125; @Override public void sayB(String s) &#123; // TODO Auto-generated method stub System.out.println(&quot;sayB&quot;); &#125;&#125; 2.实现动态代理特征接口 12345678910111213141516171819202122/** * 动态代理接口 * @author Yun * */public class Myhanlder implements InvocationHandler&#123; //需要被代理的真实角色 private Object target; public Myhanlder(Object obj) &#123; // TODO Auto-generated constructor stub this.target = obj; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // TODO Auto-generated method stub //执行真实角色拥有的方法 ,args代表如果有参数执行有参数 Object o = method.invoke(target, args); return o; &#125;&#125; 通过接口特征构造动态代理对象 12345678910public class TestJdkProxy &#123; public static void main(String[] args) &#123; //构建真实角色 InterPerson ip = new RealPerson(); //通过proxy类进行代理角色创建 InterPerson iproxy = (InterPerson) Proxy.newProxyInstance(InterPerson.class.getClassLoader(),new Class[] &#123;InterPerson.class&#125; , new Myhanlder(ip)); iproxy.sayA(); iproxy.sayB(&quot;ahha&quot;); &#125;&#125; 使用cglib的方式如果只有类,主要通过对字节码的操作.以继承的方式对原有类进行扩展 构建真实角色 123456789public class NewRole &#123; public void go()&#123; System.out.println(&quot;回家&quot;); &#125;; public void gohome()&#123; System.out.println(&quot;回重庆&quot;); &#125;;&#125; 构建代理拦截器 12345678910111213public class CglibProxy implements MethodInterceptor &#123; /** * 通过拦截真实对象的方法 */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; // TODO Auto-generated method stub Object obj = methodProxy.invokeSuper(o, objects); return obj; &#125;&#125; 生成代理对象 123456789101112public static void main(String[] args) &#123; //构建一个增强类 Enhancer eh = new Enhancer(); // 增强类需要设置被代理的类型。以及代理的方法的回调 eh.setSuperclass(NewRole.class); eh.setCallback(new CglibProxy()); //构建代理类 NewRole nr = (NewRole) eh.create(); nr.go(); nr.gohome(); &#125; spring利用aop机制的实现名词概念: Aspect：切面,由一系列切点、增强和引入组成的模块对象,可定义优先级,从而影响增强和引入的执行顺序 Join point：接入点,程序执行期的一个点,例如方法执行、类初始化、异常处理(一般用来获取方法中的一些元数据) Advice：增强,切面在特定接入点的执行动作,包括 “around,” “before” and “after”等多种类型 Pointcut：切点,用来匹配特定接入点的谓词（表达式） Weaving：织入,将一个或多个切面与类或对象链接在一起创建一个被增强对象（也就是构建代理对象的过程） 通知名词: 前置通知 在目标方法执行之前执行执行的通知 后置通知 在目标方法执行之后执行的通知 （出现异常便不再调用） 环绕通知 在目标方法执行之前和之后都可以执行额外代码的通知。 异常通知 在目标方法抛出异常时执行的通知 最终通知 是在目标方法执行之后执行的通知。 通知的应用场景: 实现方式: 构建真实角色 12345678public class UserServiceImpl implements UserService&#123; @Override public void save() &#123; // TODO Auto-generated method stub System.out.println(1/0); &#125;&#125; 定义增强类 1234567891011121314151617181920212223242526272829303132package com.wwj.springaop;import org.aspectj.lang.ProceedingJoinPoint;public class Myadvice &#123; public void before() &#123; System.out.println(&quot; 这是前置通知！ &quot;); &#125; // 后置通知 public void afterReturning() &#123; System.out.println(&quot; 这是后置通知 ( 如果出现异常不会调用 )&quot;); &#125; // 环绕通知 public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; System.out.println(&quot; 这是环绕通知之前的部分！ &quot;); Object proceed = pjp.proceed();// 调用目标方法 System.out.println(&quot; 这是环绕通知之后的部分！ &quot;); return proceed; &#125; // 异常通知 public void afterException() &#123; System.out.println(&quot; 异常出现了！ &quot;); &#125; // 最终通知 public void after() &#123; System.out.println(&quot; 这是后置通知 ( 出现异常也会调用 )&quot;); &#125;&#125; 配置xml 实例化角色 增强类 以及切面，和织入的过程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd &quot;&gt;&lt;!-- 1.构建需要被代理的对象 --&gt;&lt;bean name=&quot;userService&quot; class=&quot;com.wwj.springaop.UserServiceImpl&quot;&gt;&lt;/bean&gt;&lt;!-- 2. 构建需要增强的方法 --&gt;&lt;bean name=&quot;myAdvice&quot; class=&quot;com.wwj.springaop.Myadvice&quot;&gt;&lt;/bean&gt;&lt;!-- 3. 定义aop --&gt; &lt;!-- aop 配置 --&gt; &lt;aop:config&gt; &lt;!-- 自定义切入点 --&gt; &lt;!-- 1、execution(): 表达式主体。 2、第一个*号：表示返回类型，*号表示所有的类型。 3、包名：表示需要拦截的包名，后面的两个句点表示当前包和当前包的所有子包。 4、第二个*号：表示类名，*号表示所有的类。 5、*(..):最后这个星号表示方法名，*号表示所有的方法，后面括弧里面表示方法的参数，两个句点表示任何参数。 --&gt; &lt;aop:pointcut expression=&quot;execution(* com.wwj.springaop..*.*(..))&quot; id=&quot;anyMethod&quot;/&gt; &lt;aop:aspect ref=&quot;myAdvice&quot;&gt; &lt;!-- 前置通知 --&gt; &lt;!-- 测试自定义切入点 --&gt; &lt;aop:before method=&quot;before&quot; pointcut-ref=&quot;anyMethod&quot;/&gt; &lt;!-- 最终通知 --&gt; &lt;aop:after method=&quot;after&quot; pointcut-ref=&quot;anyMethod&quot;/&gt; &lt;!-- 后置通知 --&gt; &lt;aop:after-returning method=&quot;afterReturning&quot; pointcut-ref=&quot;anyMethod&quot;/&gt; &lt;!-- 环绕通知 --&gt; &lt;aop:around method=&quot;around&quot; pointcut-ref=&quot;anyMethod&quot;/&gt; &lt;!-- 异常抛出通知 --&gt; &lt;aop:after-throwing method=&quot;afterException&quot; pointcut-ref=&quot;anyMethod&quot;/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 4.测试执行 12345public static void main(String[] args) &#123; ApplicationContext ac=new ClassPathXmlApplicationContext(&quot;application3.xml&quot;); UserService userService = (UserService) ac.getBean(&quot;userService&quot;); userService.save();&#125; SpringAOP进行事务管理 (如何使用spring管理事务。事务的传播性)通过上面的例子，我们可以看到即将接触到的事务采用环绕通知的方式为最佳.因为全程都在跟进 何为事务的传播性 当服务被定义，就有可能会有事务的产生 服务和服务之间相互调用,就会产生我们称作为事务的传播 事务的传播存在于多个服务相互调用,要保证遵循满足首次产生事务的的ACID 举例说明 转账是一个服务,扣款是一个服务(转账的时候需要调用扣款的服务就构成了) 转账的时候,扣款出了问题,就需要回滚到首次事务,来保证事务的完整性 代码说明(未加入事务) mysql数据库一张账户表(李四余额1000，张三余额1000) 张三转账给李四1000（动作） 代码示例 构建dao层以及接口 1234567891011121314151617181920212223242526272829public interface AccountDao &#123; void updateAddMoney(int aid,int money); void updateDeleteMoney(int aid,int money); &#125;//分隔@Repository(value=&quot;acDao&quot;)public class AccountDaoImpl implements AccountDao&#123; @Resource private JdbcTemplate jdbcTemplate; @Override public void updateAddMoney(int aid, int money) &#123; // TODO Auto-generated method stub jdbcTemplate.update(&quot;update t_account set money=money-? where aid=?&quot;,money,aid); &#125; @Override public void updateDeleteMoney(int aid, int money) &#123; // TODO Auto-generated method stub jdbcTemplate.update(&quot;update t_account set money=money+? where aid=?&quot;,money,aid); &#125;&#125; 构建服务接口和接口实现 扣款 123456789101112131415161718192021222324252627/** * 收款 * @author Yun * */public interface ReciveMoney &#123; /** * * @param aid 接收人id * @param money 接收人金额 */ void Recivemoney(int aid,int money);&#125;//分隔@Service(&quot;recs&quot;)public class ReciveMoneyImpl implements ReciveMoney&#123; @Autowired private AccountDao acDao; @Override public void Recivemoney(int aid, int money) &#123; // TODO Auto-generated method stub acDao.updateDeleteMoney(aid, money); &#125;&#125; 转账 123456789101112131415161718192021222324252627282930313233/** * * @author Yun * 扣款 */public interface PayMoney &#123; /** * * @param aid 扣款人id * @param rid 收款人id * @param money 扣款人金额 */ void paymoney(int aid,int money,int rid);&#125;//分隔@Service(&quot;pays&quot;)public class PaymoneyImpl implements PayMoney&#123; @Autowired private AccountDao acDao; @Autowired private ReciveMoney recs; @Override public void paymoney(int aid, int money,int rid) &#123; acDao.updateAddMoney(aid, money); //构成了事务的传播性 recs.Recivemoney(rid, money); &#125;&#125; 测试 12345678910111213141516@Component(value=&quot;testTX&quot;)public class TestSpringTX &#123; @Autowired private PayMoney pays; public void test1()&#123; pays.paymoney(1,1000, 2); &#125; public static void main(String[] args) &#123; ApplicationContext ac=new ClassPathXmlApplicationContext(&quot;application4.xml&quot;); TestSpringTX tx = (TestSpringTX) ac.getBean(&quot;testTX&quot;); tx.test1(); &#125;&#125; 金额变动假定没有出现任何异常的情况 ==================&gt; 假定扣款出现问题，模拟sql语句执行错误 你会发现，钱扣了，但钱没到账 SpringAOP的事务管理(采用spring进行事务的管理) spring管理事务2种方式 声明式事务 (全局管理事务 可以采用xml方式 或者是 @Transactional 注解的类级别支持和方法的级别) 编程式事务 (spring推荐使用TransactionTemplate)类似在jdbc中开启事务(了解) 一个功能是否要事务,必须纳入设计.编码考虑.不能仅仅完成了基本功能就ok spring使用声明式事务 基于XML 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd &quot;&gt; &lt;!-- 自动根据扫描对应包下面的注解,并实例化对应的对象 --&gt; &lt;context:component-scan base-package=&quot;com.wwj.springtx&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 连接管理交给C3P0 --&gt; &lt;bean name=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/spring&quot;&gt;&lt;/property&gt; &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--JDBCTemplate 需要 datasource 连接池 --&gt; &lt;bean name=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 1使用spring事务管理管理数据源操作 --&gt; &lt;bean name=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 2.定义需要被增强的方法，也就是那些需要介入事务的管理 --&gt; &lt;!-- propagation:REQUIRED(依赖) 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。isolation: 隔离级别 read-only: 是否只读 --&gt; &lt;tx:advice id=&quot;advice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;pay*&quot; propagation=&quot;REQUIRED&quot; /&gt;&lt;!-- *是对所有方法都加 --&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 3.配置切入点，切哪 也就是 织入的过程 --&gt;&lt;!-- 配置织入 --&gt;&lt;aop:config &gt; &lt;!-- 配置切点表达式 --&gt; &lt;aop:pointcut expression=&quot;execution(* com.wwj.springtx..*.*(..))&quot; id=&quot;txPc&quot;/&gt; &lt;!-- 配置切面 : 通知+切点 advice-ref:通知的名称 pointcut-ref:切点的名称 --&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;txPc&quot; /&gt;&lt;/aop:config&gt;&lt;/beans&gt; 基于注解的方式进行 直接在方法或者类上面加: @Transactional(propagation=Propagation.REQUIRED,isolation=Isolation.REPEATABLE_READ,timeout=-1) xml中加入 12345678&lt;!-- 1使用spring事务管理管理数据源操作 --&gt;&lt;bean name=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;/bean&gt; &lt;!-- 支持事务注解 --&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>Spring产品</tag>
        <tag>面向切面</tag>
        <tag>事务管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringIOC]]></title>
    <url>%2F2019%2F07%2F19%2F2019-09-10-SpringIOC%2F</url>
    <content type="text"><![CDATA[Spring的核心思想就是IOC和AOP spring路线图(IOC) Spring 框架简介(Spring优势2大核心思想的体现 IOC(控制权利反转)以及Aop(面向切面)) Spring 入门案例(通过操作 看到对象的生成方式发生的不一样) Spring 配置文件中 bean 标签详解 (比较重要的单例和多例的配置) SpringIOC 讲解 (何为控制反转 为何依赖注入 以及依赖注入实现的几种方式) Spring 整合 JDBC (通过引入数据操作,发现接口和实例对象的管理方式发生的变化)(含注解) Spring框架简介在未来有很多技术,这里可能需要用,那里可能需要用.我们称作为整合,Spring就来给我们提供整合方案,如何整合这就涉及到我们所说的IOC,当然也有人说spring是一个容器(其实当做插线板更好一些) spring的产品线 快速构建可生产的应用程序,快速使用spring进行项目的集成 构建可协调一切的分布式服务应用程序，提供统一的网关.统一的服务治理,统一的可控制面板,统一的数据消息处理 构建可统一进行数据清洗的ETL,完善数据仓库信息的,处理任何数据源 注意:最终的目的是为了方便我们把更多的心思放在需求的实现上面(用我们现有的技术体系) 注意:如果转换到使用的角度来说,spring(高度自律的管理者)管理着不同的技术所产生出来的对象 Spring入门案例(观察使用步骤以及对象的生成方式)1.构建一个web项目,引入对应的jar包 2.构建一个简单的实体 12345public class User &#123; public void invoke()&#123; System.out.println(&quot;普通方法只能被对象调用&quot;); &#125;&#125; 3.构建spring管理的对象的全局文件application.xml 123456789&lt;beans xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd&quot;&gt; &lt;!-- 将该技术交给springbean容器进行管理 --&gt; &lt;bean name=&quot;t1&quot; class=&quot;com.wwj.model.User&quot;&gt;&lt;/bean&gt;&lt;/beans&gt; 4.测试 123456789 public static void main(String[] args) &#123; ApplicationContext ac=new ClassPathXmlApplicationContext(&quot;application.xml&quot;); //2. 向容器“要”user 对象 User u=(User) ac.getBean(&quot;t1&quot;); //3. 打印 user 对象 System.out.println(u.getClass().getName()); u.invoke(); &#125;&#125; 注意1:对象的生成权利交给了谁?谁在管理这个对象? Spring配置文件中bean标签详解 name属性代表定义的标记，方便spring查找到需要管理对象的名字 class 填写管理对象的类型 在bean标签中有一个scope属性默认为(singleton),决定了对象是以单例还是多例的方式生成.可以改为prototype.(了解即可) 在bean标签中默认对象有一个生命周期(了解) 分别为 init-method 和 destory-method .控制一个对象的生命周期，方便我们更好的管理对象 123456789101112public static void main(String[] args) &#123; ApplicationContext ac=new ClassPathXmlApplicationContext(&quot;application.xml&quot;); //2. 向容器“要”user 对象 User u=(User) ac.getBean(&quot;t1&quot;); User u1 = (User) ac.getBean(&quot;t1&quot;); System.out.println(u==u1); //3. 打印 user 对象 System.out.println(u.getClass().getName()); u.invoke(); //关闭容器 ((ClassPathXmlApplicationContext) ac).close();&#125; SpringIOC 讲解 (何为控制反转 为何依赖注入 以及依赖注入实现的几种方式) 先看一下控制正转 在看一下控制反转 IOC:IOC是一种思想,我们称作为控制反转(也就是权利的移交) 依赖注入(对控制反转的进一步升华)(关心对象之间的依赖如何进行管理) 谁依赖于谁：当然是应用程序依赖于IoC容器; 谁注入谁：很明显是IoC容器注入应用程序某个对象，应用程序依赖的对象 注入了什么：就是注入某个对象所需要的外部资源（包括对象、资源、常量数据） 我们可以思考出来spring容器等同于是一个万能的工厂，利用反射机制将对象生成出来，并且进行合理的管控 主要的目的为了解耦.避免代码的入侵 代码示例:假定 小王需要交通工具减轻上班的压力(小王和交通工具就产生了依赖) 123456789public class Person &#123; //这里等于这辈子就只能骑自行车了 Bike b = new Bike(); public void work()&#123; b.go(); &#125;&#125; 小王富裕了, 要换B打头的车了 如果你改代码就等同于代码入侵，所以我们要抽象出交通工具 123456789101112public class Person &#123; //这里等于这辈子就只能骑自行车了 //Bike b = new Bike(); //你可以以后换撒都可以(可以通过设置和构造方法进行对象的注入) private Transport ts; public void work()&#123; ts.go(); &#125;&#125; 6.使用Spring管理对象的注入的几种方式(关注属性注入即可(最常见) 注入的几种方式(属性注入,构造方法注入,数组,集合,map注入) 代码示例: 123456789101112131415161718192021222324public class Vmodel &#123; // 属性注入 private Vperson vp; public void setVp(Vperson vp) &#123; this.vp = vp; &#125; //构造方法注入 private String vname; public Vmodel()&#123; &#125;; public Vmodel(String vname)&#123; this.vname = vname; &#125; //复杂类型注入 private Object[] arr;// 数组类型注入 private List list;//list/set 类型注入 private Map map;//map 注入&#125; 对应的配置文件 (我们更多的看到的是ref关联对应的bean) 123456789101112131415161718192021222324252627282930313233343536 &lt;!-- 属性注入 --&gt; &lt;bean name=&quot;p1&quot; class=&quot;com.wwj.diimpl.Vperson&quot;&gt; &lt;property name=&quot;vpname&quot; value=&quot;djwangweijie&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean name=&quot;v1&quot; class=&quot;com.wwj.diimpl.Vmodel&quot;&gt; &lt;property name=&quot;vp&quot; ref=&quot;p1&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 构造方法注入 --&gt; &lt;bean name=&quot;v2&quot; class=&quot;com.wwj.diimpl.Vmodel&quot;&gt; &lt;constructor-arg name=&quot;vname&quot; value=&quot;michael&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 复杂类型的支持 --&gt; &lt;bean name=&quot;v3&quot; class=&quot;com.wwj.diimpl.Vmodel&quot;&gt; &lt;property name=&quot;arr&quot;&gt; &lt;array&gt; &lt;value&gt;tom&lt;/value&gt; &lt;value&gt;jerry&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;property name=&quot;list&quot;&gt; &lt;list&gt; &lt;value&gt;tom1&lt;/value&gt; &lt;value&gt;jerry1&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;map&quot;&gt; &lt;map&gt; &lt;entry key=&quot;A&quot; value=&quot;abc&quot;&gt;&lt;/entry&gt; &lt;entry key=&quot;B&quot; value=&quot;bcd&quot;&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 测试文件 1234567891011121314public static void main(String[] args) &#123; ApplicationContext ac=new ClassPathXmlApplicationContext(&quot;application.xml&quot;); //属性 Vmodel v1 = (Vmodel) ac.getBean(&quot;v1&quot;); System.out.println(v1.getVp().getVpname()); //构造方法 Vmodel v2 = (Vmodel) ac.getBean(&quot;v2&quot;); System.out.println(v2.getVname()); //复杂类型 Vmodel v3 = (Vmodel) ac.getBean(&quot;v3&quot;); System.out.println(v3.getArr().length); System.out.println(v3.getList().size()); System.out.println(v3.getMap().size());&#125; Spring 整合 JDBC(含注解) 依赖的jar包 类的结构图如下 关心下我们的配置文件 application1.xml 12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd&quot;&gt; &lt;!-- 连接管理交给C3P0 --&gt; &lt;bean name=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/spring&quot;&gt;&lt;/property&gt; &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--JDBCTemplate 需要 datasource 连接池 --&gt; &lt;bean name=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 构建service 和 dao实例对象 --&gt; &lt;bean name=&quot;dandmDao&quot; class=&quot;com.wwj.spring.jdbc.DandMDaoImpl&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplate&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean name=&quot;FindService&quot; class=&quot;com.wwj.spring.jdbc.FindServiceImpl&quot;&gt; &lt;property name=&quot;dandmDao&quot; ref=&quot;dandmDao&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 有没有发现虽然写起来不麻烦,但总要看看属性名再去填写配置文件 补充说明:使用注解的方式实现 依赖的jar包(多了aop) 配置文件 123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd &quot;&gt; &lt;!-- 自动根据扫描对应包下面的注解,并实例化对应的对象 --&gt; &lt;context:component-scan base-package=&quot;com.wwj.anotation&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 连接管理交给C3P0 --&gt; &lt;bean name=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/spring&quot;&gt;&lt;/property&gt; &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--JDBCTemplate 需要 datasource 连接池 --&gt; &lt;bean name=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 注解配置 dao类 12345678910111213141516171819@Repository(value=&quot;dandmDao&quot;)public class DandMDaoImpl implements DandMDao&#123; @Resource private JdbcTemplate jdbcTemplate; @Override public List&lt;Dad&gt; getD() &#123; // TODO Auto-generated method stub return jdbcTemplate.query(&quot;select * from dad&quot;, new RowMapper&lt;Dad&gt;()&#123; @Override public Dad mapRow(ResultSet rs, int arg1) throws SQLException &#123; // TODO Auto-generated method stub Dad d = new Dad(); d.setDname(rs.getString(&quot;dname&quot;)); return d; &#125; &#125;); service类 1234@Service(value=&quot;fs&quot;)public class FindServiceImpl implements FindService&#123; @Autowired private DandMDao dandmDao; 测试类 12345678910111213@Component(value=&quot;test&quot;)public class Testanotation &#123; @Autowired private FindService fs ; public void A()&#123; fs.FindDandM(); &#125; public static void main(String[] args) &#123; ApplicationContext ac=new ClassPathXmlApplicationContext(&quot;application2.xml&quot;); Testanotation tt = (Testanotation) ac.getBean(&quot;test&quot;); tt.A(); &#125;&#125; 注解说明1 @Service用于标注业务层组件（我们通常定义的service层就用这个） @Controller用于标注控制层组件 @Repository用于标注数据访问组件，即DAO组件 @Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 注解说明2 @Resource、@Autowired 当需要在某个类中定义一个属性，并且该属性是一个已存在的bean 因为jdbc在读取xml的时候已经加载了 @Autowired 可以默认使用取的value名字 同时也可以通过加上@Qualifier进行指定]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>Spring产品</tag>
        <tag>面向切面</tag>
        <tag>事务管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate使用]]></title>
    <url>%2F2019%2F07%2F18%2F2019-09-10-Hibernate(%E7%BC%98%E5%88%86)%2F</url>
    <content type="text"><![CDATA[hibernate是一个全自动对象关系映射框架,值得你去使用一番. hibernate路线图 Hibernate 简介(优点和缺点) Hibernate 入门案例(基于XML的操作方式) Hibernate 配置文件详解(基于xml的方式) Hibernate 常用api介绍 （事务,回顾脏读,不可重复读(行级,读更改),幻读(表级读新增)以及数据库隔离级别.并发事务的解决悲观锁和乐观锁机制） 使用Hibernate框架完成 CRUD 操作 Hibernate 的对应关系详解(使用注解的方式进行配置,摘取一对多进行代码数据示例操作) Hibernate 简介同样的hibernate框架是基于jdbc轻量级进行的封装在这里我们再次提到一下这个叫做ORM(面向对象进行数据结构的设计) 面向对象进行数据结构的设计和数据库表的设计有什么不同 hibernate讲究的是全自动对象映射,与mybatis不同,mybatis讲究的是半自动映射 最先本质是为了解决java程序员设计对象的问题，是java的开发人员不关心数据库设计和范式定律 随着业务场景的复杂以及追求可插拔的高度自由化,当然同时也是为了以后springBoot中使用JPA做铺垫,hibernate中我们除了在初次使用的时候使用XML配置后，hibernate的级联关系操作我们采取使用注解的方式进行操作 准确的来说hibernate有的东西,mybatis也有. Hibernate 入门案例(基于XML的操作方式) 1.构建一个新的项目(引入的jar包) 2.分别编写实体和对应的映射文件person.clas 和 pserson_hbm.xml 123456789101112131415161718192021public class Person &#123; private int pid; private String pname; private Date bir;&#125;//------------映射文件&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd&quot;&gt; &lt;hibernate-mapping&gt; &lt;!-- 映射哪一个实体类,以及表名 --&gt; &lt;class name=&quot;com.wwj.model.Person&quot; table=&quot;person&quot;&gt; &lt;!-- 主键的生成策略采用自增 name为对象的属性--&gt; &lt;id name=&quot;pid&quot; column=&quot;pid&quot;&gt; &lt;generator class=&quot;increment&quot;&gt;&lt;/generator&gt; &lt;/id&gt; &lt;property name=&quot;pname&quot; column=&quot;pname&quot;&gt;&lt;/property&gt; &lt;property name=&quot;bir&quot; column=&quot;bir&quot;&gt;&lt;/property&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 3.编写全局声明配置文件 src下 （log4j保持最先的一致） 123456789101112131415161718192021222324&lt;!DOCTYPE hibernate-configuration PUBLIC&quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot;&quot;http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd&quot;&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 方言 保证控制台输出效果一致--&gt; &lt;property name=&quot;dialect&quot;&gt; org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- 数据库驱动jar包 --&gt; &lt;property name=&quot;connection.driver_class&quot;&gt; com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;connection.url&quot;&gt;jdbc:mysql://localhost:3306/hibernate&lt;/property&gt; &lt;property name=&quot;connection.username&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;connection.password&quot;&gt;root&lt;/property&gt; &lt;!--显示sql语句是否格式化sql语句 --&gt; &lt;property name=&quot;hibernate.show_sql&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;hibernate.format_sql&quot;&gt;true&lt;/property&gt; &lt;!--执行DDL的方式,create: 每一次运行都会覆盖原表中的内容 update: 保留原表中的内容 --&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/property&gt; &lt;!-- 将我们的对象和表的映射文件加载到主配置文件中 --&gt; &lt;mapping resource=&quot;com/wwj/model/Person_hbm.xml&quot; /&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 4.构建操作,对比mybatis执行流程动作 1234567891011121314151617181920212223242526272829303132333435363738/** * * @author wwj * 1: 读取全局配置文件 * 2: 构建 sessionFactory * 3: 创建 session(会话) * 4: 开启transcation * 5: 操作数据 （CRUD） * 6: 提交事务 transcation * 7: 关闭 session * */public class TestHT &#123; public static void main(String[] args) throws ParseException &#123; //先处理下时间 SimpleDateFormat sf1 = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); String format = sf1.format(new Date()); Date parse = sf1.parse(format); // 读取配置文件，实例化 默认的寻找 名字为 hibernate.cfg.xml Configuration cfg = new Configuration().configure(); // 构建 session 工厂 SessionFactory sf = cfg.buildSessionFactory(); // 创建 session Session session = sf.openSession(); // 操作数据 (insert delete update) 手动开启事务 Transaction bt = session.beginTransaction(); // 操作数据 (注意这里的面向对象操作) Person per = new Person(); per.setPname(&quot;张三&quot;); per.setBir(parse); // CRUD操作 session.save(per); // 提交事务 bt.commit(); session.close(); &#125;&#125; 观察控制台的输出结果以及数据库表的结构 Hibernate配置文件详解 关于person映射文件以及全局文件详见代码说明 Hibernate常用api介绍 基本上大部分的框架都有一个叫做config的接口(使用xml解析填写的配置文件) xxxFactory,万物皆有工厂造出来,不会平白无故的生成(工厂模式) 工厂虽然可以有很多,工厂很庞大,庞大就耗资源,所以我们才考虑对象的生成(单例模式) (1)事务的ACID 原子性(Atomicity) 要么买要么就不买 一致性(Consistency）有买有卖,不能空仓打粮仓 隔离性(Isolation) 大家交易同一个物品的时候(互相又看不到)但是又不应该出现价格的相互影响(信息的壁垒) 持久性(Durability) 有迹可循,有记录 (2)事务并发 多个线程访问数据库同一条数据 脏读 不可重复读 幻读 不可重复读发生点在一行上面,而幻读是发生在整张表上面 行级锁机制和表级锁都等同于操作上面仅且只有一个事务 补充说明:通过数据所提供的隔离级别(由低到高) ISOLATION_READ_UNCOMMITTED：这是事务最低的隔离级别，它充许令外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻像读。 ISOLATION_READ_COMMITTED：保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据 ISOLATION_REPEATABLE_READ：这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免下面的情况产生(不可重复读)。 ISOLATION_SERIALIZABLE：这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻像读。 重点说明 (操作数据都是先查在操作) 悲观锁机制:也就是同步执行,一个一个来 查询语句加上for update 乐观锁: 使用版本号的机制 大家先查,看到的版本默认为1 做增加删除修改的时候在版本号上面加1 帅选条件要根据当前版本号 最后提交总有先后 有一个操作一定会发生异常，通过捕获异常来进行下一步的处理 使用 Hibernate 框架完成 CRUD 操作123456789101112131415161718192021222324252627282930313233343536373839public class TestHT &#123; public static void main(String[] args) throws ParseException &#123; //先处理下时间 SimpleDateFormat sf1 = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); String format = sf1.format(new Date()); Date parse = sf1.parse(format); // 读取配置文件，实例化 默认的寻找 名字为 hibernate.cfg.xml Configuration cfg = new Configuration().configure(); // 构建 session 工厂 SessionFactory sf = cfg.buildSessionFactory(); // 创建 session Session session = sf.openSession(); // 操作数据 (insert delete update) 手动开启事务 Transaction bt = session.beginTransaction(); // 操作数据 Person per = new Person(); per.setPname(&quot;张三&quot;); per.setBir(parse); // CRUD操作 // --1 .增加 session.save(per); // --2 .查询 （如果查询多个,需要用到hql语句） Person p = (Person) session.get(Person.class, 1); // --3. 修改需要先查 p.setPname(&quot;小李&quot;); session.update(p); // -- 删除 session.delete(p); // -- 查询所有 Query createQuery = session.createQuery(&quot;from Person&quot;); List&lt;Person&gt; list = createQuery.list(); for(Person pp:list) &#123; System.out.println(pp.getPname()); &#125; // 提交事务 bt.commit(); session.close(); &#125; Hibernate的对应关系详解 (采用注解的方式)1.一对一双向注解 Dad类 123456789101112131415161718192021222324252627282930313233343536373839package com.wwj.onetoone;import javax.persistence.CascadeType;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;@Entitypublic class Dad &#123; @Id @GeneratedValue private int did; private String dadName; @OneToOne(cascade = CascadeType.ALL) @JoinColumn(name=&quot;sonId&quot;,unique=true) private Son son; public int getDid() &#123; return did; &#125; public void setDid(int did) &#123; this.did = did; &#125; public String getDadName() &#123; return dadName; &#125; public void setDadName(String dadName) &#123; this.dadName = dadName; &#125; public Son getSon() &#123; return son; &#125; public void setSon(Son son) &#123; this.son = son; &#125; &#125; Son类 12345678910111213141516171819202122232425262728293031323334353637package com.wwj.onetoone;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;@Entitypublic class Son &#123; @Id @GeneratedValue private int sid; private String sname; @OneToOne(mappedBy=&quot;son&quot;) private Dad dad; public int getSid() &#123; return sid; &#125; public void setSid(int sid) &#123; this.sid = sid; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public Dad getDad() &#123; return dad; &#125; public void setDad(Dad dad) &#123; this.dad = dad; &#125; &#125; 2.一对多双向注解 Dad类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.wwj.onetomany;import java.util.List;import javax.persistence.CascadeType;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToMany;import javax.persistence.OneToOne;@Entitypublic class Dad &#123; @Id @GeneratedValue private int did; private String dadName; @OneToMany(cascade=CascadeType.ALL,mappedBy=&quot;dad&quot;) private List&lt;Son&gt; sons; public int getDid() &#123; return did; &#125; public void setDid(int did) &#123; this.did = did; &#125; public String getDadName() &#123; return dadName; &#125; public void setDadName(String dadName) &#123; this.dadName = dadName; &#125; public List&lt;Son&gt; getSons() &#123; return sons; &#125; public void setSons(List&lt;Son&gt; sons) &#123; this.sons = sons; &#125; &#125; Son类 123456789101112131415161718192021222324252627282930313233343536373839package com.wwj.onetomany;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.ManyToOne;import javax.persistence.OneToOne;@Entitypublic class Son &#123; @Id @GeneratedValue private int sid; private String sname; @ManyToOne @JoinColumn(name=&quot;dadId&quot;) private Dad dad; public int getSid() &#123; return sid; &#125; public void setSid(int sid) &#123; this.sid = sid; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public Dad getDad() &#123; return dad; &#125; public void setDad(Dad dad) &#123; this.dad = dad; &#125; &#125; 3.多对多双向注解 Dad类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.wwj.manytomany;import java.util.ArrayList;import java.util.List;import javax.persistence.CascadeType;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.JoinTable;import javax.persistence.ManyToMany;import javax.persistence.OneToMany;import javax.persistence.OneToOne;@Entitypublic class Dad &#123; @Id @GeneratedValue private int did; private String dadName; @ManyToMany(cascade = &#123;CascadeType.ALL&#125;) @JoinTable(name=&quot;dad_son&quot;, joinColumns=&#123;@JoinColumn(name=&quot;did&quot;)&#125;, inverseJoinColumns=&#123;@JoinColumn(name=&quot;sid&quot;)&#125;) private List&lt;Son&gt; sons = new ArrayList&lt;&gt;(); public int getDid() &#123; return did; &#125; public void setDid(int did) &#123; this.did = did; &#125; public String getDadName() &#123; return dadName; &#125; public void setDadName(String dadName) &#123; this.dadName = dadName; &#125; public List&lt;Son&gt; getSons() &#123; return sons; &#125; public void setSons(List&lt;Son&gt; sons) &#123; this.sons = sons; &#125; &#125; son类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.wwj.manytomany;import java.util.List;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.JoinTable;import javax.persistence.ManyToMany;import javax.persistence.ManyToOne;import javax.persistence.OneToOne;@Entitypublic class Son &#123; @Id @GeneratedValue private int sid; private String sname; @ManyToMany @JoinTable(name=&quot;dad_son&quot;, joinColumns=&#123;@JoinColumn(name=&quot;sid&quot;)&#125;, inverseJoinColumns=&#123;@JoinColumn(name=&quot;did&quot;)&#125;) private List&lt;Dad&gt; dads; public int getSid() &#123; return sid; &#125; public void setSid(int sid) &#123; this.sid = sid; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public List&lt;Dad&gt; getDads() &#123; return dads; &#125; public void setDads(List&lt;Dad&gt; dads) &#123; this.dads = dads; &#125; &#125;]]></content>
      <categories>
        <category>Hibernate</category>
      </categories>
      <tags>
        <tag>数据持久化</tag>
        <tag>orm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis2]]></title>
    <url>%2F2019%2F07%2F18%2F2019-09-10-Mybatis(%E4%BB%BD)%2F</url>
    <content type="text"><![CDATA[mybatis是一个优秀的开源框架,半自动ORM映射,能够适配各种业务需求 mybatis路线图(下) MyBatis的多表联合查询(了解一对一,熟练一对多(理解延迟加载),熟练多对多) MyBatis的动态SQL(嵌套的语句的几种方式,按需使用) MyBatis中#{}${}之间的区别 MyBatis的延迟加载(什么是延迟加载,好处,场景) MyBatis的缓存机制(缓存机制策略,一级缓存和二级缓存的不同,二级缓存的实现) MyBatis逆向工程(了解逆向工程,思考不方便的地方) MyBatis的多表联合查询 1对1的说明:在级联关系中OneToOne是比较不太频繁出现的一种情况(在数据库设计上面可以考虑共用主键关系,或者利用一对多进行变种实现,利用外键可设置唯一约束UNIQUE约束),我们应该专注sql语句,追求高度自由化,虽然mybatis提供一对一的关联设置,但是我们还是利用一对多的方式进行变种实现 引用:级联不是必须的,级联的好处是获取关联数据十分便捷,但是级联过多会增加系统的复杂度，同时降低系统的性能,此增彼减,所以当级联的层级超过3层时,就不要考虑使用级联了,因为这样会造成多个对象的关联,导致系统的耦合,复杂和难以维护.在现实的使用过程中,要根据实际情况判断是否需要使用级联. 1对m的实现方式与m对1实现方式:(场景:1个用户有多个贴子,多个帖子的著作人) 表和实体关系说明:user表和post表为1:M的关系 实体代码如下:自行get和set 123456789public class User &#123; private int uid; private String uname; private List&lt;Post&gt; posts;&#125;public class Post &#123; private int pid; private int pname; &#125; 接口和mapper映射内容操作如下 1234567891011121314151617181920212223242526272829/** * 进行1对多的操作 * @author Yun * */public interface UserDao &#123; /** * 获取用户的信息和所发的帖子 * @return */ List&lt;User&gt; getUsers();&#125;//-----------对应的动作实现&lt;mapper namespace=&quot;com.wwj.dao.UserDao&quot;&gt; &lt;!-- 定义一对多的resultmap --&gt; &lt;resultMap type=&quot;com.wwj.model.User&quot; id=&quot;users&quot;&gt; &lt;id property=&quot;uid&quot; column=&quot;uid&quot; /&gt; &lt;result column=&quot;uname&quot; property=&quot;uname&quot; /&gt; &lt;collection property=&quot;posts&quot; ofType=&quot;com.wwj.model.Post&quot;&gt; &lt;id property=&quot;pid&quot; column=&quot;pid&quot; /&gt; &lt;result column=&quot;pname&quot; property=&quot;pname&quot; /&gt; &lt;/collection&gt; &lt;/resultMap&gt;//----------数据库操作 &lt;select id=&quot;getUsers&quot; resultMap=&quot;users&quot;&gt; select u.*,p.* from user u,post p where u.uid = p.uid &lt;/select&gt; 接下来是多对一的实现也就是在站在帖子这一边,展现帖子的时候希望看到著作人是谁(注意:实体会发生一点小的变动,在post属性中添加user属性) 1234567891011121314151617181920212223242526public interface PostDao &#123; /** * 获取所有帖子信息 * @return */ List&lt;Post&gt; getPosts();&#125;//-------动作的实现映射&lt;mapper namespace=&quot;com.wwj.dao.PostDao&quot;&gt; &lt;!-- 定义一对多的resultmap --&gt; &lt;resultMap type=&quot;com.wwj.model.Post&quot; id=&quot;posts&quot;&gt; &lt;id property=&quot;pid&quot; column=&quot;pid&quot; /&gt; &lt;result column=&quot;pname&quot; property=&quot;pname&quot; /&gt; &lt;association property=&quot;user&quot; javaType=&quot;com.wwj.model.User&quot;&gt; &lt;id property=&quot;uid&quot; column=&quot;uid&quot; /&gt; &lt;result column=&quot;uname&quot; property=&quot;uname&quot; /&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id=&quot;getPosts&quot; resultMap=&quot;posts&quot;&gt; select u.*,p.* from user u,post p where u.uid = p.uid &lt;/select&gt;&lt;/mapper&gt; 下面是多对多上面的操作场景(一个用户可以有多个兴趣,一个兴趣可能有多个人选择) 构建二个实体分别是animal和interest和第三方表(animal_interest) 创建一个第三方表的映射接口(animal_interestDao)和映射的实现(animal_interestMapper.xml) 12345678910111213141516171819202122232425262728293031323334353637383940 /** * 根据兴趣id查看有多少用户选择 * @param iid * @return */ List&lt;Animal&gt; getAnimalByIid(int iid); /** * 根据用户id查看有当前用户有哪些兴趣 * @param aid * @return */ List&lt;Interest&gt; getInterestByAid(int aid); //------对应的映射实现 &lt;mapper namespace=&quot;com.wwj.dao.Animal_InterestDao&quot;&gt; &lt;resultMap type=&quot;com.wwj.model.Animal&quot; id=&quot;animals&quot;&gt; &lt;id property=&quot;aid&quot; column=&quot;aid&quot; /&gt; &lt;result column=&quot;aname&quot; property=&quot;aname&quot; /&gt; &lt;/resultMap&gt; &lt;resultMap type=&quot;com.wwj.model.Interest&quot; id=&quot;interests&quot;&gt; &lt;id property=&quot;iid&quot; column=&quot;iid&quot; /&gt; &lt;result column=&quot;iname&quot; property=&quot;iname&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;getAnimalByIid&quot; parameterType=&quot;int&quot; resultMap=&quot;animals&quot;&gt; select a.*,ai.iid from animal a,animal_interest ai where a.aid = ai.aid and ai.iid = #&#123;iid&#125; &lt;/select&gt; &lt;select id=&quot;getInterestByAid&quot; parameterType=&quot;int&quot; resultMap=&quot;interests&quot;&gt; select i.*,ai.aid from interest i,animal_interest ai where i.iid = ai.iid and ai.aid = #&#123;aid&#125; &lt;/select&gt;&lt;/mapper&gt; 分别构建AnimalDao和InterestDao以及映射文件 1234567891011121314151617 //获取用户信息 List&lt;Animal&gt; getAnimals();//-------&lt;mapper namespace=&quot;com.wwj.dao.AnimalDao&quot;&gt;&lt;!-- 定义一对多的resultmap --&gt;&lt;resultMap type=&quot;com.wwj.model.Animal&quot; id=&quot;animals1&quot;&gt; &lt;id property=&quot;aid&quot; column=&quot;aid&quot; /&gt; &lt;result column=&quot;uname&quot; property=&quot;uname&quot; /&gt; &lt;collection property=&quot;interests&quot; column=&quot;aid&quot; select=&quot;com.wwj.dao.Animal_InterestDao.getInterestByAid&quot;&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;select id=&quot;getAnimals&quot; resultMap=&quot;animals1&quot; &gt; select a.* from animal a&lt;/select&gt; &lt;/mapper&gt; 1234567891011121314151617181920public interface InterestDao &#123; /** * 获取兴趣信息 * @return */ List&lt;Interest&gt; getInterests();&#125;//---------------------------- &lt;!-- 定义一对多的resultmap --&gt; &lt;resultMap type=&quot;com.wwj.model.Interest&quot; id=&quot;interests1&quot;&gt; &lt;id property=&quot;iid&quot; column=&quot;iid&quot; /&gt; &lt;result column=&quot;uname&quot; property=&quot;uname&quot; /&gt; &lt;collection property=&quot;animals&quot; column=&quot;iid&quot; select=&quot;com.wwj.dao.Animal_InterestDao.getAnimalByIid&quot;&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id=&quot;getInterests&quot; resultMap=&quot;interests1&quot; &gt; select i.* from interest i &lt;/select&gt;&lt;/mapper&gt; MyBatis的动态SQL模拟一张用户表进行说明,以及代码说明 123456789101112public interface TestUserDao &#123; /** * 依次为if/whereif/set/(whenchoose)/foreach * @param msg * @return */ TestUser getUser(Map msg); TestUser getUserUseWhere(Map msg); TestUser updateUserById(Map msg); TestUser selectUserByChoose(Map msg); List&lt;TestUser&gt; selectUserByListId(List ids); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapperPUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.wwj.dao.UserDao&quot;&gt; &lt;resultMap type=&quot;com.wwj.model.TestUser&quot; id=&quot;tuser&quot;&gt; &lt;id property=&quot;tid&quot; column=&quot;tid&quot; /&gt; &lt;result column=&quot;tname&quot; property=&quot;tname&quot; /&gt; &lt;result column=&quot;tage&quot; property=&quot;tage&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;getUser&quot; resultMap=&quot;tuser&quot;&gt; select * from testuser where &lt;if test=&quot;tname != null&quot;&gt; tname=#&#123;tname&#125; &lt;/if&gt; &lt;if test=&quot;tage != null&quot;&gt; and tage=#&#123;tage&#125; &lt;/if&gt; &lt;/select&gt; &lt;!-- where”标签会知道如果它包含的标签中有返回值的话,它就插入一个‘where’.此外，如果标签首次返回的内容是以AND或OR开头的,则它会剔除掉。 --&gt; &lt;select id=&quot;getUserUseWhere&quot; resultMap=&quot;tuser&quot;&gt; select * from testuser &lt;where&gt; &lt;if test=&quot;tname != null&quot;&gt; tname=#&#123;tname&#125; &lt;/if&gt; &lt;if test=&quot;tage != null&quot;&gt; and tage=#&#123;tage&#125; &lt;/if&gt; &lt;/where&gt; &lt;!-- (不常用)trim标记是一个格式化的标记，可以完成set或者是where标记的功能 prefix：前缀 prefixoverride：去掉第一个 suffix：后缀 suffixoverride：去掉最后一个 &lt;trim prefix=&quot;where&quot; prefixOverrides=&quot;and | or&quot;&gt; &lt;if test=&quot;username != null&quot;&gt; and username=#&#123;username&#125; &lt;/if&gt; &lt;if test=&quot;sex != null&quot;&gt; and sex=#&#123;sex&#125; &lt;/if&gt; &lt;/trim&gt; --&gt; &lt;/select&gt; &lt;update id=&quot;updateUserById&quot; parameterType=&quot;java.util.Map&quot;&gt; update testuser &lt;set&gt; &lt;if test=&quot;tname != null and tname != &apos;&apos;&quot;&gt; tname = #&#123;tname&#125;, &lt;/if&gt; &lt;if test=&quot;tage != null and tage != &apos;&apos;&quot;&gt; tage = #&#123;tage&#125; &lt;/if&gt; &lt;/set&gt; where tid=#&#123;tid&#125; &lt;/update&gt; &lt;select id=&quot;selectUserByChoose&quot; resultMap=&quot;tuser&quot; parameterType=&quot;java.util.Map&quot;&gt; select * from testuser &lt;where&gt; &lt;choose&gt; &lt;when test=&quot;tid !=&apos;&apos; and tid != null&quot;&gt; tid=#&#123;tid&#125; &lt;/when&gt; &lt;when test=&quot;tname !=&apos;&apos; and tname != null&quot;&gt; and tname=#&#123;tname&#125; &lt;/when&gt; &lt;otherwise&gt; and tage=#&#123;tage&#125; &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt; &lt;/select&gt; &lt;select id=&quot;selectUserByListId&quot; resultMap=&quot;tuser&quot; parameterType=&quot;java.util.List&quot;&gt; select * from testuser &lt;where&gt; &lt;!-- collection:指定输入对象中的集合属性 item:每次遍历生成的对象 open:开始遍历时的拼接字符串 close:结束时拼接的字符串 separator:遍历对象之间需要拼接的字符串 select * from user where 1=1 and (id=1 or id=2 or id=3) --&gt; &lt;foreach collection=&quot;list&quot; item=&quot;tid&quot; open=&quot;and (&quot; close=&quot;)&quot; separator=&quot;or&quot;&gt; tid=#&#123;tid&#125; &lt;/foreach&gt; &lt;/where&gt; &lt;/select&gt; &lt;/mapper&gt; MyBatis中#{}和${}区别简单的说#{}是采用占位符的方式，而$是采用是字符串拼接的方式字符串拼接的方式就一定会存在sql注入的问题 MyBatis的延迟加载(延迟加载===按需加载) 比如刚才的一个用户有多个兴趣,现在需要用户信息的时候,编写sql语句的时候同时也把暂时不需要看用户的兴趣的数据加载出来,在数据量大的情况就肯定有瓶颈。 所以我们可以参照多对多示例中进行设置延迟加载,来观察sql语句的发出 1234567//代码示例如下: 我仅仅需要用户信息,但是同样的也把其它非相关的信息加载出来了 List&lt;Animal&gt; as =session.selectList(&quot;getAnimals&quot;); System.out.println(as.get(0).getAname()); //---------DEBUG [main] - ==&gt; Preparing: select a.* from animal a DEBUG [main] - ==&gt; Parameters: DEBUG [main] - ====&gt; Preparing: select i.*,ai.aid from interest i,animal_interest ai where i.iid = ai.iid and ai.aid = ? 配置延迟加载 全局配置文件中配置添加 1234567891011121314&lt;settings&gt; &lt;!-- 启用延迟加载特性，不配置默认关闭该特性--&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;&gt;&lt;/setting&gt; &lt;!-- 按需加载: false:使用关联属性，及时加载; true,加载对象，则加载所有属性--&gt; &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt;&lt;/settings&gt; //------信息展示结果DEBUG [main] - ==&gt; Preparing: select a.* from animal a DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 2DEBUG [main] - ==&gt; Preparing: select i.*,ai.aid from interest i,animal_interest ai where i.iid = ai.iid and ai.aid = ? DEBUG [main] - ==&gt; Parameters: 1(Integer)DEBUG [main] - &lt;== Total: 3唱歌 MyBatis的缓存机制 一级缓存(缓存不相互共享,在同一个事务中,如果存在同样的操作,中间不带增删改操作的话。那么不在进行二次IO读取操作) 12345678910 List&lt;Animal&gt; as =session.selectList(&quot;getAnimals&quot;); System.out.println(as.get(0).getAname()); List&lt;Animal&gt; ass =session.selectList(&quot;getAnimals&quot;); System.out.println(as.get(0).getAname()); //------DEBUG [main] - ==&gt; Preparing: select a.* from animal a DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 2用户1用户1 二级缓存(缓存共享)需要映射的接口对应的映射文件加入: 12&lt;mapper namespace=&quot;com.wwj.dao.AnimalDao&quot;&gt;&lt;cache/&gt; 12345678910111213141516171819SqlSession session = build.openSession();List&lt;Animal&gt; as =session.selectList(&quot;getAnimals&quot;);System.out.println(as.get(0).getAname());List&lt;Animal&gt; ass =session.selectList(&quot;getAnimals&quot;);System.out.println(as.get(0).getAname()); // 提交事务session.commit();// 关闭 sessionsession.close();System.out.println(&quot;---------------------------分割线利于观察&quot;);//关闭了之后数据会放入缓存中//测试二级缓存SqlSession session1 = build.openSession();List&lt;Animal&gt; asss =session1.selectList(&quot;getAnimals&quot;);System.out.println(as.get(0).getAname());// 提交事务session1.commit();// 关闭 sessionsession1.close(); 1234567891011//-----控制台结果DEBUG [main] - &lt;== Total: 2用户1DEBUG [main] - Cache Hit Ratio [com.wwj.dao.AnimalDao]: 0.0用户1DEBUG [main] - Resetting autocommit to true on JDBC Connection [com.mysql.jdbc.Connection@8c03696]DEBUG [main] - Closing JDBC Connection [com.mysql.jdbc.Connection@8c03696]DEBUG [main] - Returned connection 146814614 to pool.---------------------------分割线利于观察DEBUG [main] - Cache Hit Ratio [com.wwj.dao.AnimalDao]: 0.3333333333333333用户1 (缓存机制策略的补充) 默认mybatis映射语句文件中所有的select语句将会被缓存 映射语句文件中所有的insert update delete 语句会刷新缓存 缓存会使用(Least Flush Interval,LRU最近最少使用的)算法来收回 根据时间表（如 no Flush Interval,没有刷新间隔），缓存不会以任何时间顺序来刷新 eviction(收回策略===更新策略)LRU 最近最少使用的，移除最长时间不被使用的对象,这是默认值 FIFO 先进先出，按对象进入缓存的顺序来移除它们 SOFT 软引用，移除基于垃圾回收器状态和软引用规则的对象 WEAK 弱引用，更积极的移除基于垃圾收集器状态和弱引用规则的对象 缓存存在数据可能出现脏读的现象(操作同一数据)缓存数据尽量用在变更不频繁的数据上面影响缓存的三个因素(缓存更新策略,缓存最大数据量,命中率) MyBatis逆向工程 逆向工程我们做简单的展示 逆向工程的含义在于根据数据库的表的结构以面向对象的方式自动的帮助我们生成对应的实体类 逆向为什么不太常用，因为一旦数据库的结构和关联发生变化，那么实际开发过程中就需要自己手动调整对应的实体类,这个可以说是一个非常浩瀚的工程,无论从人力和无力成本看来都得不偿失 以前我们可以说小的项目,用逆向比较方便,不如我们把逆向看成是不可取的，mybatis本身也是追求语句的自由化。所以逆向作为了解即可. 引入对应的jar包 构建逆向配置xml文件generatorConfig.xml位置在项目外 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;!-- targetRuntime=“MyBatis3“可以生成带条件的增删改查，targetRuntime=“MyBatis3Simple“可以生成基本的增删改查 --&gt;&lt;generatorConfiguration&gt; &lt;context id=&quot;testTables&quot; targetRuntime=&quot;MyBatis3Simple&quot;&gt; &lt;commentGenerator&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot; /&gt; &lt;/commentGenerator&gt; &lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://localhost:3306/mybatis&quot; userId=&quot;root&quot; password=&quot;root&quot;&gt; &lt;/jdbcConnection&gt; &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot; /&gt; &lt;/javaTypeResolver&gt; &lt;!-- targetProject:生成PO类的位置 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.wwj.model1&quot; targetProject=&quot;./src&quot;&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot; /&gt; &lt;/javaModelGenerator&gt; &lt;!-- targetProject:mapper映射文件生成的位置 --&gt; &lt;sqlMapGenerator targetPackage=&quot;com.wwj.dao1&quot; targetProject=&quot;./src&quot;&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- targetPackage：mapper接口生成的位置 --&gt; &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.wwj.dao1&quot; targetProject=&quot;./src&quot;&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定数据库表 --&gt;&lt;table schema=&quot;mybatis&quot; tableName=&quot;person&quot; domainObjectName=&quot;personG&quot;&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 构建生成main函数 123456789101112131415161718192021222324public class TestG &#123; public void generator() throws Exception&#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; //指定 逆向工程配置文件 File configFile = new File(&quot;generatorConfig.xml&quot;); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); &#125; public static void main(String[] args) throws Exception &#123; try &#123; TestG generatorSqlmap = new TestG(); generatorSqlmap.generator(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>数据持久化</tag>
        <tag>orm</tag>
        <tag>半自动</tag>
      </tags>
  </entry>
</search>
